---
sidebar_position: 3
sidebar_class_name: hidden
---

# Memory | メモリ

ほとんどのLLMアプリケーションには会話型インターフェースがあります。会話において重要な要素の一つは、会話の中で以前に導入された情報を参照できる能力です。最低限、会話型システムは過去のメッセージの一定範囲に直接アクセスできるべきです。より複雑なシステムでは、世界モデルを常に更新し続ける必要があり、それによってエンティティやその関係性についての情報を保持することが可能になります。

> Most LLM applications have a conversational interface. An essential component of a conversation is being able to refer to information introduced earlier in the conversation.
> At bare minimum, a conversational system should be able to access some window of past messages directly.
> A more complex system will need to have a world model that it is constantly updating, which allows it to do things like maintain information about entities and their relationships.

過去のやり取りに関する情報を保存するこの能力を「記憶」と呼びます。LangChainは、システムに記憶を追加するための多くのユーティリティを提供しています。これらのユーティリティは単独で使用することも、チェーンにシームレスに組み込むこともできます。

> We call this ability to store information about past interactions "memory".
> LangChain provides a lot of utilities for adding memory to a system.
> These utilities can be used by themselves or incorporated seamlessly into a chain.

メモリシステムは、基本的に読み取りと書き込みの2つのアクションをサポートする必要があります。すべてのチェーンは、特定の入力を期待するコア実行ロジックを定義していることを思い出してください。これらの入力のいくつかは直接ユーザーから提供されますが、一部はメモリから得られることもあります。チェーンは、一回の実行で2回、メモリシステムと対話します。

> A memory system needs to support two basic actions: reading and writing.
> Recall that every chain defines some core execution logic that expects certain inputs.
> Some of these inputs come directly from the user, but some of these inputs can come from memory.
> A chain will interact with its memory system twice in a given run.

1. 初期ユーザー入力を受け取った後、しかしコアロジックを実行する前に、チェーンはメモリシステムから読み取りを行い、ユーザー入力を拡張します。
   > AFTER receiving the initial user inputs but BEFORE executing the core logic, a chain will READ from its memory system and augment the user inputs.
2. コアロジックを実行した後、しかし答えを返す前に、チェーンは現在の実行の入力と出力をメモリに記録し、それらが将来の実行で参照できるようにします。
   > AFTER executing the core logic but BEFORE returning the answer, a chain will WRITE the inputs and outputs of the current run to memory, so that they can be referred to in future runs.

![memory-diagram](/img/memory_diagram.png)

## Building memory into a system | システムにメモリを組み込む

どんなメモリシステムにおいても、二つの核心的な設計決定があります：

> The two core design decisions in any memory system are:

* 状態がどのように保存されるか
  > How state is stored
* 状態がどのように照会されるか
  > How state is queried

### Storing: List of chat messages | 保存: チャットメッセージのリスト

どのメモリにも、すべてのチャットのやり取りの履歴が基盤として存在します。これらが直接全て使用されるわけではないものの、何らかの形で保存される必要があります。LangChainメモリモジュールの重要な部分の一つは、インメモリリストから永続的なデータベースまで、これらのチャットメッセージを保存するための一連の統合機能です。

> Underlying any memory is a history of all chat interactions.
> Even if these are not all used directly, they need to be stored in some form.
> One of the key parts of the LangChain memory module is a series of integrations for storing these chat messages,
> from in-memory lists to persistent databases.

* [チャットメッセージの保存](/docs/modules/memory/chat_messages/)：チャットメッセージの扱い方と、提供される様々な統合機能について。
  > [Chat message storage](/docs/modules/memory/chat_messages/): How to work with Chat Messages, and the various integrations offered.

### Querying: Data structures and algorithms on top of chat messages | クエリング：チャットメッセージ上のデータ構造とアルゴリズム

チャットメッセージのリストを保持することは比較的簡単です。しかし、それらのメッセージを最も役立つビューで提供するためにチャットメッセージの上に構築されるデータ構造やアルゴリズムは、それほど簡単ではありません。

> Keeping a list of chat messages is fairly straight-forward.
> What is less straight-forward are the data structures and algorithms built on top of chat messages that serve a view of those messages that is most useful.

非常にシンプルなメモリシステムは、それぞれの実行ごとに最新のメッセージを返すことがあります。やや複雑なメモリシステムは、過去K件のメッセージの簡潔な要約を返すこともできます。さらに洗練されたシステムでは、保存されたメッセージからエンティティを抽出し、現在の実行で言及されたエンティティに関する情報のみを返すことができます。

> A very simply memory system might just return the most recent messages each run. A slightly more complex memory system might return a succinct summary of the past K messages.
> An even more sophisticated system might extract entities from stored messages and only return information about entities referenced in the current run.

各アプリケーションは、メモリがどのように問い合わせられるかについて異なる要件を持っています。メモリモジュールは、シンプルなメモリシステムの導入を容易にするだけでなく、必要に応じて独自のカスタムシステムを書くことも簡単にできるようにするべきです。

> Each application can have different requirements for how memory is queried. The memory module should make it easy to both get started with simple memory systems and write your own custom systems if needed.

* [メモリタイプ](/docs/modules/memory/types/)：LangChainがサポートするさまざまなデータ構造とアルゴリズムによって構成されるメモリタイプ
  > [Memory types](/docs/modules/memory/types/): The various data structures and algorithms that make up the memory types LangChain supports

## Get started | 始めましょう

LangChainでのMemoryが実際にどのように見えるのかを見てみましょう。
ここでは、任意のメモリクラスとの基本的なインタラクションについて説明します。

> Let's take a look at what Memory actually looks like in LangChain.
> Here we'll cover the basics of interacting with an arbitrary memory class.

`ConversationBufferMemory`をチェーン内でどのように使用するか見てみましょう。
`ConversationBufferMemory`は、チャットメッセージのリストをバッファに保持し、それをプロンプトテンプレートに渡す、非常にシンプルな形式のメモリです。

> Let's take a look at how to use `ConversationBufferMemory` in chains.
> `ConversationBufferMemory` is an extremely simple form of memory that just keeps a list of chat messages in a buffer
> and passes those into the prompt template.

```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
memory.chat_memory.add_user_message("hi!")
memory.chat_memory.add_ai_message("what's up?")
```

チェーンでメモリを使用する際には、理解しておくべきいくつかの重要な概念があります。ここでは、ほとんどのメモリタイプに共通して役立つ一般的な概念について説明します。各個別のメモリタイプには、それぞれ理解が必要な独自のパラメーターや概念が存在する可能性があります。

> When using memory in a chain, there are a few key concepts to understand.
> Note that here we cover general concepts that are useful for most types of memory.
> Each individual memory type may very well have its own parameters and concepts that are necessary to understand.

### What variables get returned from memory | メモリから返される変数は何か

チェーンに入る前に、様々な変数がメモリから読み込まれます。これらは特定の名前を持っており、チェーンが期待する変数名と一致している必要があります。これらの変数が何であるかは、`memory.load_memory_variables({})`を呼び出すことで確認できます。ここで渡される空の辞書は、実際の変数用のプレースホルダーに過ぎないことに注意してください。使用しているメモリタイプが入力変数に依存している場合、いくつかの変数を渡す必要があるかもしれません。

> Before going into the chain, various variables are read from memory.
> These have specific names which need to align with the variables the chain expects.
> You can see what these variables are by calling `memory.load_memory_variables({})`.
> Note that the empty dictionary that we pass in is just a placeholder for real variables.
> If the memory type you are using is dependent upon the input variables, you may need to pass some in.

```python
memory.load_memory_variables({})
```

<CodeOutputBlock lang="python">

```
    {'history': "Human: hi!\nAI: what's up?"}
```

</CodeOutputBlock>

この場合、`load_memory_variables`が単一のキー`history`を返すことがわかります。これは、あなたのチェーン（おそらくプロンプトも）が`history`という名前の入力を期待することを意味しています。通常、メモリクラスのパラメータを通じてこの変数を制御することができます。例えば、メモリ変数を`chat_history`というキーで返すようにしたい場合は、次のようにすることができます：

> In this case, you can see that `load_memory_variables` returns a single key, `history`.
> This means that your chain (and likely your prompt) should expect an input named `history`.
> You can usually control this variable through parameters on the memory class.
> For example, if you want the memory variables to be returned in the key `chat_history` you can do:

```python
memory = ConversationBufferMemory(memory_key="chat_history")
memory.chat_memory.add_user_message("hi!")
memory.chat_memory.add_ai_message("what's up?")
```

<CodeOutputBlock lang="python">

```
    {'chat_history': "Human: hi!\nAI: what's up?"}
```

</CodeOutputBlock>

これらのキーを制御するパラメータ名はメモリタイプによって異なる場合がありますが、(1)これが制御可能であること、そして(2)どのように制御するかを理解することが重要です。

> The parameter name to control these keys may vary per memory type, but it's important to understand that (1) this is controllable, and (2) how to control it.

### Whether memory is a string or a list of messages | メモリが文字列であるか、メッセージのリストであるか

最も一般的なメモリのタイプの一つは、チャットメッセージのリストを返すことです。これらは、すべて連結された単一の文字列として返されることもあります（LLMに渡す際に便利）、またはChatMessagesのリストとして返されることもあります（ChatModelsに渡す際に便利です）。

> One of the most common types of memory involves returning a list of chat messages.
> These can either be returned as a single string, all concatenated together (useful when they will be passed into LLMs)
> or a list of ChatMessages (useful when passed into ChatModels).

デフォルトでは、結果は単一の文字列として返されます。メッセージのリストとして返すためには、`return_messages=True`を設定することができます。

> By default, they are returned as a single string.
> In order to return as a list of messages, you can set `return_messages=True`

```python
memory = ConversationBufferMemory(return_messages=True)
memory.chat_memory.add_user_message("hi!")
memory.chat_memory.add_ai_message("what's up?")
```

<CodeOutputBlock lang="python">

```
    {'history': [HumanMessage(content='hi!', additional_kwargs={}, example=False),
  AIMessage(content='what's up?', additional_kwargs={}, example=False)]}
```

</CodeOutputBlock>

### What keys are saved to memory | どのキーがメモリに保存されているか

しばしば、チェーンは複数の入力キーや出力キーを取り込んだり返したりします。このような場合、どのキーをチャットメッセージの履歴に保存したいかをどうやって知ることができるでしょうか？これは通常、メモリタイプの`input_key`と`output_key`パラメータによって制御されます。これらはデフォルトで`None`に設定されており、入力キー/出力キーが1つだけの場合は、そのキーを使用することが分かっています。しかし、複数の入力キー/出力キーがある場合は、使用するキーの名前を明示的に指定しなければなりません。

> Often times chains take in or return multiple input/output keys.
> In these cases, how can we know which keys we want to save to the chat message history?
> This is generally controllable by `input_key` and `output_key` parameters on the memory types.
> These default to `None` - and if there is only one input/output key it is known to just use that.
> However, if there are multiple input/output keys then you MUST specify the name of which one to use.

### End to end example | エンドツーエンドの例

最後に、これを連鎖的に使用する方法を見てみましょう。
`LLMChain`を使用し、LLMとChatModelの両方を使った作業を示します。

> Finally, let's take a look at using this in a chain.
> We'll use an `LLMChain`, and show working with both an LLM and a ChatModel.

#### Using an LLM | LLMの利用

```python
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory


llm = OpenAI(temperature=0)
# Notice that "chat_history" is present in the prompt template
template = """You are a nice chatbot having a conversation with a human.

Previous conversation:
{chat_history}

New human question: {question}
Response:"""
prompt = PromptTemplate.from_template(template)
# Notice that we need to align the `memory_key`
memory = ConversationBufferMemory(memory_key="chat_history")
conversation = LLMChain(
    llm=llm,
    prompt=prompt,
    verbose=True,
    memory=memory
)
```

```python
# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory
conversation({"question": "hi"})
```

#### Using a ChatModel | ChatModelの使用

```python
from langchain.chat_models import ChatOpenAI
from langchain.prompts import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory


llm = ChatOpenAI()
prompt = ChatPromptTemplate(
    messages=[
        SystemMessagePromptTemplate.from_template(
            "You are a nice chatbot having a conversation with a human."
        ),
        # The `variable_name` here is what must align with memory
        MessagesPlaceholder(variable_name="chat_history"),
        HumanMessagePromptTemplate.from_template("{question}")
    ]
)
# Notice that we `return_messages=True` to fit into the MessagesPlaceholder
# Notice that `"chat_history"` aligns with the MessagesPlaceholder name.
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
conversation = LLMChain(
    llm=llm,
    prompt=prompt,
    verbose=True,
    memory=memory
)
```

```python
# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory
conversation({"question": "hi"})
```

## Next steps | 次のステップ

これでスタートの準備は完了です！カスタムメモリ、複数メモリ、その他の高度なトピックの詳細な解説は、他のセクションをご覧ください。

> And that's it for getting started!
> Please see the other sections for walkthroughs of more advanced topics,
> like custom memory, multiple memories, and more.
