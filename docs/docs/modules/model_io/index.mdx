---
sidebar_position: 0
sidebar_custom_props:
  description: Interface with language models
sidebar_class_name: hidden
---

# Model I/O | Model I/O

言語モデルアプリケーションの中核要素は...モデルです。LangChainは、どんな言語モデルともインターフェースするための構成要素を提供します。

> The core element of any language model application is...the model. LangChain gives you the building blocks to interface with any language model.

* [Prompts](/docs/modules/model_io/prompts/): モデルの入力をテンプレート化し、動的に選択し、管理する
  > [Prompts](/docs/modules/model_io/prompts/): Templatize, dynamically select, and manage model inputs
* [チャットモデル](/docs/modules/model_io/chat/)：言語モデルに裏打ちされ、入力としてチャットメッセージのリストを受け取り、チャットメッセージを返すモデル
  > [Chat models](/docs/modules/model_io/chat/): Models that are backed by a language model but take a list of Chat Messages as input and return a Chat Message
* [LLMs](/docs/modules/model_io/llms/)：テキスト文字列を入力として受け取り、テキスト文字列を返すモデル
  > [LLMs](/docs/modules/model_io/llms/): Models that take a text string as input and return a text string
* [出力パーサー](/docs/modules/model_io/output_parsers/)：モデルの出力から情報を抽出する
  > [Output parsers](/docs/modules/model_io/output_parsers/): Extract information from model outputs

![model\_io\_diagram](/img/model_io.jpg)

## LLMs vs Chat models | LLMsとチャットモデルの比較

LLMとチャットモデルは微妙に異なりますが、重要な違いがあります。LangChainにおけるLLMは、純粋なテキスト補完モデルを指します。それらがラップするAPIは、文字列のプロンプトを入力として受け取り、文字列の補完を出力します。OpenAIのGPT-3はLLMとして実装されています。チャットモデルはしばしばLLMに基づいていますが、会話を行うために特別に調整されています。そして、重要なことに、それらのプロバイダーAPIは純粋なテキスト補完モデルとは異なるインターフェースを使用します。単一の文字列の代わりに、彼らはチャットメッセージのリストを入力として取ります。通常、これらのメッセージには話者（通常は「System」、「AI」、または「Human」のいずれか）がラベル付けされています。そして、AIのチャットメッセージを出力として返します。GPT-4とAnthropicのClaude-2は、両方ともチャットモデルとして実装されています。

> LLMs and chat models are subtly but importantly different. LLMs in LangChain refer to pure text completion models.
> The APIs they wrap take a string prompt as input and output a string completion. OpenAI's GPT-3 is implemented as an LLM.
> Chat models are often backed by LLMs but tuned specifically for having conversations.
> And, crucially, their provider APIs use a different interface than pure text completion models. Instead of a single string,
> they take a list of chat messages as input. Usually these messages are labeled with the speaker (usually one of "System",
> "AI", and "Human"). And they return an AI chat message as output. GPT-4 and Anthropic's Claude-2 are both implemented as chat models.
