{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9b7651",
   "metadata": {},
   "source": [
    "# Azure OpenAI | Azure OpenAI\n",
    "\n",
    "このノートブックでは、[Azure OpenAI](https://aka.ms/azure-openai)を使用してLangchainを使う方法について説明します。\n",
    "\n",
    "> This notebook goes over how to use Langchain with [Azure OpenAI](https://aka.ms/azure-openai).\n",
    "\n",
    "Azure OpenAI APIはOpenAIのAPIと互換性があります。`openai` Pythonパッケージを使用すると、OpenAIとAzure OpenAIの両方を簡単に使用できます。以下に記載された例外を除き、OpenAIを呼び出すのと同じ方法でAzure OpenAIを呼び出すことができます。\n",
    "\n",
    "> The Azure OpenAI API is compatible with OpenAI's API.  The `openai` Python package makes it easy to use both OpenAI and Azure OpenAI.  You can call Azure OpenAI the same way you call OpenAI with the exceptions noted below.\n",
    "\n",
    "## API configuration | API設定\n",
    "\n",
    "`openai` パッケージを環境変数を使用して Azure OpenAI で使用するように設定できます。以下は `bash` 用です：\n",
    "\n",
    "> You can configure the `openai` package to use Azure OpenAI using environment variables.  The following is for `bash`:\n",
    "\n",
    "```bash\n",
    "# Set this to `azure`\n",
    "export OPENAI_API_TYPE=azure\n",
    "# The API version you want to use: set this to `2023-05-15` for the released version.\n",
    "export OPENAI_API_VERSION=2023-05-15\n",
    "# The base URL for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource.\n",
    "export OPENAI_API_BASE=https://your-resource-name.openai.azure.com\n",
    "# The API key for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource.\n",
    "export OPENAI_API_KEY=<your Azure OpenAI API key>\n",
    "```\n",
    "\n",
    "あるいは、実行中のPython環境内で直接APIを設定することもできます：\n",
    "\n",
    "> Alternatively, you can configure the API right within your running Python environment:\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "```\n",
    "\n",
    "## Azure Active Directory Authentication | Azure Active Directory 認証\n",
    "\n",
    "Azure OpenAIに認証する方法は2つあります：\n",
    "\n",
    "> There are two ways you can authenticate to Azure OpenAI:\n",
    "\n",
    "* APIキー\n",
    "\n",
    "  > API Key\n",
    "\n",
    "* Azure Active Directory (AAD)\n",
    "\n",
    "  > Azure Active Directory (AAD)\n",
    "\n",
    "\n",
    "APIキーの使用は、スタートする上で最も簡単な方法です。Azureポータル内のあなたのAzure OpenAIリソースにあるAPIキーを見つけることができます。\n",
    "\n",
    "> Using the API key is the easiest way to get started. You can find your API key in the Azure portal under your Azure OpenAI resource.\n",
    "\n",
    "しかし、複雑なセキュリティ要件がある場合は、Azure Active Directory (AAD) の使用を検討してください。Azure OpenAIでAADを使用する方法についての詳細は[こちら](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/managed-identity)で確認できます。\n",
    "\n",
    "> However, if you have complex security requirements - you may want to use Azure Active Directory. You can find more information on how to use AAD with Azure OpenAI [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/managed-identity).\n",
    "\n",
    "ローカルで開発を行う場合、Azure CLIをインストールし、ログインしている必要があります。Azure CLIは[こちら](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli)からインストールできます。インストール後、`az login`コマンドを実行してログインしてください。\n",
    "\n",
    "> If you are developing locally, you will need to have the Azure CLI installed and be logged in. You can install the Azure CLI [here](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli). Then, run `az login` to log in.\n",
    "\n",
    "Azure OpenAIリソースに`Cognitive Services OpenAI User`というAzureロール割り当てを追加してください。これにより、Azure OpenAIを使用するためのAADからのトークンを取得できるようになります。このロール割り当ては、ユーザー、グループ、サービスプリンシパル、または管理されたアイデンティティに付与することができます。Azure OpenAIのRBACロールについての詳細は[こちら](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/role-based-access-control)をご覧ください。\n",
    "\n",
    "> Add a role an Azure role assignment `Cognitive Services OpenAI User` scoped to your Azure OpenAI resource. This will allow you to get a token from AAD to use with Azure OpenAI. You can grant this role assignment to a user, group, service principal, or managed identity. For more information about Azure OpenAI RBAC roles see [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/role-based-access-control).\n",
    "\n",
    "LangChainでPythonにおいてAADを利用するには、`azure-identity`パッケージをインストールしてください。次に、`OPENAI_API_TYPE`を`azure_ad`に設定します。その後、以下に示すように`DefaultAzureCredential`クラスを使用して`get_token`を呼び出し、AADからトークンを取得します。最後に、トークン値を環境変数`OPENAI_API_KEY`に設定してください。\n",
    "\n",
    "> To use AAD in Python with LangChain, install the `azure-identity` package. Then, set `OPENAI_API_TYPE` to `azure_ad`. Next, use the `DefaultAzureCredential` class to get a token from AAD by calling `get_token` as shown below. Finally, set the `OPENAI_API_KEY` environment variable to the token value.\n",
    "\n",
    "```python\n",
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Get the Azure Credential\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Set the API type to `azure_ad`\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure_ad\"\n",
    "# Set the API_KEY to the token from the Azure credential\n",
    "os.environ[\"OPENAI_API_KEY\"] = credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "```\n",
    "\n",
    "`DefaultAzureCredential` クラスは、AAD認証を始めるための簡単な方法です。必要に応じて、クレデンシャルチェーンをカスタマイズすることも可能です。以下に示す例では、最初に Managed Identity を試み、それが利用できない場合は Azure CLI にフォールバックします。これは、Azure でコードを実行しつつ、ローカルでの開発を行いたい場合に便利です。\n",
    "\n",
    "> The `DefaultAzureCredential` class is an easy way to get started with AAD authentication. You can also customize the credential chain if necessary. In the example shown below, we first try Managed Identity, then fall back to the Azure CLI. This is useful if you are running your code in Azure, but want to develop locally.\n",
    "\n",
    "```python\n",
    "from azure.identity import ChainedTokenCredential, ManagedIdentityCredential, AzureCliCredential\n",
    "\n",
    "credential = ChainedTokenCredential(\n",
    "    ManagedIdentityCredential(),\n",
    "    AzureCliCredential()\n",
    ")\n",
    "```\n",
    "\n",
    "## Deployments | デプロイメント\n",
    "\n",
    "Azure OpenAIでは、一般的なGPT-3およびCodexモデルのデプロイメントを自分で設定します。APIを呼び出す際には、使用したいデプロイメントを指定する必要があります。\n",
    "\n",
    "> With Azure OpenAI, you set up your own deployments of the common GPT-3 and Codex models.  When calling the API, you need to specify the deployment you want to use.\n",
    "\n",
    "\\***注意**: これらのドキュメントはAzureのテキスト補完モデル用です。GPT-4のようなモデルはチャットモデルであり、少し異なるインターフェースを持っています。これらは`AzureChatOpenAI`クラスを通じてアクセスできます。Azureチャットに関するドキュメントについては、[Azure Chat OpenAI documentation](/docs/integrations/chat/azure_chat_openai)をご覧ください。\n",
    "\n",
    "> ***Note**: These docs are for the Azure text completion models. Models like GPT-4 are chat models. They have a slightly different interface, and can be accessed via the `AzureChatOpenAI` class. For docs on Azure chat see [Azure Chat OpenAI documentation](/docs/integrations/chat/azure_chat_openai).*\n",
    "\n",
    "例えば、あなたのデプロイメント名が `text-davinci-002-prod` だとしましょう。`openai` Python APIでは、`engine` パラメータを使用してこのデプロイメントを指定できます。例えば：\n",
    "\n",
    "> Let's say your deployment name is `text-davinci-002-prod`.  In the `openai` Python API, you can specify this deployment with the `engine` parameter.  For example:\n",
    "\n",
    "```python\n",
    "import openai\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-002-prod\",\n",
    "    prompt=\"This is a test\",\n",
    "    max_tokens=5\n",
    ")\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fdb593-5a42-4098-87b7-1496fa511b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faacfa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"...\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fad2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Azure OpenAI\n",
    "from langchain.llms import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c80213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Azure OpenAI\n",
    "# Replace the deployment name with your own\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=\"td2\",\n",
    "    model_name=\"gpt-3.5-turbo-instruct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "592dc404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nWhy couldn't the bicycle stand up by itself? Because it was...two tired!\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the LLM\n",
    "llm(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfebea1",
   "metadata": {},
   "source": [
    "LLMを出力して、そのカスタム出力を見ることもできます。\n",
    "\n",
    "> We can also print the LLM and see its custom print.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c33fa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAzureOpenAI\u001b[0m\n",
      "Params: {'deployment_name': 'text-davinci-002', 'model_name': 'text-davinci-002', 'temperature': 0.7, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'best_of': 1}\n"
     ]
    }
   ],
   "source": [
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b5917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3bae61d45a4f4d73ecea8149862d4bfbae7d4d4a2f71b6e609a1be8f6c8d4298"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}