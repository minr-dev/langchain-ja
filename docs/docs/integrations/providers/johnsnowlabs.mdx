# Johnsnowlabs | Johnsnowlabs

オープンソースの `johnsnowlabs` ライブラリを使用して、200以上の言語で21,000以上のエンタープライズNLPモデルを含む、[johnsnowlabs](https://www.johnsnowlabs.com/) のエンタープライズNLPライブラリのエコシステムにアクセスできます。24,000以上のモデルについては、[John Snow Labs Model Hub](https://nlp.johnsnowlabs.com/models)をご覧ください。

> Gain access to the [johnsnowlabs](https://www.johnsnowlabs.com/) ecosystem of enterprise NLP libraries
> with over 21.000 enterprise NLP models in over 200 languages with the open source `johnsnowlabs` library.
> For all 24.000+ models, see the [John Snow Labs Model Models Hub](https://nlp.johnsnowlabs.com/models)

## Installation and Setup | インストールとセットアップ

```bash
pip install johnsnowlabs
```

[エンタープライズ機能をインストール](https://nlp.johnsnowlabs.com/docs/en/jsl/install_licensed_quick)するには、以下を実行してください:

> To \[install enterprise features]\(https://nlp.johnsnowlabs.com/docs/en/jsl/install\_licensed\_quick, run:

```python
# for more details see https://nlp.johnsnowlabs.com/docs/en/jsl/install_licensed_quick
nlp.install()
```

クエリやドキュメントを埋め込む際には、`gpu`、`cpu`、`apple_silicon`、`aarch`に最適化されたバイナリを使用することができます。デフォルトではCPUバイナリが使用されます。セッションが開始された後は、GPUとCPU間で切り替えるにはノートブックを再起動する必要があります。そうしなければ変更は有効になりません。

> You can embed your queries and documents with either `gpu`,`cpu`,`apple_silicon`,`aarch` based optimized binaries.
> By default cpu binaries are used.
> Once a session is started, you must restart your notebook to switch between GPU or CPU, or changes will not take effect.

## Embed Query with CPU: | CPUを使用したクエリの埋め込み:

```python
document = "foo bar"
embedding = JohnSnowLabsEmbeddings('embed_sentence.bert')
output = embedding.embed_query(document)
```

## Embed Query with GPU: | GPUを使用したクエリの埋め込み:

```python
document = "foo bar"
embedding = JohnSnowLabsEmbeddings('embed_sentence.bert','gpu')
output = embedding.embed_query(document)
```

## Embed Query with Apple Silicon (M1,M2,etc..): | Apple Silicon（M1, M2など）でのクエリの埋め込み:

```python
documents = ["foo bar", 'bar foo']
embedding = JohnSnowLabsEmbeddings('embed_sentence.bert','apple_silicon')
output = embedding.embed_query(document)
```

## Embed Query with AARCH: | AARCHでクエリを埋め込む：

```python
documents = ["foo bar", 'bar foo']
embedding = JohnSnowLabsEmbeddings('embed_sentence.bert','aarch')
output = embedding.embed_query(document)
```

## Embed Document with CPU: | CPUを使用してドキュメントを埋め込む：

```python
documents = ["foo bar", 'bar foo']
embedding = JohnSnowLabsEmbeddings('embed_sentence.bert','gpu')
output = embedding.embed_documents(documents)
```

## Embed Document with GPU: | GPUを使用してドキュメントを埋め込む：

```python
documents = ["foo bar", 'bar foo']
embedding = JohnSnowLabsEmbeddings('embed_sentence.bert','gpu')
output = embedding.embed_documents(documents)
```

## Embed Document with Apple Silicon (M1,M2,etc..): | Apple Silicon（M1, M2など）を搭載したデバイスでのドキュメント埋め込み：

````python

```python
documents = ["foo bar", 'bar foo']
embedding = JohnSnowLabsEmbeddings('embed_sentence.bert','apple_silicon')
output = embedding.embed_documents(documents)
````

## Embed Document with AARCH: | AARCHでドキュメントを埋め込む：

````python

```python
documents = ["foo bar", 'bar foo']
embedding = JohnSnowLabsEmbeddings('embed_sentence.bert','aarch')
output = embedding.embed_documents(documents)
````

モデルは [nlp.load](https://nlp.johnsnowlabs.com/docs/en/jsl/load_api) で読み込まれ、内部的に [nlp.start()](https://nlp.johnsnowlabs.com/docs/en/jsl/start-a-sparksession) によってSparkセッションが開始されます。

> Models are loaded with [nlp.load](https://nlp.johnsnowlabs.com/docs/en/jsl/load_api) and spark session is started with [nlp.start()](https://nlp.johnsnowlabs.com/docs/en/jsl/start-a-sparksession) under the hood.
