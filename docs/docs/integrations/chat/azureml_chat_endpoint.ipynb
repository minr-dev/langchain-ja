{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Azure ML Endpoint\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AzureMLChatOnlineEndpoint | AzureMLChatOnlineEndpoint\n",
    "\n",
    "> [Azure Machine Learning](https://azure.microsoft.com/en-us/products/machine-learning/)は、機械学習モデルを構築、訓練、デプロイするために使用されるプラットフォームです。ユーザーは、Azure Foundation ModelsやOpenAI Modelsを提供するModel Catalogでデプロイするモデルの種類を探索することができます。`Azure Foundation Models`には、さまざまなオープンソースモデルや人気のあるHugging Faceモデルが含まれています。ユーザーは、自分の好みに合わせてモデルをAzureMLにインポートすることもできます。\n",
    ">\n",
    "> > [Azure Machine Learning](https://azure.microsoft.com/en-us/products/machine-learning/) is a platform used to build, train, and deploy machine learning models. Users can explore the types of models to deploy in the Model Catalog, which provides Azure Foundation Models and OpenAI Models. `Azure Foundation Models` include various open-source models and popular Hugging Face models. Users can also import models of their liking into AzureML.\n",
    ">\n",
    "> [Azure Machine Learning Online Endpoints](https://learn.microsoft.com/en-us/azure/machine-learning/concept-endpoints)について。機械学習モデルやパイプラインをトレーニングした後、他の人が推論のために使用できるように、それらを本番環境にデプロイする必要があります。推論とは、新しい入力データを機械学習モデルやパイプラインに適用して出力を生成するプロセスのことです。これらの出力は通常「予測」と呼ばれますが、推論は分類やクラスタリングなど、他の機械学習タスクの出力を生成するためにも使用されます。`Azure Machine Learning`では、エンドポイントとデプロイメントを使用して推論を実行します。`Endpoints`と`Deployments`により、本番ワークロードのインターフェースをそれを提供する実装から切り離すことが可能です。\n",
    ">\n",
    "> > [Azure Machine Learning Online Endpoints](https://learn.microsoft.com/en-us/azure/machine-learning/concept-endpoints). After you train machine learning models or pipelines, you need to deploy them to production so that others can use them for inference. Inference is the process of applying new input data to the machine learning model or pipeline to generate outputs. While these outputs are typically referred to as \"predictions,\" inferencing can be used to generate outputs for other machine learning tasks, such as classification and clustering. In `Azure Machine Learning`, you perform inferencing by using endpoints and deployments. `Endpoints` and `Deployments` allow you to decouple the interface of your production workload from the implementation that serves it.\n",
    "\n",
    "このノートブックでは、`Azure Machine Learning Endpoint`にホストされているチャットモデルの使用方法について説明しています。\n",
    "\n",
    "> This notebook goes over how to use a chat model hosted on an `Azure Machine Learning Endpoint`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models.azureml_endpoint import AzureMLChatOnlineEndpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up | セットアップ\n",
    "\n",
    "ラッパーを使用するには、[AzureML上でモデルをデプロイ](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-foundation-models?view=azureml-api-2#deploying-foundation-models-to-endpoints-for-inferencing)して、以下のパラメーターを取得する必要があります：\n",
    "\n",
    "> To use the wrapper, you must [deploy a model on AzureML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-foundation-models?view=azureml-api-2#deploying-foundation-models-to-endpoints-for-inferencing) and obtain the following parameters:\n",
    "\n",
    "* `endpoint_api_key`：エンドポイントによって提供されるAPIキー\n",
    "\n",
    "  > `endpoint_api_key`: The API key provided by the endpoint\n",
    "\n",
    "* `endpoint_url`：エンドポイントによって提供されるRESTエンドポイントのURL\n",
    "\n",
    "  > `endpoint_url`: The REST endpoint url provided by the endpoint\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Formatter | コンテンツフォーマッター\n",
    "\n",
    "`content_formatter` パラメータは、AzureMLエンドポイントのリクエストとレスポンスを必要なスキーマに合わせて変換するハンドラクラスです。モデルカタログには多種多様なモデルがあり、それぞれがデータを異なる方法で処理することがあるため、ユーザーがデータを自分の好みに合わせて変換できるように`ContentFormatterBase` クラスが提供されています。以下に、提供されているコンテンツフォーマッターを示します：\n",
    "\n",
    "> The `content_formatter` parameter is a handler class for transforming the request and response of an AzureML endpoint to match with required schema. Since there are a wide range of models in the model catalog, each of which may process data differently from one another, a `ContentFormatterBase` class is provided to allow users to transform data to their liking. The following content formatters are provided:\n",
    "\n",
    "* `LLamaContentFormatter`：LLaMa2-chatのリクエストとレスポンスデータを整形します\n",
    "\n",
    "  > `LLamaContentFormatter`: Formats request and response data for LLaMa2-chat\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='  The Collatz Conjecture is one of the most famous unsolved problems in mathematics, and it has been the subject of much study and research for many years. While it is impossible to predict with certainty whether the conjecture will ever be solved, there are several reasons why it is considered a challenging and important problem:\\n\\n1. Simple yet elusive: The Collatz Conjecture is a deceptively simple statement that has proven to be extraordinarily difficult to prove or disprove. Despite its simplicity, the conjecture has eluded some of the brightest minds in mathematics, and it remains one of the most famous open problems in the field.\\n2. Wide-ranging implications: The Collatz Conjecture has far-reaching implications for many areas of mathematics, including number theory, algebra, and analysis. A solution to the conjecture could have significant impacts on these fields and potentially lead to new insights and discoveries.\\n3. Computational evidence: While the conjecture remains unproven, extensive computational evidence supports its validity. In fact, no counterexample to the conjecture has been found for any starting value up to 2^64 (a number', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models.azureml_endpoint import LlamaContentFormatter\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = AzureMLChatOnlineEndpoint(\n",
    "    endpoint_url=\"https://<your-endpoint>.<your_region>.inference.ml.azure.com/score\",\n",
    "    endpoint_api_key=\"my-api-key\",\n",
    "    content_formatter=LlamaContentFormatter,\n",
    ")\n",
    "response = chat(\n",
    "    messages=[HumanMessage(content=\"Will the Collatz conjecture ever be solved?\")]\n",
    ")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}