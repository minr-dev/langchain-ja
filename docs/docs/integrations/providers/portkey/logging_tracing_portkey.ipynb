{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log, Trace, and Monitor | ログ、トレース、監視\n",
    "\n",
    "Langchainを使用してアプリやエージェントを構築する際、単一のユーザーリクエストを満たすためには複数のAPIコールが必要になります。しかし、これらのリクエストは分析する際には連携されていません。[**Portkey**](/docs/ecosystem/integrations/portkey)を利用すると、単一のユーザーリクエストに関連する全ての埋め込み、完了、その他のリクエストがログに記録され、共通のIDで追跡されます。これにより、ユーザーのインタラクションを完全に可視化することが可能になります。\n",
    "\n",
    "> When building apps or agents using Langchain, you end up making multiple API calls to fulfill a single user request. However, these requests are not chained when you want to analyse them. With [**Portkey**](/docs/ecosystem/integrations/portkey), all the embeddings, completion, and other requests from a single user request will get logged and traced to a common ID, enabling you to gain full visibility of user interactions.\n",
    "\n",
    "このノートブックは、Langchainアプリで`Portkey`を使用してLangchain LLMの呼び出しをログに記録し、追跡し、監視する方法についてのステップバイステップガイドとして機能します。\n",
    "\n",
    "> This notebook serves as a step-by-step guide on how to log, trace, and monitor Langchain LLM calls using `Portkey` in your Langchain app.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、Portkey、OpenAI、そしてAgentツールをインポートしましょう\n",
    "\n",
    "> First, let's import Portkey, OpenAI, and Agent tools\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.utilities import Portkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下にあなたのOpenAI APIキーを貼り付けてください。[(こちらで見つけることができます)](https://platform.openai.com/account/api-keys)\n",
    "\n",
    "> Paste your OpenAI API key below. [(You can find it here)](https://platform.openai.com/account/api-keys)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"<OPENAI_API_KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Portkey API Key | Portkey APIキーを取得する\n",
    "\n",
    "1. [こちらからPortkeyに登録してください](https://app.portkey.ai/login)\n",
    "\n",
    "   > Sign up for [Portkey here](https://app.portkey.ai/login)\n",
    "\n",
    "2. [ダッシュボード](https://app.portkey.ai/)で、左上にあるプロフィールアイコンをクリックし、その後「APIキーをコピー」をクリックしてください。\n",
    "\n",
    "   > On your [dashboard](https://app.portkey.ai/), click on the profile icon on the top left, then click on \"Copy API Key\"\n",
    "\n",
    "3. 以下に貼り付けてください\n",
    "\n",
    "   > Paste it below\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PORTKEY_API_KEY = \"<PORTKEY_API_KEY>\"  # Paste your Portkey API Key here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Trace ID | トレースIDを設定\n",
    "\n",
    "1. 以下にあなたのリクエストのトレースIDを設定してください\n",
    "\n",
    "   > Set the trace id for your request below\n",
    "\n",
    "2. 単一のリクエストから発生するすべてのAPIコールに対して、Trace IDが共通であることがあります\n",
    "\n",
    "   > The Trace ID can be common for all API calls originating from a single request\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACE_ID = \"portkey_langchain_demo\"  # Set trace id here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Portkey Headers | Portkey ヘッダーを生成する\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = Portkey.Config(\n",
    "    api_key=PORTKEY_API_KEY,\n",
    "    trace_id=TRACE_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エージェントを通常通り実行してください。**唯一の変更点**は、これからリクエストに**上記のヘッダーを含める**ことです。\n",
    "\n",
    "> Run your agent as usual. The **only** change is that we will **include the above headers** in the request now.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, headers=headers)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "# Let's test it out!\n",
    "agent.run(\n",
    "    \"What was the high temperature in SF yesterday in Fahrenheit? What is that number raised to the .023 power?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Logging & Tracing Works on Portkey | Portkeyでのログ記録とトレースの仕組み\n",
    "\n",
    "**ログ記録**\n",
    "\n",
    "> **Logging**\n",
    "\n",
    "* Portkeyを通じてリクエストを送信することで、デフォルトで全てのリクエストが記録されます\n",
    "\n",
    "  > Sending your request through Portkey ensures that all of the requests are logged by default\n",
    "\n",
    "* 各リクエストログには、`timestamp`（タイムスタンプ）、`model name`（モデル名）、`total cost`（総コスト）、`request time`（リクエスト時間）、`request json`（リクエストJSON）、`response json`（レスポンスJSON）、および追加のPortkey機能が含まれています\n",
    "\n",
    "  > Each request log contains `timestamp`, `model name`, `total cost`, `request time`, `request json`, `response json`, and additional Portkey features\n",
    "\n",
    "\n",
    "**トレーシング**\n",
    "\n",
    "> **Tracing**\n",
    "\n",
    "* トレースIDは各リクエストに添付され、Portkeyダッシュボードのログに表示されます\n",
    "\n",
    "  > Trace id is passed along with each request and is visibe on the logs on Portkey dashboard\n",
    "\n",
    "* また、必要であれば、各リクエストに**固有のトレースID**を設定することもできます\n",
    "\n",
    "  > You can also set a **distinct trace id** for each request if you want\n",
    "\n",
    "* ユーザーフィードバックをトレースIDにも追加することができます。[この件の詳細はこちら](https://docs.portkey.ai/key-features/feedback-api)\n",
    "\n",
    "  > You can append user feedback to a trace id as well. [More info on this here](https://docs.portkey.ai/key-features/feedback-api)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced LLMOps Features - Caching, Tagging, Retries | 高度なLLMOpsの機能 - キャッシング、タグ付け、リトライ\n",
    "\n",
    "ログ記録やトレーシングに加えて、Portkeyは既存のワークフローに生産機能を追加する追加の機能も提供します：\n",
    "\n",
    "> In addition to logging and tracing, Portkey provides more features that add production capabilities to your existing workflows:\n",
    "\n",
    "**キャッシング**\n",
    "\n",
    "> **Caching**\n",
    "\n",
    "以前に対応した顧客の問い合わせについては、OpenAIに再度送信する代わりにキャッシュから応答します。完全に一致する文字列または意味的に類似した文字列にマッチします。キャッシュを利用することでコストを削減し、レイテンシーを20倍短縮できます。\n",
    "\n",
    "> Respond to previously served customers queries from cache instead of sending them again to OpenAI. Match exact strings OR semantically similar strings. Cache can save costs and reduce latencies by 20x.\n",
    "\n",
    "**リトライ**\n",
    "\n",
    "> **Retries**\n",
    "\n",
    "失敗したAPIリクエストを自動的に**最大5回**再処理します。ネットワークの過負荷を防ぐために、リトライ試行間の間隔を広げる**指数バックオフ**戦略を使用します。\n",
    "\n",
    "> Automatically reprocess any unsuccessful API requests **`upto 5`** times. Uses an **`exponential backoff`** strategy, which spaces out retry attempts to prevent network overload.\n",
    "\n",
    "| 機能 | 設定キー | 値（タイプ） |\n",
    "| -- | -- | -- |\n",
    "| [🔁 自動リトライ](https://docs.portkey.ai/key-features/automatic-retries) | `retry_count` | `integer` \\[1,2,3,4,5] |\n",
    "| [🧠 キャッシュを有効にする](https://docs.portkey.ai/key-features/request-caching) | `cache` | `simple` または `semantic` |\n",
    "\n",
    "> | Feature | Config Key | Value (Type) |\n",
    "> | -- | -- | -- |\n",
    "> | [🔁 Automatic Retries](https://docs.portkey.ai/key-features/automatic-retries) | `retry_count` | `integer` \\[1,2,3,4,5] |\n",
    "> | [🧠 Enabling Cache](https://docs.portkey.ai/key-features/request-caching) | `cache` | `simple` OR `semantic` |\n",
    "\n",
    "**タグ付け**\n",
    "\n",
    "> **Tagging**\n",
    "\n",
    "事前に定義されたタグを使用して、各ユーザーのインタラクションを高い詳細度で追跡および監査します。\n",
    "\n",
    "> Track and audit ach user interaction in high detail with predefined tags.\n",
    "\n",
    "| タグ | 設定キー | 値（タイプ） |\n",
    "| -- | -- | -- |\n",
    "| ユーザータグ | `user` | `string` |\n",
    "| 組織タグ | `organisation` | `string` |\n",
    "| 環境タグ | `environment` | `string` |\n",
    "| プロンプトタグ（バージョン/ID/文字列） | `prompt` | `string` |\n",
    "\n",
    "> | Tag | Config Key | Value (Type) |\n",
    "> | -- | -- | -- |\n",
    "> | User Tag | `user` | `string` |\n",
    "> | Organisation Tag | `organisation` | `string` |\n",
    "> | Environment Tag | `environment` | `string` |\n",
    "> | Prompt Tag (version/id/string) | `prompt` | `string` |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Example With All Features | すべての機能を含むコード例\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = Portkey.Config(\n",
    "    # Mandatory\n",
    "    api_key=\"<PORTKEY_API_KEY>\",\n",
    "    # Cache Options\n",
    "    cache=\"semantic\",\n",
    "    cache_force_refresh=\"True\",\n",
    "    cache_age=1729,\n",
    "    # Advanced\n",
    "    retry_count=5,\n",
    "    trace_id=\"langchain_agent\",\n",
    "    # Metadata\n",
    "    environment=\"production\",\n",
    "    user=\"john\",\n",
    "    organisation=\"acme\",\n",
    "    prompt=\"Frost\",\n",
    ")\n",
    "\n",
    "llm = OpenAI(temperature=0.9, headers=headers)\n",
    "\n",
    "print(llm(\"Two roads diverged in the yellow woods\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}