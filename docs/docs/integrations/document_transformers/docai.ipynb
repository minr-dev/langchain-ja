{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b317191d",
   "metadata": {},
   "source": [
    "# Google Cloud Document AI | Google Cloud Document AI",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e6f94",
   "metadata": {},
   "source": [
    "Document AIは、ドキュメントの非構造化データを構造化データに変換し、理解、分析、そして利用を容易にするGoogle Cloudのドキュメント理解プラットフォームです。",
    "",
    "> Document AI is a document understanding platform from Google Cloud to transform unstructured data from documents into structured data, making it easier to understand, analyze, and consume.",
    "",
    "詳細はこちら：",
    "",
    "> Learn more:",
    "",
    "* [Document AI 概要](https://cloud.google.com/document-ai/docs/overview)",
    "  > [Document AI overview](https://cloud.google.com/document-ai/docs/overview)",
    "* [Document AIのビデオとラボ](https://cloud.google.com/document-ai/docs/videos)",
    "  > [Document AI videos and labs](https://cloud.google.com/document-ai/docs/videos)",
    "* [試してみてください！](https://cloud.google.com/document-ai/docs/drag-and-drop)",
    "  > [Try it!](https://cloud.google.com/document-ai/docs/drag-and-drop)",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184c0af8",
   "metadata": {},
   "source": [
    "このモジュールには、Google CloudのDocAIに基づいた`PDF`パーサーが含まれています。",
    "",
    "> The module contains a `PDF` parser based on DocAI from Google Cloud.",
    "",
    "このパーサーを使用するには、2つのライブラリをインストールする必要があります：",
    "",
    "> You need to install two libraries to use this parser:",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b2f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-cloud-documentai\n",
    "%pip install google-cloud-documentai-toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51946817-798c-4d11-abd6-db2ae53a0270",
   "metadata": {},
   "source": [
    "まず、Google Cloud Storage（GCS）バケットを設定し、こちらの説明に従ってご自身の光学文字認識（OCR）プロセッサを作成する必要があります：https://cloud.google.com/document-ai/docs/create-processor",
    "",
    "> First, you need to set up a Google Cloud Storage (GCS) bucket and create your own Optical Character Recognition (OCR) processor as described here: https://cloud.google.com/document-ai/docs/create-processor",
    "",
    "`GCS_OUTPUT_PATH`はGCS（Google Cloud Storage）上のフォルダへのパスであり（`gs://`で始まる必要があります）、`PROCESSOR_NAME`は`projects/PROJECT_NUMBER/locations/LOCATION/processors/PROCESSOR_ID`または`projects/PROJECT_NUMBER/locations/LOCATION/processors/PROCESSOR_ID/processorVersions/PROCESSOR_VERSION_ID`の形式である必要があります。これはプログラムによって取得することも、Google Cloud Consoleの`Processor details`タブにある`Prediction endpoint`セクションからコピーすることもできます。",
    "",
    "> The `GCS_OUTPUT_PATH` should be a path to a folder on GCS (starting with `gs://`) and a `PROCESSOR_NAME` should look like `projects/PROJECT_NUMBER/locations/LOCATION/processors/PROCESSOR_ID` or `projects/PROJECT_NUMBER/locations/LOCATION/processors/PROCESSOR_ID/processorVersions/PROCESSOR_VERSION_ID`. You can get it either programmatically or copy from the `Prediction endpoint` section of the `Processor details` tab in the Google Cloud Console.",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac85f7f3-3ef6-41d5-920a-b55f2939c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_OUTPUT_PATH = \"gs://BUCKET_NAME/FOLDER_PATH\"\n",
    "PROCESSOR_NAME = \"projects/PROJECT_NUMBER/locations/LOCATION/processors/PROCESSOR_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48438efb-9f0d-473b-a91c-9f1e29c2539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.blob_loaders import Blob\n",
    "from langchain.document_loaders.parsers import DocAIParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2bcca-1c0e-4888-b82d-15823ba57e60",
   "metadata": {},
   "source": [
    "次に、`DocAIParser`を作成します。",
    "",
    "> Now, create a `DocAIParser`.",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc0c65a-86c5-448d-8b21-2e564b1903b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = DocAIParser(\n",
    "    location=\"us\", processor_name=PROCESSOR_NAME, gcs_output_path=GCS_OUTPUT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5a3ff-650a-4ad3-a73a-395f86e4c9e1",
   "metadata": {},
   "source": [
    "この例では、公開されているGCSバケットにアップロードされたAlphabetの収益報告書を使用できます。",
    "",
    "> For this example, you can use an Alphabet earnings report that's uploaded to a public GCS bucket.",
    "",
    "[2022年第1四半期アルファベットの決算発表.pdf](https://storage.googleapis.com/cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2022Q1_alphabet_earnings_release.pdf)",
    "",
    "> [2022Q1\\_alphabet\\_earnings\\_release.pdf](https://storage.googleapis.com/cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2022Q1_alphabet_earnings_release.pdf)",
    "",
    "`lazy_parse()` メソッドにドキュメントを渡してください",
    "",
    "> Pass the document to the `lazy_parse()` method to",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "373cc18e-a311-4c8d-8180-47e4ade1d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = Blob(\n",
    "    path=\"gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/2022Q1_alphabet_earnings_release.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e4ee1-e07d-4c29-a120-4d56aae91859",
   "metadata": {},
   "source": [
    "1ページにつき1つのドキュメントがあり、合計で11個です。",
    "",
    "> We'll get one document per page, 11 in total:",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "343919f5-35d2-47fb-9790-de464649ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "docs = list(parser.lazy_parse(blob))\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104ae56-011b-4abe-ac07-e999c69494c5",
   "metadata": {},
   "source": [
    "blobを一つずつエンドツーエンドで解析することができます。多くのドキュメントがある場合、それらをまとめてバッチ処理し、さらには解析の結果を扱う作業から解析自体を分離することが、より良いアプローチかもしれません。",
    "",
    "> You can run end-to-end parsing of a blob one-by-one. If you have many documents, it might be a better approach to batch them together and maybe even detach parsing from handling the results of parsing.",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ecc1b99-5cef-47b0-a125-dbb2c41d2224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['projects/543079149601/locations/us/operations/16447136779727347991']\n"
     ]
    }
   ],
   "source": [
    "operations = parser.docai_parse([blob])\n",
    "print([op.operation.name for op in operations])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d24d63-c2c7-454c-9df3-2a9cf51309a6",
   "metadata": {},
   "source": [
    "操作が完了したかどうかを確認することができます：",
    "",
    "> You can check whether operations are finished:",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab11efb0-e514-4f44-9ba5-3d638a59c9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.is_running(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602ca0bc-080a-4a4e-a413-0e705aeab189",
   "metadata": {},
   "source": [
    "そして処理が完了したら、結果を解析することができます：",
    "",
    "> And when they're finished, you can parse the results:",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec1e6041-bc10-47d4-ba64-d09055c14f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.is_running(operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95d89da4-1c8a-413d-8473-ddd4a39375a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DocAIParsingResults(source_path='gs://vertex-pgt/examples/goog-exhibit-99-1-q1-2023-19.pdf', parsed_path='gs://vertex-pgt/test/run1/16447136779727347991/0')\n"
     ]
    }
   ],
   "source": [
    "results = parser.get_results(operations)\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5b606-1679-46c7-9577-4cf9bc93a752",
   "metadata": {},
   "source": [
    "そして、これでようやく解析結果からドキュメントを生成することができます：",
    "",
    "> And now we can finally generate Documents from parsed results:",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e8878d-889b-41ad-9500-2f772d38782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(parser.parse_from_results(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c59525fb-448d-444b-8f12-c4aea791e19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}