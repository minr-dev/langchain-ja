{
 "cells": [
  {
   "cell_type": "raw",
   "id": "df29b30a-fd27-4e08-8269-870df5631f9e",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 1\n",
    "title: Extraction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84edb4e",
   "metadata": {},
   "source": [
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/use_cases/extraction.ipynb)\n",
    "\n",
    "## Use case | ユースケース\n",
    "\n",
    "生のLLM生成物から構造化された出力を得ることは困難です。\n",
    "\n",
    "> Getting structured output from raw LLM generations is hard.\n",
    "\n",
    "例えば、特定のスキーマに従ってモデルの出力をフォーマットする必要がある場合を想定してください：\n",
    "\n",
    "> For example, suppose you need the model output formatted with a specific schema for:\n",
    "\n",
    "* データベースに挿入するための構造化された行の抽出\n",
    "  > Extracting a structured row to insert into a database\n",
    "* APIパラメータの抽出\n",
    "  > Extracting API parameters\n",
    "* ユーザーのクエリから異なる部分を抽出する（例えば、セマンティック検索とキーワード検索のために）\n",
    "  > Extracting different parts of a user query (e.g., for semantic vs keyword search)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178dbc59",
   "metadata": {},
   "source": [
    "![Image description](../../static/img/extraction.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f474d4",
   "metadata": {},
   "source": [
    "## Overview | 概要\n",
    "\n",
    "これには2つの主要なアプローチがあります：\n",
    "\n",
    "> There are two primary approaches for this:\n",
    "\n",
    "* `Functions`：一部のLLMは、LLMの応答から任意のエンティティを抽出する[関数](https://openai.com/blog/function-calling-and-other-api-updates)を呼び出すことができます。\n",
    "  > `Functions`: Some LLMs can call [functions](https://openai.com/blog/function-calling-and-other-api-updates) to extract arbitrary entities from LLM responses.\n",
    "\n",
    "* `Parsing`：[Output parsers](/docs/modules/model_io/output_parsers/)は、LLMの応答を構造化するクラスです。\n",
    "  > `Parsing`: [Output parsers](/docs/modules/model_io/output_parsers/) are classes that structure LLM responses.\n",
    "\n",
    "一部のLLM（例えばOpenAI）のみが関数をサポートしており、それらはパーサーよりも一般的です。\n",
    "\n",
    "> Only some LLMs support functions (e.g., OpenAI), and they are more general than parsers.\n",
    "\n",
    "パーサーは、提供されたスキーマ（例えば、人物の特定の属性）に列挙されているものを正確に抽出します。\n",
    "\n",
    "> Parsers extract precisely what is enumerated in a provided schema (e.g., specific attributes of a person).\n",
    "\n",
    "関数は、提供されたスキーマ以上のことを推測することができます（例えば、あなたが尋ねなかった人物の属性など）。\n",
    "\n",
    "> Functions can infer things beyond of a provided schema (e.g., attributes about a person that you did not ask for).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d89f21",
   "metadata": {},
   "source": [
    "## Quickstart | クイックスタート\n",
    "\n",
    "OpenAIの関数は、抽出を始める一つの方法です。\n",
    "\n",
    "> OpenAI functions are one way to get started with extraction.\n",
    "\n",
    "LLMの出力から抽出したいプロパティを指定するスキーマを定義してください。\n",
    "\n",
    "> Define a schema that specifies the properties we want to extract from the LLM output.\n",
    "\n",
    "その後、OpenAIの関数呼び出しを使用して、`create_extraction_chain`で目的のスキーマを抽出することができます。\n",
    "\n",
    "> Then, we can use `create_extraction_chain` to extract our desired schema using an OpenAI function call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ec7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain openai \n",
    "\n",
    "# Set env var OPENAI_API_KEY or load from a .env file:\n",
    "# import dotenv\n",
    "# dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e017ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Alex', 'height': 5, 'hair_color': 'blonde'},\n",
       " {'name': 'Claudia', 'height': 6, 'hair_color': 'brunette'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_extraction_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Schema\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"height\": {\"type\": \"integer\"},\n",
    "        \"hair_color\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"name\", \"height\"],\n",
    "}\n",
    "\n",
    "# Input\n",
    "inp = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\"\"\"\n",
    "\n",
    "# Run chain\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "chain = create_extraction_chain(schema, llm)\n",
    "chain.run(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7eb826",
   "metadata": {},
   "source": [
    "## Option 1: OpenAI functions | オプション 1: OpenAIの機能\n",
    "\n",
    "### Looking under the hood | エンジンルームを覗く\n",
    "\n",
    "`create_extraction_chain`を呼び出すときに何が起こっているのかを詳しく見ていきましょう。\n",
    "\n",
    "> Let's dig into what is happening when we call `create_extraction_chain`.\n",
    "\n",
    "[LangSmith trace](https://smith.langchain.com/public/72bc3205-7743-4ca6-929a-966a9d4c2a77/r)によると、入力文字列`inp`に`information_extraction`関数を呼び出していることがわかります。\n",
    "\n",
    "> The [LangSmith trace](https://smith.langchain.com/public/72bc3205-7743-4ca6-929a-966a9d4c2a77/r) shows that we call the function `information_extraction` on the input string, `inp`.\n",
    "\n",
    "![Image description](../../static/img/extraction_trace_function.png)\n",
    "\n",
    "`information_extraction` 関数は[こちら](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/openai_functions/extraction.py)で定義されており、辞書型のデータを返します。\n",
    "\n",
    "> This `information_extraction` function is defined [here](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/openai_functions/extraction.py) and returns a dict.\n",
    "\n",
    "モデルの出力で`dict`を確認できます：\n",
    "\n",
    "> We can see the `dict` in the model output:\n",
    "\n",
    "```\n",
    " {\n",
    "      \"info\": [\n",
    "        {\n",
    "          \"name\": \"Alex\",\n",
    "          \"height\": 5,\n",
    "          \"hair_color\": \"blonde\"\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"Claudia\",\n",
    "          \"height\": 6,\n",
    "          \"hair_color\": \"brunette\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "```\n",
    "\n",
    "`create_extraction_chain`は、[`JsonKeyOutputFunctionsParser`](https://github.com/langchain-ai/langchain/blob/f81e613086d211327b67b0fb591fd4d5f9a85860/libs/langchain/langchain/chains/openai_functions/extraction.py#L62)を使用して、生のLLM出力を私たちのためにパースします。\n",
    "\n",
    "> The `create_extraction_chain` then parses the raw LLM output for us using [`JsonKeyOutputFunctionsParser`](https://github.com/langchain-ai/langchain/blob/f81e613086d211327b67b0fb591fd4d5f9a85860/libs/langchain/langchain/chains/openai_functions/extraction.py#L62).\n",
    "\n",
    "これにより、上記のチェーンによって返されるJSONオブジェクトのリストが得られます：\n",
    "\n",
    "> This results in the list of JSON objects returned by the chain above:\n",
    "\n",
    "```\n",
    "[{'name': 'Alex', 'height': 5, 'hair_color': 'blonde'},\n",
    " {'name': 'Claudia', 'height': 6, 'hair_color': 'brunette'}]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb03138",
   "metadata": {},
   "source": [
    "### Multiple entity types | 複数のエンティティタイプ\n",
    "\n",
    "これをさらに拡張することができます。\n",
    "\n",
    "> We can extend this further.\n",
    "\n",
    "例えば、犬と人間を区別したいとしましょう。\n",
    "\n",
    "> Let's say we want to differentiate between dogs and people.\n",
    "\n",
    "各プロパティに`person_`と`dog_`の接頭辞を追加できます\n",
    "\n",
    "> We can add `person_` and `dog_` prefixes for each property\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01eae733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'person_name': 'Alex',\n",
       "  'person_height': 5,\n",
       "  'person_hair_color': 'blonde',\n",
       "  'dog_name': 'Frosty',\n",
       "  'dog_breed': 'labrador'},\n",
       " {'person_name': 'Claudia',\n",
       "  'person_height': 6,\n",
       "  'person_hair_color': 'brunette'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"person_name\": {\"type\": \"string\"},\n",
    "        \"person_height\": {\"type\": \"integer\"},\n",
    "        \"person_hair_color\": {\"type\": \"string\"},\n",
    "        \"dog_name\": {\"type\": \"string\"},\n",
    "        \"dog_breed\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"person_name\", \"person_height\"],\n",
    "}\n",
    "\n",
    "chain = create_extraction_chain(schema, llm)\n",
    "\n",
    "inp = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
    "Alex's dog Frosty is a labrador and likes to play hide and seek.\"\"\"\n",
    "\n",
    "chain.run(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205905c",
   "metadata": {},
   "source": [
    "### Unrelated entities | 関連性のないエンティティ\n",
    "\n",
    "`required: []`を使用すると、モデルは単一のエンティティ（人物または犬）に対して**のみ**人物の属性**または**犬の属性を返すことが可能です。\n",
    "\n",
    "> If we use `required: []`, we allow the model to return **only** person attributes or **only** dog attributes for a single entity (person or dog).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ff4ac7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'person_name': 'Alex', 'person_height': 5, 'person_hair_color': 'blonde'},\n",
       " {'person_name': 'Claudia',\n",
       "  'person_height': 6,\n",
       "  'person_hair_color': 'brunette'},\n",
       " {'dog_name': 'Willow', 'dog_breed': 'German Shepherd'},\n",
       " {'dog_name': 'Milo', 'dog_breed': 'border collie'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"person_name\": {\"type\": \"string\"},\n",
    "        \"person_height\": {\"type\": \"integer\"},\n",
    "        \"person_hair_color\": {\"type\": \"string\"},\n",
    "        \"dog_name\": {\"type\": \"string\"},\n",
    "        \"dog_breed\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [],\n",
    "}\n",
    "\n",
    "chain = create_extraction_chain(schema, llm)\n",
    "\n",
    "inp = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
    "Willow is a German Shepherd that likes to play with other dogs and can always be found playing with Milo, a border collie that lives close by.\"\"\"\n",
    "\n",
    "chain.run(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f3b958",
   "metadata": {},
   "source": [
    "### Extra information | 追加情報\n",
    "\n",
    "関数の力は（パーサーだけを使うのと比べて）、セマンティック抽出を行う能力にあります。\n",
    "\n",
    "> The power of functions (relative to using parsers alone) lies in the ability to perform semantic extraction.\n",
    "\n",
    "特に、スキーマで明示的に列挙されていないものを要求することができます。\n",
    "\n",
    "> In particular, `we can ask for things that are not explicitly enumerated in the schema`.\n",
    "\n",
    "犬に関する特定されていない追加情報が必要だと仮定しましょう。\n",
    "\n",
    "> Suppose we want unspecified additional information about dogs.\n",
    "\n",
    "非構造化抽出のためのプレースホルダー `dog_extra_info` を追加できます。\n",
    "\n",
    "> We can use add a placeholder for unstructured extraction, `dog_extra_info`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c7b26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'person_name': 'Alex', 'person_height': 5, 'person_hair_color': 'blonde'},\n",
       " {'person_name': 'Claudia',\n",
       "  'person_height': 6,\n",
       "  'person_hair_color': 'brunette'},\n",
       " {'dog_name': 'Willow',\n",
       "  'dog_breed': 'German Shepherd',\n",
       "  'dog_extra_info': 'likes to play with other dogs'},\n",
       " {'dog_name': 'Milo',\n",
       "  'dog_breed': 'border collie',\n",
       "  'dog_extra_info': 'lives close by'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"person_name\": {\"type\": \"string\"},\n",
    "        \"person_height\": {\"type\": \"integer\"},\n",
    "        \"person_hair_color\": {\"type\": \"string\"},\n",
    "        \"dog_name\": {\"type\": \"string\"},\n",
    "        \"dog_breed\": {\"type\": \"string\"},\n",
    "        \"dog_extra_info\": {\"type\": \"string\"},\n",
    "    },\n",
    "}\n",
    "\n",
    "chain = create_extraction_chain(schema, llm)\n",
    "chain.run(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a949c60",
   "metadata": {},
   "source": [
    "これにより、犬に関する追加情報が得られます。\n",
    "\n",
    "> This gives us additional information about the dogs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf71ddce",
   "metadata": {},
   "source": [
    "### Pydantic | Pydantic\n",
    "\n",
    "Pydanticは、Python用のデータ検証と設定管理ライブラリです。\n",
    "\n",
    "> Pydantic is a data validation and settings management library for Python.\n",
    "\n",
    "オブジェクトをインスタンス化する際に、自動的に検証される属性を持つデータクラスを作成することができます。\n",
    "\n",
    "> It allows you to create data classes with attributes that are automatically validated when you instantiate an object.\n",
    "\n",
    "型注釈を付けた属性を持つクラスを定義しましょう。\n",
    "\n",
    "> Lets define a class with attributes annotated with types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36a743b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Properties(person_name='Alex', person_height=5, person_hair_color='blonde', dog_breed=None, dog_name=None),\n",
       " Properties(person_name='Claudia', person_height=6, person_hair_color='brunette', dog_breed=None, dog_name=None)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "\n",
    "# Pydantic data class\n",
    "class Properties(BaseModel):\n",
    "    person_name: str\n",
    "    person_height: int\n",
    "    person_hair_color: str\n",
    "    dog_breed: Optional[str]\n",
    "    dog_name: Optional[str]\n",
    "\n",
    "\n",
    "# Extraction\n",
    "chain = create_extraction_chain_pydantic(pydantic_schema=Properties, llm=llm)\n",
    "\n",
    "# Run\n",
    "inp = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\"\"\"\n",
    "chain.run(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0351a",
   "metadata": {},
   "source": [
    "[トレース](https://smith.langchain.com/public/fed50ae6-26bb-4235-a254-e0b7a229d10f/r)からわかるように、上記のように`information_extraction`関数をPydanticスキーマと共に使用しています。\n",
    "\n",
    "> As we can see from the [trace](https://smith.langchain.com/public/fed50ae6-26bb-4235-a254-e0b7a229d10f/r), we use the function `information_extraction`, as above, with the Pydantic schema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9f121",
   "metadata": {},
   "source": [
    "## Option 2: Parsing | オプション 2: パース\n",
    "\n",
    "[Output parsers](/docs/modules/model_io/output_parsers/)は、言語モデルのレスポンスを構造化するのに役立つクラスです。\n",
    "\n",
    "> [Output parsers](/docs/modules/model_io/output_parsers/) are classes that help structure language model responses.\n",
    "\n",
    "上記の通り、これらは `create_extraction_chain` でのOpenAI関数呼び出しの出力を解析するために使用されます。\n",
    "\n",
    "> As shown above, they are used to parse the output of the OpenAI function calls in `create_extraction_chain`.\n",
    "\n",
    "しかし、それらは関数とは独立して使用することができます。\n",
    "\n",
    "> But, they can be used independent of functions.\n",
    "\n",
    "### Pydantic | Pydantic\n",
    "\n",
    "上記の通り、Pydanticデータクラスを基にした生成物を解析しましょう。\n",
    "\n",
    "> Just as a above, let's parse a generation based on a Pydantic data class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64650362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(person_name='Alex', person_height=5, person_hair_color='blonde', dog_breed=None, dog_name=None), Person(person_name='Claudia', person_height=6, person_hair_color='brunette', dog_breed=None, dog_name=None)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional, Sequence\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    ")\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    person_name: str\n",
    "    person_height: int\n",
    "    person_hair_color: str\n",
    "    dog_breed: Optional[str]\n",
    "    dog_name: Optional[str]\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: Sequence[Person]\n",
    "\n",
    "\n",
    "# Run\n",
    "query = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\"\"\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Run\n",
    "_input = prompt.format_prompt(query=query)\n",
    "model = OpenAI(temperature=0)\n",
    "output = model(_input.to_string())\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826899df",
   "metadata": {},
   "source": [
    "[LangSmith trace](https://smith.langchain.com/public/8e3aa858-467e-46a5-aa49-5db65f0a2b9a/r)を見ると、上記と同じ出力が得られることがわかります。\n",
    "\n",
    "> We can see from the [LangSmith trace](https://smith.langchain.com/public/8e3aa858-467e-46a5-aa49-5db65f0a2b9a/r) that we get the same output as above.\n",
    "\n",
    "![Image description](../../static/img/extraction_trace_function_2.png)\n",
    "\n",
    "私たちは、望むフォーマットでLLMが出力するよう指示するために、2ショットのプロンプトを提供していることがわかります。\n",
    "\n",
    "> We can see that we provide a two-shot prompt in order to instruct the LLM to output in our desired format.\n",
    "\n",
    "そして、もう少し作業をする必要があります：\n",
    "\n",
    "> And, we need to do a bit more work:\n",
    "\n",
    "* `Person`の複数のインスタンスを保持するクラスを定義する\n",
    "  > Define a class that holds multiple instances of `Person`\n",
    "* LLMの出力をPydanticクラスに明示的にパースする\n",
    "  > Explicitly parse the output of the LLM to the Pydantic class\n",
    "\n",
    "これは他のケースについても同様です。\n",
    "\n",
    "> We can see this for other cases, too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "837c350e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    ")\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Run\n",
    "_input = prompt.format_prompt(query=joke_query)\n",
    "model = OpenAI(temperature=0)\n",
    "output = model(_input.to_string())\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3601bde",
   "metadata": {},
   "source": [
    "見ての通り、`Joke` クラスからの出力は、私たちが最初に望んでいたスキーマである 'setup' と 'punchline' を守っています。\n",
    "\n",
    "> As we can see, we get an output of the `Joke` class, which respects our originally desired schema: 'setup' and 'punchline'.\n",
    "\n",
    "[LangSmith trace](https://smith.langchain.com/public/69f11d41-41be-4319-93b0-6d0eda66e969/r)を見ることで、内部で具体的に何が起こっているのかを正確に把握することができます。\n",
    "\n",
    "> We can look at the [LangSmith trace](https://smith.langchain.com/public/69f11d41-41be-4319-93b0-6d0eda66e969/r) to see exactly what is going on under the hood.\n",
    "\n",
    "![Image description](../../static/img/extraction_trace_joke.png)\n",
    "\n",
    "### Going deeper | さらに深く\n",
    "\n",
    "* [出力パーサー](/docs/modules/model_io/output_parsers/)のドキュメントには、特定のタイプ（例えば、リスト、日時、列挙型など）に対する様々なパーサーの例が含まれています。\n",
    "  > The [output parser](/docs/modules/model_io/output_parsers/) documentation includes various parser examples for specific types (e.g., lists, datetime, enum, etc).\n",
    "* 実験的な[Anthropic function calling](https://python.langchain.com/docs/integrations/chat/anthropic_functions)のサポートは、Anthropicチャットモデルに似た機能を提供します。\n",
    "  > The experimental [Anthropic function calling](https://python.langchain.com/docs/integrations/chat/anthropic_functions) support provides similar functionality to Anthropic chat models.\n",
    "* [LlamaCPP](https://python.langchain.com/docs/integrations/llms/llamacpp#grammars)は、カスタム文法を使用した制約付きデコーディングをネイティブにサポートしており、ローカルLLMを使用して構造化されたコンテンツを簡単に出力することが可能です。\n",
    "  > [LlamaCPP](https://python.langchain.com/docs/integrations/llms/llamacpp#grammars) natively supports constrained decoding using custom grammars, making it easy to output structured content using local LLMs\n",
    "* [JSONFormer](/docs/integrations/llms/jsonformer_experimental)は、JSONスキーマのサブセットを構造化してデコードするための別の方法を提供します。\n",
    "  > [JSONFormer](/docs/integrations/llms/jsonformer_experimental) offers another way for structured decoding of a subset of the JSON Schema.\n",
    "* [Kor](https://eyurtsev.github.io/kor/)は、スキーマと例をLLMに提供して抽出を行うことができる別のライブラリです。\n",
    "  > [Kor](https://eyurtsev.github.io/kor/) is another library for extraction where schema and examples can be provided to the LLM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab95ecf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
