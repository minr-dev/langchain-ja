{
 "cells": [
  {
   "cell_type": "raw",
   "id": "97e00fdb-f771-473f-90fc-d6038e19fd9a",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 3\n",
    "sidebar_class_name: hidden\n",
    "title: Agents\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c03f40-1328-412d-8a48-1db0cd481b77",
   "metadata": {},
   "source": [
    "エージェントの核心的なコンセプトは、一連のアクションを選択するために言語モデルを使用することです。チェーンでは、アクションのシーケンスはコード内でハードコードされています。エージェントでは、どのアクションを、どの順序で取るべきかを決定するために、言語モデルが推論エンジンとして使用されます。\n",
    "\n",
    "> The core idea of agents is to use a language model to choose a sequence of actions to take.\n",
    "> In chains, a sequence of actions is hardcoded (in code).\n",
    "> In agents, a language model is used as a reasoning engine to determine which actions to take and in which order.\n",
    "\n",
    "## Concepts | 概念\n",
    "\n",
    "ここにはいくつかの重要な要素があります：\n",
    "\n",
    "> There are several key components here:\n",
    "\n",
    "### Agent | エージェント\n",
    "\n",
    "これは次にどのステップを踏むかを決定する責任を持つチェーンです。これは言語モデルとプロンプトによって駆動されています。このチェーンへの入力は以下の通りです：\n",
    "\n",
    "> This is the chain responsible for deciding what step to take next.\n",
    "> This is powered by a language model and a prompt.\n",
    "> The inputs to this chain are:\n",
    "\n",
    "1. ツール: 利用可能なツールの説明\n",
    "\n",
    "   > Tools: Descriptions of available tools\n",
    "\n",
    "2. ユーザー入力：高水準の目的\n",
    "\n",
    "   > User input: The high level objective\n",
    "\n",
    "3. 中間ステップ：ユーザーの入力を達成するために以前に実行された（アクション、ツールの出力）のペア\n",
    "\n",
    "   > Intermediate steps: Any (action, tool output) pairs previously executed in order to achieve the user input\n",
    "\n",
    "\n",
    "出力は、次に取るべきアクション、またはユーザーに送信する最終的なレスポンスです（`AgentAction`または`AgentFinish`）。アクションは、ツールとそのツールに対する入力を指定します。\n",
    "\n",
    "> The output is the next action(s) to take or the final response to send to the user (`AgentAction`s or `AgentFinish`). An action specifies a tool and the input to that tool.\n",
    "\n",
    "異なるエージェントには、推論のための異なるプロンプトスタイル、入力のエンコーディング方法、出力のパース方法があります。組み込みエージェントの完全なリストについては、[エージェントタイプ](/docs/modules/agents/agent_types/)をご覧ください。また、カスタムエージェントを**簡単に構築することが可能です**。その方法については、下記の「はじめに」セクションで示しています。\n",
    "\n",
    "> Different agents have different prompting styles for reasoning, different ways of encoding inputs, and different ways of parsing the output.\n",
    "> For a full list of built-in agents see [agent types](/docs/modules/agents/agent_types/).\n",
    "> You can also **easily build custom agents**, which we show how to do in the Get started section below.\n",
    "\n",
    "### Tools | ツール\n",
    "\n",
    "ツールはエージェントが呼び出すことができる機能です。\n",
    "ツールに関する2つの重要な設計上の考慮事項があります：\n",
    "\n",
    "> Tools are functions that an agent can invoke.\n",
    "> There are two important design considerations around tools:\n",
    "\n",
    "1. エージェントに適切なツールへのアクセスを与える\n",
    "\n",
    "   > Giving the agent access to the right tools\n",
    "\n",
    "2. エージェントにとって最も役立つ方法でツールを説明する\n",
    "\n",
    "   > Describing the tools in a way that is most helpful to the agent\n",
    "\n",
    "\n",
    "両方をしっかりと考え抜かなければ、機能するエージェントを構築することはできません。エージェントに正しいツールセットへのアクセスを与えなければ、あなたが設定した目標を達成することは決してできません。ツールを適切に説明しなければ、エージェントはそれらを正しく使いこなす方法を知ることができません。\n",
    "\n",
    "> Without thinking through both, you won't be able to build a working agent.\n",
    "> If you don't give the agent access to a correct set of tools, it will never be able to accomplish the objectives you give it.\n",
    "> If you don't describe the tools well, the agent won't know how to use them properly.\n",
    "\n",
    "LangChainは幅広い組み込みツールを提供しており、また、独自のツールやカスタムの説明を定義することも容易です。組み込みツールの完全なリストについては、[ツール統合セクション](/docs/integrations/tools/)をご覧ください。\n",
    "\n",
    "> LangChain provides a wide set of built-in tools, but also makes it easy to define your own (including custom descriptions).\n",
    "> For a full list of built-in tools, see the [tools integrations section](/docs/integrations/tools/)\n",
    "\n",
    "### Toolkits | ツールキット\n",
    "\n",
    "多くの一般的なタスクにおいて、エージェントには関連するツールのセットが必要です。このためにLangChainはツールキットの概念を提供しており、これは特定の目的を達成するために必要な約3-5個のツールのグループです。例えば、GitHubツールキットには、GitHubのイシューを検索するツール、ファイルを読むツール、コメントを投稿するツールなどが含まれています。\n",
    "\n",
    "> For many common tasks, an agent will need a set of related tools.\n",
    "> For this LangChain provides the concept of toolkits - groups of around 3-5 tools needed to accomplish specific objectives.\n",
    "> For example, the GitHub toolkit has a tool for searching through GitHub issues, a tool for reading a file, a tool for commenting, etc.\n",
    "\n",
    "LangChainは、始めるための幅広いツールキットを提供しています。組み込まれているツールキットの完全なリストについては、[ツールキット統合セクション](/docs/integrations/toolkits/)をご覧ください。\n",
    "\n",
    "> LangChain provides a wide set of toolkits to get started.\n",
    "> For a full list of built-in toolkits, see the [toolkits integrations section](/docs/integrations/toolkits/)\n",
    "\n",
    "### AgentExecutor | AgentExecutor\n",
    "\n",
    "エージェントエグゼキュータは、エージェントのランタイムです。これは実際にエージェントを呼び出し、選択したアクションを実行し、アクションの出力をエージェントに渡し、そして繰り返します。擬似コードでは、大まかに次のようになります：\n",
    "\n",
    "> The agent executor is the runtime for an agent.\n",
    "> This is what actually calls the agent, executes the actions it chooses, passes the action outputs back to the agent, and repeats.\n",
    "> In pseudocode, this looks roughly like:\n",
    "\n",
    "```python\n",
    "next_action = agent.get_action(...)\n",
    "while next_action != AgentFinish:\n",
    "    observation = run(next_action)\n",
    "    next_action = agent.get_action(..., next_action, observation)\n",
    "return next_action\n",
    "```\n",
    "\n",
    "これは単純に見えるかもしれませんが、このランタイムがあなたに代わって処理してくれるいくつかの複雑な部分があります。これには以下のものが含まれます：\n",
    "\n",
    "> While this may seem simple, there are several complexities this runtime handles for you, including:\n",
    "\n",
    "1. エージェントが存在しないツールを選択した場合の対処方法\n",
    "\n",
    "   > Handling cases where the agent selects a non-existent tool\n",
    "\n",
    "2. ツールがエラーを出した場合の対処方法\n",
    "\n",
    "   > Handling cases where the tool errors\n",
    "\n",
    "3. エージェントがツールの呼び出しに解析できない出力を生成した場合の対処方法\n",
    "\n",
    "   > Handling cases where the agent produces output that cannot be parsed into a tool invocation\n",
    "\n",
    "4. すべてのレベル（エージェントの決定、ツールの呼び出し）におけるログ記録と可観測性は、標準出力および/または[LangSmith](/docs/langsmith)へ出力されます。\n",
    "\n",
    "   > Logging and observability at all levels (agent decisions, tool calls) to stdout and/or to [LangSmith](/docs/langsmith).\n",
    "\n",
    "\n",
    "### Other types of agent runtimes | その他の種類のエージェントランタイム\n",
    "\n",
    "`AgentExecutor` クラスは、LangChainによってサポートされる主要なエージェントランタイムです。しかし、私たちは他にも、より実験的なランタイムをサポートしています。これには以下のものが含まれます：\n",
    "\n",
    "> The `AgentExecutor` class is the main agent runtime supported by LangChain.\n",
    "> However, there are other, more experimental runtimes we also support.\n",
    "> These include:\n",
    "\n",
    "* [Plan-and-execute Agent](/docs/use_cases/more/agents/autonomous_agents/plan_and_execute)（計画と実行エージェント）\n",
    "\n",
    "  > [Plan-and-execute Agent](/docs/use_cases/more/agents/autonomous_agents/plan_and_execute)\n",
    "\n",
    "* [ベビーAGI](/docs/use_cases/more/agents/autonomous_agents/baby_agi)\n",
    "\n",
    "  > [Baby AGI](/docs/use_cases/more/agents/autonomous_agents/baby_agi)\n",
    "\n",
    "* [Auto GPT](/docs/use_cases/more/agents/autonomous_agents/autogpt)\n",
    "\n",
    "  > [Auto GPT](/docs/use_cases/more/agents/autonomous_agents/autogpt)\n",
    "\n",
    "\n",
    "また、以下で説明する方法に従って、独自のカスタム実行ロジックを作成することもできます。\n",
    "\n",
    "> You can also always create your own custom execution logic, which we show how to do below.\n",
    "\n",
    "## Get started | 始めましょう\n",
    "\n",
    "LangChain Expression Language (LCEL) を使ってエージェントフレームワークを深く理解するために、一からエージェントを構築しましょう。エージェント自体を構築し、カスタムツールを定義し、カスタムループでエージェントとツールを実行する必要があります。最後に、実行をより簡単にするための標準LangChain `AgentExecutor` の使用方法を紹介します。\n",
    "\n",
    "> To best understand the agent framework, lets build an agent from scratch using LangChain Expression Language (LCEL).\n",
    "> We'll need to build the agent itself, define custom tools, and run the agent and tools in a custom loop. At the end we'll show how to use the standard LangChain `AgentExecutor` to make execution easier.\n",
    "\n",
    "知っておくべきいくつかの重要な用語（およびスキーマ）：\n",
    "\n",
    "> Some important terminology (and schema) to know:\n",
    "\n",
    "1. `AgentAction`: これはエージェントが取るべきアクションを表すデータクラスです。`tool` プロパティ（呼び出すべきツールの名前）と `tool_input` プロパティ（そのツールへの入力）を持っています\n",
    "\n",
    "   > `AgentAction`: This is a dataclass that represents the action an agent should take. It has a `tool` property (which is the name of the tool that should be invoked) and a `tool_input` property (the input to that tool)\n",
    "\n",
    "2. `AgentFinish`: これはエージェントが処理を完了し、ユーザーに結果を返すべきことを示すデータクラスです。`return_values`というパラメータを持っており、これは返すべきデータを含む辞書です。しばしばこの辞書は`output`という一つのキーのみを持ち、そのキーは文字列です。そのため、多くの場合、この`output`キーのみが返されます。\n",
    "\n",
    "   > `AgentFinish`: This is a dataclass that signifies that the agent has finished and should return to the user. It has a `return_values` parameter, which is a dictionary to return. It often only has one key - `output` - that is a string, and so often it is just this key that is returned.\n",
    "\n",
    "3. `intermediate_steps`: これらは、過去のエージェントのアクションとそれに対応する出力を表しており、受け渡されていきます。エージェントがこれまでに行った作業を把握するために、これらを将来のイテレーションに渡すことが重要です。これは`List[Tuple[AgentAction, Any]]`として型付けされています。観測は最大限の柔軟性を持たせるために現在`Any`型として残されていますが、実際には、これは通常文字列です。\n",
    "\n",
    "   > `intermediate_steps`: These represent previous agent actions and corresponding outputs that are passed around. These are important to pass to future iteration so the agent knows what work it has already done. This is typed as a `List[Tuple[AgentAction, Any]]`. Note that observation is currently left as type `Any` to be maximally flexible. In practice, this is often a string.\n",
    "\n",
    "\n",
    "### Setup: LangSmith | セットアップ：LangSmith\n",
    "\n",
    "定義によれば、エージェントはユーザーに対する出力を返す前に、自己決定的かつ入力依存の一連のステップを踏みます。これにより、これらのシステムのデバッグは特に難しくなり、可観測性が特に重要になります。[LangSmith](/docs/langsmith)は、このような場合に特に有用です。\n",
    "\n",
    "> By definition, agents take a self-determined, input-dependent sequence of steps before returning a user-facing output. This makes debugging these systems particularly tricky, and observability particularly important. [LangSmith](/docs/langsmith) is especially useful for such cases.\n",
    "\n",
    "LangChainを使用して構築する際、組み込みエージェントやLCELで構築されたカスタムエージェントは、LangSmithで自動的にトレースされます。また、`AgentExecutor`を使用すれば、エージェントの計画ステップだけでなく、ツールの入力と出力も完全にトレースされます。\n",
    "\n",
    "> When building with LangChain, any built-in agent or custom agent built with LCEL will automatically be traced in LangSmith. And if we use the `AgentExecutor`, we'll get full tracing of not only the agent planning steps but also the tool inputs and outputs.\n",
    "\n",
    "LangSmithをセットアップするためには、以下の環境変数を設定する必要があります：\n",
    "\n",
    "> To set up LangSmith we just need set the following environment variables:\n",
    "\n",
    "```bash\n",
    "export LANGCHAIN_TRACING_V2=\"true\"\n",
    "export LANGCHAIN_API_KEY=\"<your-api-key>\"\n",
    "```\n",
    "\n",
    "### Define the agent | エージェントを定義する\n",
    "\n",
    "まず、私たちのエージェントを作成する必要があります。これは次に取る行動を決定するための連鎖的なプロセスを担当します。\n",
    "\n",
    "> We first need to create our agent.\n",
    "> This is the chain responsible for determining what action to take next.\n",
    "\n",
    "この例では、OpenAI Function Callingを使用してこのエージェントを作成します。\n",
    "**これは一般的にエージェントを作成する最も信頼性の高い方法です。**\n",
    "\n",
    "> In this example, we will use OpenAI Function Calling to create this agent.\n",
    "> **This is generally the most reliable way to create agents.**\n",
    "\n",
    "このガイドでは、カスタムツールにアクセスできるカスタムエージェントを構築します。実際の多くの使用例では、エージェントまたはツールのいずれかをカスタマイズする必要があります。この例を選んだのは、そのためです。単語の長さを計算するシンプルなツールを作成しましょう。これは、トークン化のためにLLMが間違えることがあるので、実際に役立ちます。最初は記憶機能なしで作成しますが、その後、記憶機能をどのように追加するかを示します。記憶機能は対話を可能にするために必要です。\n",
    "\n",
    "> For this guide, we will construct a custom agent that has access to a custom tool.\n",
    "> We are choosing this example because for most real world use cases you will NEED to customize either the agent or the tools.\n",
    "> We'll create a simple tool that computes the length of a word.\n",
    "> This is useful because it's actually something LLMs can mess up due to tokenization.\n",
    "> We will first create it WITHOUT memory, but we will then show how to add memory in.\n",
    "> Memory is needed to enable conversation.\n",
    "\n",
    "まず、エージェントを制御するために使用する言語モデルをロードしましょう。\n",
    "\n",
    "> First, let's load the language model we're going to use to control the agent.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89cf72b4-6046-4b47-8f27-5522d8cb8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe32b4-5b67-49fd-9f05-e94c46fbcc08",
   "metadata": {},
   "source": [
    "文字列「educa」の文字を数えるのに苦労していることがわかります。\n",
    "\n",
    "> We can see that it struggles to count the letters in the string \"educa\".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8eafbad-4084-4f27-b880-308430c44bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There are 6 letters in the word \"educa\".')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how many letters in the word educa?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f353a1-7b03-4692-ba6c-581d82de454b",
   "metadata": {},
   "source": [
    "次に、使用するいくつかのツールを定義しましょう。\n",
    "渡された単語の長さを計算する非常にシンプルなPython関数を書いてみましょう。\n",
    "\n",
    "> Next, let's define some tools to use.\n",
    "> Let's write a really simple Python function to calculate the length of a word that is passed in.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf6c6a6-4aa2-44fc-9d90-5981de827c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "tools = [get_word_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc3aeb-012f-4fe6-a980-2bd6d7612e1d",
   "metadata": {},
   "source": [
    "それでは、プロンプトを作成しましょう。\n",
    "OpenAI Function Callingはツール使用に特化してファインチューニングされているので、推論の方法や出力フォーマットについての指示はほとんど必要ありません。\n",
    "私たちは二つの入力変数、`input`と`agent_scratchpad`を用意するだけです。`input`はユーザーの目的を含む文字列であるべきです。`agent_scratchpad`は、以前のエージェントツールの呼び出しとそれに対応するツールの出力を含むメッセージのシーケンスであるべきです。\n",
    "\n",
    "> Now let us create the prompt.\n",
    "> Because OpenAI Function Calling is finetuned for tool usage, we hardly need any instructions on how to reason, or how to output format.\n",
    "> We will just have two input variables: `input` and `agent_scratchpad`. `input` should be a string containing the user objective. `agent_scratchpad` should be a sequence of messages that contains the previous agent tool invocations and the corresponding tool outputs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c98f77-d203-42cf-adcf-7da9ee93f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be29b821-b988-4921-8a1f-f04ec87e2863",
   "metadata": {},
   "source": [
    "エージェントはどのようにして使用可能なツールを知るのでしょうか？この場合、私たちは関数を別の引数として受け取り、それらの関数をいつ呼び出すべきかを特に訓練されているOpenAIの関数呼び出しLLMsに頼っています。\n",
    "\n",
    "> How does the agent know what tools it can use?\n",
    "> In this case we're relying on OpenAI function calling LLMs, which take functions as a separate argument and have been specifically trained to know when to invoke those functions.\n",
    "\n",
    "エージェントにツールを渡すためには、それらをOpenAI関数の形式にフォーマットし、モデルに渡すだけです。（関数を`bind`することにより、モデルが呼び出されるたびにそれらが渡されるようにしています。）\n",
    "\n",
    "> To pass in our tools to the agent, we just need to format them to the OpenAI function format and pass them to our model. (By `bind`-ing the functions, we're making sure that they're passed in each time the model is invoked.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5231ffd7-a044-4ebd-8e31-d1fe334334c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efbf02b-8686-4559-8b4c-c2be803cb475",
   "metadata": {},
   "source": [
    "これらの要素を組み合わせて、私たちはこれでエージェントを作成することができます。最後に2つのユーティリティ関数をインポートしましょう：1つは中間ステップ（エージェントのアクションとツールの出力のペア）をモデルに送信できる入力メッセージにフォーマットするコンポーネント、もう1つは出力メッセージをエージェントのアクションまたはエージェントの終了に変換するコンポーネントです。\n",
    "\n",
    "> Putting those pieces together, we can now create the agent.\n",
    "> We will import two last utility functions: a component for formatting intermediate steps (agent action, tool output pairs) to input messages that can be sent to the model, and a component for converting the output message into an agent action/agent finish.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f24d11-1133-48f3-ba70-fc3dd1da5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d55d2ad-6608-44ab-9949-b16ae8031f53",
   "metadata": {},
   "source": [
    "エージェントを準備できたので、早速試してみましょう！簡単な質問と空の中間ステップを渡して、どのような結果が返ってくるか見てみましょう：\n",
    "\n",
    "> Now that we have our agent, let's play around with it!\n",
    "> Let's pass in a simple question and empty intermediate steps and see what it returns:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01cb7adc-97b6-4713-890e-5d1ddeba909c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentActionMessageLog(tool='get_word_length', tool_input={'word': 'educa'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'educa'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"word\": \"educa\"\\n}', 'name': 'get_word_length'}})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"input\": \"how many letters in the word educa?\", \"intermediate_steps\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689ec562-3ec1-4b28-928b-c78c788aa097",
   "metadata": {},
   "source": [
    "それが `AgentAction` を取るために応答していることがわかります（実際には、完全なメッセージログを追跡する `AgentAction` のサブクラスである `AgentActionMessageLog` です）。\n",
    "\n",
    "> We can see that it responds with an `AgentAction` to take (it's actually an `AgentActionMessageLog` - a subclass of `AgentAction` which also tracks the full message log).\n",
    "\n",
    "LangSmithを設定していれば、シーケンス内の各ステップの入力と出力を検査することができるトレースが表示されます: https://smith.langchain.com/public/04110122-01a8-413c-8cd0-b4df6eefa4b7/r\n",
    "\n",
    "> If we've set up LangSmith, we'll see a trace that let's us inspect the input and output to each step in the sequence: https://smith.langchain.com/public/04110122-01a8-413c-8cd0-b4df6eefa4b7/r\n",
    "\n",
    "### Define the runtime | ランタイムを定義する\n",
    "\n",
    "これは最初のステップに過ぎません - これに対応するランタイムを書く必要があります。最もシンプルなランタイムは、エージェントを呼び出し、アクションを実行し、`AgentFinish`が返されるまでそのプロセスを繰り返すものです。以下でそのコードを書いてみましょう：\n",
    "\n",
    "> So this is just the first step - now we need to write a runtime for this.\n",
    "> The simplest one is just one that continuously loops, calling the agent, then taking the action, and repeating until an `AgentFinish` is returned.\n",
    "> Let's code that up below:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29bbf63b-f866-4b8c-aeea-2f9cffe70b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOL NAME: get_word_length\n",
      "TOOL INPUT: {'word': 'educa'}\n",
      "There are 5 letters in the word \"educa\".\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.agents import AgentFinish\n",
    "\n",
    "user_input = \"how many letters in the word educa?\"\n",
    "intermediate_steps = []\n",
    "while True:\n",
    "    output = agent.invoke(\n",
    "        {\n",
    "            \"input\": user_input,\n",
    "            \"intermediate_steps\": intermediate_steps,\n",
    "        }\n",
    "    )\n",
    "    if isinstance(output, AgentFinish):\n",
    "        final_result = output.return_values[\"output\"]\n",
    "        break\n",
    "    else:\n",
    "        print(f\"TOOL NAME: {output.tool}\")\n",
    "        print(f\"TOOL INPUT: {output.tool_input}\")\n",
    "        tool = {\"get_word_length\": get_word_length}[output.tool]\n",
    "        observation = tool.run(output.tool_input)\n",
    "        intermediate_steps.append((output, observation))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de8e688-fed4-4efc-a2bc-8d3c504dd764",
   "metadata": {},
   "source": [
    "わーい！動いてる。\n",
    "\n",
    "> Woo! It's working.\n",
    "\n",
    "### Using AgentExecutor | AgentExecutorの使用\n",
    "\n",
    "これを少し簡単にするために、`AgentExecutor` クラスをインポートして使用できます。これにより、上記のすべてが一つにまとめられ、エラーハンドリング、早期停止、トレーシング、その他の利便性を向上させる改善が加えられ、書く必要のあるセーフガードが減少します。\n",
    "\n",
    "> To simplify this a bit, we can import and use the `AgentExecutor` class.\n",
    "> This bundles up all of the above and adds in error handling, early stopping, tracing, and other quality-of-life improvements that reduce safeguards you need to write.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c94ee41-f146-403e-bd0a-5756a53d7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbd94a2-b456-45e6-835c-a33be3475119",
   "metadata": {},
   "source": [
    "さあ、試してみましょう！\n",
    "\n",
    "> Now let's test it out!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e1e64c7-627c-4713-82ca-8f6db3d9c8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThere are 5 letters in the word \"educa\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how many letters in the word educa?',\n",
       " 'output': 'There are 5 letters in the word \"educa\".'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how many letters in the word educa?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578aede-2ad2-4c15-832e-3e0a1660b342",
   "metadata": {},
   "source": [
    "トレースを見ると、エージェントの呼び出しやツールの起動が自動的に記録されていることがわかります：https://smith.langchain.com/public/957b7e26-bef8-4b5b-9ca3-4b4f1c96d501/r\n",
    "\n",
    "> And looking at the trace, we can see that all of our agent calls and tool invocations are automatically logged: https://smith.langchain.com/public/957b7e26-bef8-4b5b-9ca3-4b4f1c96d501/r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29c0705-b9bc-419f-aae4-974fc092faab",
   "metadata": {},
   "source": [
    "### Adding memory | メモリの追加\n",
    "\n",
    "素晴らしいことです - 私たちにはエージェントがいます！ しかし、このエージェントはステートレスで、以前のインタラクションについて何も記憶していません。これでは、フォローアップの質問を簡単にはできません。記憶機能を追加して、この問題を解決しましょう。\n",
    "\n",
    "> This is great - we have an agent!\n",
    "> However, this agent is stateless - it doesn't remember anything about previous interactions.\n",
    "> This means you can't ask follow up questions easily.\n",
    "> Let's fix that by adding in memory.\n",
    "\n",
    "これを行うためには、二つのことを行う必要があります：\n",
    "\n",
    "> In order to do this, we need to do two things:\n",
    "\n",
    "1. プロンプトにメモリ変数を格納するための場所を追加してください\n",
    "\n",
    "   > Add a place for memory variables to go in the prompt\n",
    "\n",
    "2. チャット履歴を記録しておく\n",
    "\n",
    "   > Keep track of the chat history\n",
    "\n",
    "\n",
    "まず、プロンプトにメモリースペースを追加しましょう。\n",
    "これを行うには、`\"chat_history\"` というキーを持つメッセージのためのプレースホルダーを追加します。\n",
    "新しいユーザー入力の上にこれを配置することに注意してください（会話の流れに沿って配置するためです）。\n",
    "\n",
    "> First, let's add a place for memory in the prompt.\n",
    "> We do this by adding a placeholder for messages with the key `\"chat_history\"`.\n",
    "> Notice that we put this ABOVE the new user input (to follow the conversation flow).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceef8c26-becc-4893-b55c-efcf52c4b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4f1e1b-695d-4b25-88aa-d46c015e6342",
   "metadata": {},
   "source": [
    "その後、チャット履歴を追跡するためのリストを設定できます\n",
    "\n",
    "> We can then set up a list to track the chat history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "935abfee-ab5d-4e9a-b33c-6a40a6fa4777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107b5dd-b934-48a0-a8c5-3b5bd76f2b98",
   "metadata": {},
   "source": [
    "それでは、全てをまとめましょう！\n",
    "\n",
    "> We can then put it all together!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24b094ff-bbea-45c4-8000-ed2b5de459a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ee9bd-20be-4ab7-b384-a5f0335e7611",
   "metadata": {},
   "source": [
    "実行中には、チャット履歴として入力と出力を追跡する必要があります\n",
    "\n",
    "> When running, we now need to track the inputs and outputs as chat history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f238022b-3348-45cd-bd6a-c6770b7dc600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThere are 5 letters in the word \"educa\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNo, \"educa\" is not a real word in English.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'is that a real word?',\n",
       " 'chat_history': [HumanMessage(content='how many letters in the word educa?'),\n",
       "  AIMessage(content='There are 5 letters in the word \"educa\".')],\n",
       " 'output': 'No, \"educa\" is not a real word in English.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = \"how many letters in the word educa?\"\n",
    "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input1),\n",
    "        AIMessage(content=result[\"output\"]),\n",
    "    ]\n",
    ")\n",
    "agent_executor.invoke({\"input\": \"is that a real word?\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba072cd-eb58-409d-83be-55c8110e37f0",
   "metadata": {},
   "source": [
    "LangSmithのトレースはこちらです：https://smith.langchain.com/public/1e1b7e07-3220-4a6c-8a1e-f04182a755b3/r\n",
    "\n",
    "> Here's the LangSmith trace: https://smith.langchain.com/public/1e1b7e07-3220-4a6c-8a1e-f04182a755b3/r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8b9127-758b-4dab-b093-2e6357dca3e6",
   "metadata": {},
   "source": [
    "## Next Steps | 次のステップ\n",
    "\n",
    "素晴らしい！あなたは最初のエンドツーエンドエージェントを実行しました。\n",
    "さらに詳しく学びたい場合は、以下のことができます：\n",
    "\n",
    "> Awesome! You've now run your first end-to-end agent.\n",
    "> To dive deeper, you can:\n",
    "\n",
    "* サポートされているさまざまな[エージェントの種類](/docs/modules/agents/agent_types/)をご覧ください\n",
    "\n",
    "  > Check out all the different [agent types](/docs/modules/agents/agent_types/) supported\n",
    "\n",
    "* [AgentExecutor](/docs/modules/agents/how_to/)のすべてのコントロールを学びましょう。\n",
    "\n",
    "  > Learn all the controls for [AgentExecutor](/docs/modules/agents/how_to/)\n",
    "\n",
    "* [ツール](/docs/modules/agents/tools/)の使い方と、すべての[ツールの統合](/docs/integrations/tools)を探求しましょう。\n",
    "\n",
    "  > Explore the how-to's of [tools](/docs/modules/agents/tools/) and all the [tool integrations](/docs/integrations/tools)\n",
    "\n",
    "* 私たちが提供する既製の[ツールキット](/docs/integrations/toolkits/)の完全なリストをご覧ください\n",
    "\n",
    "  > See a full list of all the off-the-shelf [toolkits](/docs/integrations/toolkits/) we provide\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe7160-7c82-48ba-a4d3-4426c62edd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}