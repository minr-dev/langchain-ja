{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclia Understanding | Nuclia Understanding\n",
    "\n",
    "> [Nuclia](https://nuclia.com)は、内部および外部のあらゆるソースからの非構造化データを自動的にインデックス化し、最適化された検索結果と生成的な回答を提供します。ビデオとオーディオの書き起こし、画像コンテンツの抽出、文書のパースが可能です。\n",
    ">\n",
    "> > [Nuclia](https://nuclia.com) automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.\n",
    "\n",
    "`Nuclia Understanding API`は、テキスト、ウェブページ、ドキュメント、オーディオ/ビデオコンテンツを含む非構造化データの処理をサポートしています。必要に応じて音声認識やOCRを使用して、どこにでもあるテキストを抽出し、エンティティを識別し、メタデータやPDF内の画像のような埋め込まれたファイル、ウェブリンクも抽出します。さらに、コンテンツの要約を提供します。\n",
    "\n",
    "> The `Nuclia Understanding API` supports the processing of unstructured data, including text, web pages, documents, and audio/video contents. It extracts all texts wherever it is (using speech-to-text or OCR when needed), it identifies entities, it aslo extracts metadata, embedded files (like images in a PDF), and web links. It also provides a summary of the content.\n",
    "\n",
    "`Nuclia Understanding API`を使用するためには、`Nuclia`アカウントが必要です。<https://nuclia.cloud>で無料でアカウントを作成し、その後[NUAキーを作成する](https://docs.nuclia.dev/docs/docs/using/understanding/intro)手順はこちらです。\n",
    "\n",
    "> To use the `Nuclia Understanding API`, you need to have a `Nuclia` account. You can create one for free at <https://nuclia.cloud>, and then [create a NUA key](https://docs.nuclia.dev/docs/docs/using/understanding/intro).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade protobuf\n",
    "#!pip install nucliadb-protos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"NUCLIA_ZONE\"] = \"<YOUR_ZONE>\"  # e.g. europe-1\n",
    "os.environ[\"NUCLIA_NUA_KEY\"] = \"<YOUR_API_KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.nuclia import NucliaUnderstandingAPI\n",
    "\n",
    "nua = NucliaUnderstandingAPI(enable_ml=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuclia Understanding APIにファイルをプッシュするには、`push`アクションを使用します。処理は非同期で行われるため、結果はファイルがプッシュされた順番とは異なる順序で返される可能性があります。そのため、結果を対応するファイルと照合するためには`id`を提供する必要があります。\n",
    "\n",
    "> You can push files to the Nuclia Understanding API using the `push` action. As the processing is done asynchronously, the results might be returned in a different order than the files were pushed. That is why you need to provide an `id` to match the results with the corresponding file.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nua.run({\"action\": \"push\", \"id\": \"1\", \"path\": \"./report.docx\"})\n",
    "nua.run({\"action\": \"push\", \"id\": \"2\", \"path\": \"./interview.mp4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON形式の結果が得られるまで、`pull`アクションをループ内で呼び出すことができるようになりました。\n",
    "\n",
    "> You can now call the `pull` action in a loop until you get the JSON-formatted result.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "pending = True\n",
    "data = None\n",
    "while pending:\n",
    "    time.sleep(15)\n",
    "    data = nua.run({\"action\": \"pull\", \"id\": \"1\", \"path\": None})\n",
    "    if data:\n",
    "        print(data)\n",
    "        pending = False\n",
    "    else:\n",
    "        print(\"waiting...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`async`モードでは一つのステップで実行することもできます。プッシュを行うだけで、結果がプルされるまで待機します。\n",
    "\n",
    "> You can also do it in one step in `async` mode, you only need to do a push, and it will wait until the results are pulled:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def process():\n",
    "    data = await nua.arun(\n",
    "        {\"action\": \"push\", \"id\": \"1\", \"path\": \"./talk.mp4\", \"text\": None}\n",
    "    )\n",
    "    print(data)\n",
    "\n",
    "\n",
    "asyncio.run(process())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieved information | 取得した情報\n",
    "\n",
    "Nucliaは以下の情報を返します：\n",
    "\n",
    "> Nuclia returns the following information:\n",
    "\n",
    "* ファイルのメタデータ\n",
    "\n",
    "  > file metadata\n",
    "\n",
    "* 抽出されたテキスト\n",
    "\n",
    "  > extracted text\n",
    "\n",
    "* 埋め込まれた画像内のテキストのような、ネストされたテキスト\n",
    "\n",
    "  > nested text (like text in an embedded image)\n",
    "\n",
    "* `enable_ml`が`True`に設定されている場合にのみ、要約\n",
    "\n",
    "  > a summary (only when `enable_ml` is set to `True`)\n",
    "\n",
    "* 段落と文の分割（それぞれの最初と最後の文字の位置によって定義され、ビデオやオーディオファイルの場合は開始時刻と終了時刻によっても定義される）\n",
    "\n",
    "  > paragraphs and sentences splitting (defined by the position of their first and last characters, plus start time and end time for a video or audio file)\n",
    "\n",
    "* 固有名詞：人物、日付、場所、組織など（`enable_ml`が`True`に設定されている場合のみ）\n",
    "\n",
    "  > named entities: people, dates, places, organizations, etc. (only when `enable_ml` is set to `True`)\n",
    "\n",
    "* リンク\n",
    "\n",
    "  > links\n",
    "\n",
    "* サムネイル\n",
    "\n",
    "  > a thumbnail\n",
    "\n",
    "* 埋め込まれたファイル\n",
    "\n",
    "  > embedded files\n",
    "\n",
    "* テキストのベクトル表現（`enable_ml`が`True`に設定されている場合のみ）\n",
    "\n",
    "  > the vector representations of the text (only when `enable_ml` is set to `True`)\n",
    "\n",
    "\n",
    "注意：\n",
    "\n",
    "> Note:\n",
    "\n",
    "生成されたファイル（サムネイル、抽出された埋め込みファイルなど）はトークンとして提供されます。これらは[`/processing/download` エンドポイント](https://docs.nuclia.dev/docs/api#operation/Download_binary_file_processing_download_get)を使用してダウンロードできます。\n",
    "\n",
    "> Generated files (thumbnail, extracted embedded files, etc.) are provided as a token. You can download them with the [`/processing/download` endpoint](https://docs.nuclia.dev/docs/api#operation/Download_binary_file_processing_download_get).\n",
    "\n",
    "また、任意のレベルで属性が特定のサイズを超えた場合、それはダウンロード可能なファイルに格納され、ドキュメント内では `{\"file\": {\"uri\": \"JWT_TOKEN\"}}` の形式のファイルポインターに置き換えられます。ルールとして、メッセージのサイズが100万文字を超えると、最も大きな部分がダウンロード可能なファイルに移動されます。最初に、圧縮プロセスはベクターを対象にします。それが不十分な場合、次に大規模なフィールドメタデータを対象にし、最終的には抽出されたテキストを対象にします。\n",
    "\n",
    "> Also at any level, if an attribute exceeds a certain size, it will be put in a downloadable file and will be replaced in the document by a file pointer. This will consist of `{\"file\": {\"uri\": \"JWT_TOKEN\"}}`. The rule is that if the size of the message is greater than 1000000 characters, the biggest parts will be moved to downloadable files. First, the compression process will target vectors. If that is not enough, it will target large field metadata, and finally it will target extracted text.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}