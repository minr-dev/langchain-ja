# Momento | モメント

> [Momento Cache](https://docs.momentohq.com/)は、即時の弾力性、スケールトゥーゼロ機能、そして驚異的な高速パフォーマンスを提供する、世界初の真にサーバーレスなキャッシングサービスです。
>
> > [Momento Cache](https://docs.momentohq.com/) is the world's first truly serverless caching service, offering instant elasticity, scale-to-zero
> > capability, and blazing-fast performance.
>
> [Momento Vector Index](https://docs.momentohq.com/vector-index)は、最も生産性が高く、使いやすく、完全にサーバーレスなベクターインデックスとして際立っています。
>
> > [Momento Vector Index](https://docs.momentohq.com/vector-index) stands out as the most productive, easiest-to-use, fully serverless vector index.
>
> どちらのサービスも、SDKを取得し、APIキーを入手し、コードに数行追加するだけで、すぐに使用開始できます。これらは合わせて、あなたのLLMデータニーズに対する包括的なソリューションを提供します。
>
> > For both services, simply grab the SDK, obtain an API key, input a few lines into your code, and you're set to go. Together, they provide a comprehensive solution for your LLM data needs.

このページでは、LangChain内で[Momento](https://gomomento.com)エコシステムを使用する方法について説明します。

> This page covers how to use the [Momento](https://gomomento.com) ecosystem within LangChain.

## Installation and Setup | インストールとセットアップ

* 無料アカウントに[こちら](https://console.momentohq.com)からサインアップして、APIキーを取得してください
  > Sign up for a free account [here](https://console.momentohq.com) to get an API key
* `pip install momento`でMomento Python SDKをインストールしてください
  > Install the Momento Python SDK with `pip install momento`

## Cache | キャッシュ

Momentoをサーバーレスで分散された低遅延キャッシュとして、LLMのプロンプトとレスポンスに使用してください。標準キャッシュは、どのような環境においてもMomentoユーザーの主要な使用ケースです。

> Use Momento as a serverless, distributed, low-latency cache for LLM prompts and responses. The standard cache is the primary use case for Momento users in any environment.

Momento Cacheをアプリケーションに統合するには：

> To integrate Momento Cache into your application:

```python
from langchain.cache import MomentoCache
```

次に、以下のコードで設定してください：

> Then, set it up with the following code:

```python
from datetime import timedelta
from momento import CacheClient, Configurations, CredentialProvider
from langchain.globals import set_llm_cache

# Instantiate the Momento client
cache_client = CacheClient(
    Configurations.Laptop.v1(),
    CredentialProvider.from_environment_variable("MOMENTO_API_KEY"),
    default_ttl=timedelta(days=1))

# Choose a Momento cache name of your choice
cache_name = "langchain"

# Instantiate the LLM cache
set_llm_cache(MomentoCache(cache_client, cache_name))
```

## Memory | メモリ

Momentoは、LLMの分散メモリストアとして使用することができます。

> Momento can be used as a distributed memory store for LLMs.

### Chat Message History Memory | チャットメッセージ履歴メモリ

チャットメッセージ履歴をメモリーストアとしてMomentoを使用する手順については、[このノートブック](/docs/integrations/memory/momento_chat_message_history)をご覧ください。

> See [this notebook](/docs/integrations/memory/momento_chat_message_history) for a walkthrough of how to use Momento as a memory store for chat message history.

## Vector Store | ベクターストア

Momento Vector Index（MVI）は、ベクトルストアとして使用できます。

> Momento Vector Index (MVI) can be used as a vector store.

ベクターストアとしてMVIを使用する方法の手順については、[このノートブック](/docs/integrations/vectorstores/momento_vector_index)をご覧ください。

> See [this notebook](/docs/integrations/vectorstores/momento_vector_index) for a walkthrough of how to use MVI as a vector store.
