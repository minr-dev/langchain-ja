# Logical Fallacy chain | 論理的誤謬の連鎖

この例では、モデルの出力から論理的誤謬を取り除く方法を示しています。

> This example shows how to remove logical fallacies from model output.

## Logical Fallacies | 論理的誤謬

`論理的誤謬`は、モデルの出力の妥当性を損なう可能性がある、誤った推論や虚偽の議論です。

> `Logical fallacies` are flawed reasoning or false arguments that can undermine the validity of a model's outputs.

例としては、循環論法、誤った二分法、人身攻撃などがあります。機械学習モデルは、正確性、困惑度、または損失のような特定の指標でうまく機能するように最適化されています。しかし、指標の最適化だけでは、論理的に健全な推論を保証するものではありません。

> Examples include circular reasoning, false
> dichotomies, ad hominem attacks, etc.  Machine learning models are optimized to perform well on specific metrics like accuracy, perplexity, or loss. However,
> optimizing for metrics alone does not guarantee logically sound reasoning.

言語モデルは、論理的に無効であるがもっともらしい議論を生成するために、推論の欠陥を利用することを学ぶことができます。モデルが誤謬に依存している場合、その出力は信頼できず、メトリクスで高いスコアを達成していたとしても信用できなくなります。ユーザーはそのような出力に依存すべきではありません。論理的誤謬を広めることは、誤情報を拡散し、ユーザーを混乱させ、モデルが製品やサービスに導入された際に害を及ぼす実際の結果につながる可能性があります。

> Language models can learn to exploit flaws in reasoning to generate plausible-sounding but logically invalid arguments.  When models rely on fallacies, their outputs become unreliable and untrustworthy, even if they achieve high scores on metrics. Users cannot depend on such outputs. Propagating logical fallacies can spread misinformation, confuse users, and lead to harmful real-world consequences when models are deployed in products or services.

論理的な欠陥を特に監視およびテストすることは、他の品質問題とは異なり、挑戦的です。これはパターンマッチングではなく、論理的な議論について推論することを必要とします。

> Monitoring and testing specifically for logical flaws is challenging unlike other quality issues. It requires reasoning about arguments rather than pattern matching.

したがって、モデル開発者は、メトリクスを最適化した後、積極的に論理的誤謬に対処することが重要です。因果モデリング、堅牢性テスト、バイアスの軽減などの特殊技術を用いることで、誤った推論を避けることができます。全体として、論理的な欠陥を放置することは、モデルを安全でなく、倫理的でないものにします。誤謬を排除することで、モデルの出力が論理的に妥当であり、人間の推論と一致していることを保証します。これにより、ユーザーの信頼を維持し、リスクを軽減します。

> Therefore, it is crucial that model developers proactively address logical fallacies after optimizing metrics. Specialized techniques like causal modeling, robustness testing, and bias mitigation can help avoid flawed reasoning.  Overall, allowing logical flaws to persist makes models less safe and ethical. Eliminating fallacies ensures model outputs remain logically valid and aligned with human reasoning. This maintains user trust and mitigates risks.

## Example | 例

```python
# Imports
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains.llm import LLMChain
from langchain_experimental.fallacy_removal.base import FallacyChain
```

```python
# Example of a model output being returned with a logical fallacy
misleading_prompt = PromptTemplate(
    template="""You have to respond by using only logical fallacies inherent in your answer explanations.

Question: {question}

Bad answer:""",
    input_variables=["question"],
)

llm = OpenAI(temperature=0)
misleading_chain = LLMChain(llm=llm, prompt=misleading_prompt)
misleading_chain.run(question="How do I know the earth is round?")
```

<CodeOutputBlock lang="python">

```
    'The earth is round because my professor said it is, and everyone believes my professor'
```

</CodeOutputBlock>

```python
fallacies = FallacyChain.get_fallacies(["correction"])
fallacy_chain = FallacyChain.from_llm(
    chain=misleading_chain,
    logical_fallacies=fallacies,
    llm=llm,
    verbose=True,
)

fallacy_chain.run(question="How do I know the earth is round?")
```

<CodeOutputBlock lang="python">

```


    > Entering new FallacyChain chain...
    Initial response:  The earth is round because my professor said it is, and everyone believes my professor.

    Applying correction...

    Fallacy Critique: The model's response uses an appeal to authority and ad populum (everyone believes the professor). Fallacy Critique Needed.

    Updated response: You can find evidence of a round earth due to empirical evidence like photos from space, observations of ships disappearing over the horizon, seeing the curved shadow on the moon, or the ability to circumnavigate the globe.


    > Finished chain.





    'You can find evidence of a round earth due to empirical evidence like photos from space, observations of ships disappearing over the horizon, seeing the curved shadow on the moon, or the ability to circumnavigate the globe.'
```

</CodeOutputBlock>
