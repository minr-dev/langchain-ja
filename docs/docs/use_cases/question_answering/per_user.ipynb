{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14d3fd06",
   "metadata": {},
   "source": [
    "# Per-User Retrieval | ユーザーごとの検索\n",
    "\n",
    "検索アプリを構築する際には、多くの場合、複数のユーザーを考慮して構築する必要があります。これは、一人のユーザーだけでなく、多くの異なるユーザーのデータを保存している可能性があり、ユーザー同士が互いのデータを見えないようにする必要があることを意味します。つまり、特定の情報のみを取得するように検索チェーンを設定できるようにする必要があります。これには通常、二つのステップが関わっています。\n",
    "\n",
    "> When building a retrieval app, you often have to build it with multiple users in mind. This means that you may be storing data not just for one user, but for many different users, and they should not be able to see eachother's data. This means that you need to be able to configure your retrieval chain to only retrieve certain information. This generally involves two steps.\n",
    "\n",
    "**ステップ 1: 使用しているリトリーバーが複数ユーザーをサポートしていることを確認してください**\n",
    "\n",
    "> **Step 1: Make sure the retriever you are using supports multiple users**\n",
    "\n",
    "現時点でLangChainには、この機能に対する統一されたフラグやフィルターは存在しません。むしろ、各ベクトルストアやリトリーバーはそれぞれ独自のものを持っており、それらは異なる名称（ネームスペース、マルチテナンシーなど）で呼ばれることがあります。ベクトルストアでは、これは通常、`similarity_search`実行時に渡されるキーワード引数として利用可能です。使用しているリトリーバーが複数ユーザーをサポートしているかどうか、そしてサポートしている場合、その使用方法を知るためには、ドキュメントやソースコードを確認してください。\n",
    "\n",
    "> At the moment, there is no unified flag or filter for this in LangChain. Rather, each vectorstore and retriever may have their own, and may be called different things (namespaces, multi-tenancy, etc). For vectorstores, this is generally exposed as a keyword argument that is passed in during `similarity_search`. By reading the documentation or source code, figure out whether the retriever you are using supports multiple users, and, if so, how to use it.\n",
    "\n",
    "注意：サポートされていない、またはドキュメント化されていないリトリバーに対して、複数ユーザー向けのドキュメントやサポートを追加することは、LangChainへの素晴らしい貢献方法です。\n",
    "\n",
    "> Note: adding documentation and/or support for multiple users for retrievers that do not support it (or document it) is a GREAT way to contribute to LangChain\n",
    "\n",
    "**ステップ 2: そのパラメータをチェーンの設定可能なフィールドに追加する**\n",
    "\n",
    "> **Step 2: Add that parameter as a configurable field for the chain**\n",
    "\n",
    "これにより、実行時にチェーンを簡単に呼び出し、関連するフラグを設定することができます。設定に関する詳細は、[このドキュメント](docs/expression_language/how_to/configure)をご覧ください。\n",
    "\n",
    "> This will let you easily call the chain and configure any relevant flags at runtime. See [this documentation](docs/expression_language/how_to/configure) for more information on configuration.\n",
    "\n",
    "**ステップ 3: 設定可能なフィールドを使ってチェーンを呼び出す**\n",
    "\n",
    "> **Step 3: Call the chain with that configurable field**\n",
    "\n",
    "実行時に、設定可能なフィールドを持つこのチェーンを呼び出すことができます。\n",
    "\n",
    "> Now, at runtime you can call this chain with configurable field.\n",
    "\n",
    "## Code Example | コード例\n",
    "\n",
    "コードでこれがどのように見えるかの具体的な例を見てみましょう。この例にはPineconeを使用します。\n",
    "\n",
    "> Let's see a concrete example of what this looks like in code. We will use Pinecone for this example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75823b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonchase/.pyenv/versions/3.10.1/envs/langchain/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7345de3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ce15571e-4e2f-44c9-98df-7e83f6f63095']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The environment should be the one specified next to the API key\n",
    "# in your Pinecone console\n",
    "pinecone.init(api_key=\"...\", environment=\"...\")\n",
    "index = pinecone.Index(\"test-example\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Pinecone(index, embeddings, \"text\")\n",
    "\n",
    "vectorstore.add_texts([\"i worked at kensho\"], namespace=\"harrison\")\n",
    "vectorstore.add_texts([\"i worked at facebook\"], namespace=\"ankush\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c11920",
   "metadata": {},
   "source": [
    "`namespace`の`pinecone`キーワード引数は、ドキュメントを分離するために使用できます\n",
    "\n",
    "> The pinecone kwarg for `namespace` can be used to separate documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c2a39fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='i worked at facebook')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will only get documents for Ankush\n",
    "vectorstore.as_retriever(search_kwargs={\"namespace\": \"ankush\"}).get_relevant_documents(\n",
    "    \"where did i work?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56393baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='i worked at kensho')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will only get documents for Harrison\n",
    "vectorstore.as_retriever(\n",
    "    search_kwargs={\"namespace\": \"harrison\"}\n",
    ").get_relevant_documents(\"where did i work?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae97ed",
   "metadata": {},
   "source": [
    "これで、質問応答に使用するチェーンを作成することができます。\n",
    "\n",
    "> We can now create the chain that we will use to do question-answering over\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62707b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import (\n",
    "    ConfigurableField,\n",
    "    RunnableBinding,\n",
    "    RunnableLambda,\n",
    "    RunnablePassthrough,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6778ffa",
   "metadata": {},
   "source": [
    "これは基本的な質問応答チェーンのセットアップです。\n",
    "\n",
    "> This is basic question-answering chain set up.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44a865f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72125166",
   "metadata": {},
   "source": [
    "ここでは、リトリーバーに設定可能なフィールドがあることを示しています。すべてのベクトルストアリトリーバーには`search_kwargs`というフィールドがあります。これはベクトルストア特有のフィールドを含む単なる辞書です。\n",
    "\n",
    "> Here we mark the retriever as having a configurable field. All vectorstore retrievers have `search_kwargs` as a field. This is just a dictionary, with vectorstore specific fields\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "babbadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "configurable_retriever = retriever.configurable_fields(\n",
    "    search_kwargs=ConfigurableField(\n",
    "        id=\"search_kwargs\",\n",
    "        name=\"Search Kwargs\",\n",
    "        description=\"The search kwargs to use\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d481b70",
   "metadata": {},
   "source": [
    "これで、設定可能なリトリバーを使用してチェーンを作成することができます\n",
    "\n",
    "> We can now create the chain using our configurable retriever\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "210b0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": configurable_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6458c3",
   "metadata": {},
   "source": [
    "これで、設定可能なオプションを持つチェーンを呼び出すことができます。`search_kwargs`は設定可能なフィールドのIDで、その値はPineconeで使用する検索のkwargsです。\n",
    "\n",
    "> We can now invoke the chain with configurable options. `search_kwargs` is the id of the configurable field. The value is the search kwargs to use for Pinecone\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a38037b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The user worked at Kensho.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    \"where did the user work?\",\n",
    "    config={\"configurable\": {\"search_kwargs\": {\"namespace\": \"harrison\"}}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ff4f5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The user worked at Facebook.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    \"where did the user work?\",\n",
    "    config={\"configurable\": {\"search_kwargs\": {\"namespace\": \"ankush\"}}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa0b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}