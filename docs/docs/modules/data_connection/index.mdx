---
sidebar_position: 1
sidebar_class_name: hidden
---

# Retrieval | 検索

多くのLLMアプリケーションには、モデルのトレーニングセットに含まれていないユーザー固有のデータが必要です。これを実現する主な方法は、Retrieval Augmented Generation（RAG）を通じてです。このプロセスでは、外部データが*検索*され、その後LLMが*生成*ステップを行う際に渡されます。

> Many LLM applications require user-specific data that is not part of the model's training set.
> The primary way of accomplishing this is through Retrieval Augmented Generation (RAG).
> In this process, external data is *retrieved* and then passed to the LLM when doing the *generation* step.

LangChainは、シンプルなものから複雑なものまで、RAGアプリケーションを構築するために必要な全ての要素を提供します。このドキュメントのセクションでは、*検索*ステップに関連するあらゆる内容を扱っています。例えば、データの取得がそれに含まれます。これは単純に思えるかもしれませんが、実は微妙に複雑です。このプロセスにはいくつかの重要なモジュールが含まれています。

> LangChain provides all the building blocks for RAG applications - from simple to complex.
> This section of the documentation covers everything related to the *retrieval* step - e.g. the fetching of the data.
> Although this sounds simple, it can be subtly complex.
> This encompasses several key modules.

![data\_connection\_diagram](/img/data_connection.jpg)

**[ドキュメントローダー](/docs/modules/data_connection/document_loaders/)**

> **[Document loaders](/docs/modules/data_connection/document_loaders/)**

**ドキュメントローダー**は、多様なソースからドキュメントを読み込む機能です。LangChainは100種類以上の異なるドキュメントローダーを提供するだけでなく、AirByteやUnstructuredのような、この分野の他の主要プロバイダーとの統合も提供しています。LangChainは、プライベートなS3バケットや公開ウェブサイトなど、あらゆる種類の場所からあらゆるタイプのドキュメント（HTML、PDF、コード）を読み込むための統合機能を提供しています。

> **Document loaders** load documents from many different sources.
> LangChain provides over 100 different document loaders as well as integrations with other major providers in the space,
> like AirByte and Unstructured.
> LangChain provides integrations to load all types of documents (HTML, PDF, code) from all types of locations (private S3 buckets, public websites).

**[ドキュメント変換器](/docs/modules/data_connection/document_transformers/)**

> **[Document transformers](/docs/modules/data_connection/document_transformers/)**

情報検索の鍵となる部分は、ドキュメントから関連する部分のみを取り出すことです。これには、ドキュメントを検索用に準備するための複数の変換ステップが含まれています。ここでの主要なステップの一つは、大きなドキュメントを小さなチャンクに分割（またはチャンキング）することです。LangChainは、この処理を行うための複数の変換アルゴリズムを提供するとともに、特定のドキュメントタイプ（コード、マークダウンなど）に最適化されたロジックも提供しています。

> A key part of retrieval is fetching only the relevant parts of documents.
> This involves several transformation steps to prepare the documents for retrieval.
> One of the primary ones here is splitting (or chunking) a large document into smaller chunks.
> LangChain provides several transformation algorithms for doing this, as well as logic optimized for specific document types (code, markdown, etc).

**[テキスト埋め込みモデル](/docs/modules/data_connection/text_embedding/)**

> **[Text embedding models](/docs/modules/data_connection/text_embedding/)**

検索のもう一つの重要な要素は、ドキュメントの埋め込みを作成することです。埋め込みはテキストの意味内容を捉え、類似したテキストの部分を迅速かつ効率的に見つけ出すことを可能にします。LangChainは、オープンソースからプロプライエタリAPIまで、25種類以上の異なる埋め込みプロバイダーと方法を統合しており、あなたのニーズに最適なものを選ぶことができます。LangChainは標準的なインターフェースを提供し、モデル間を容易に切り替えることができます。

> Another key part of retrieval is creating embeddings for documents.
> Embeddings capture the semantic meaning of the text, allowing you to quickly and
> efficiently find other pieces of a text that are similar.
> LangChain provides integrations with over 25 different embedding providers and methods,
> from open-source to proprietary API,
> allowing you to choose the one best suited for your needs.
> LangChain provides a standard interface, allowing you to easily swap between models.

**[ベクターストア](/docs/modules/data_connection/vectorstores/)**

> **[Vector stores](/docs/modules/data_connection/vectorstores/)**

埋め込みの台頭に伴い、これらの埋め込みを効率的に保存し検索するためのデータベースのサポートが必要とされています。LangChainは、オープンソースのローカルなものからクラウドホストのプロプライエタリなものまで、50種類以上の異なるベクトルストアとの統合を提供し、あなたのニーズに最適なものを選ぶことができます。LangChainは標準的なインターフェースを提供しており、ベクトルストア間で簡単に切り替えることができます。

> With the rise of embeddings, there has emerged a need for databases to support efficient storage and searching of these embeddings.
> LangChain provides integrations with over 50 different vectorstores, from open-source local ones to cloud-hosted proprietary ones,
> allowing you to choose the one best suited for your needs.
> LangChain exposes a standard interface, allowing you to easily swap between vector stores.

**[リトリーバー](/docs/modules/data_connection/retrievers/)**

> **[Retrievers](/docs/modules/data_connection/retrievers/)**

データがデータベースに入ったら、それを取り出す必要があります。LangChainは多様な検索アルゴリズムをサポートしており、私たちが最も価値を付加する部分の一つです。LangChainは、簡単に始められる基本的な方法、すなわちシンプルなセマンティック検索をサポートしています。しかし、私たちはこれに加えて、パフォーマンスを向上させるためのアルゴリズムのコレクションも追加しています。これには以下のものが含まれます：

> Once the data is in the database, you still need to retrieve it.
> LangChain supports many different retrieval algorithms and is one of the places where we add the most value.
> LangChain supports basic methods that are easy to get started - namely simple semantic search.
> However, we have also added a collection of algorithms on top of this to increase performance.
> These include:

* [Parent Document Retriever](/docs/modules/data_connection/retrievers/parent_document_retriever)：これにより、親ドキュメントごとに複数の埋め込みを作成することができ、小さなチャンクを検索しながらも、より大きなコンテキストを返すことが可能です。
  > [Parent Document Retriever](/docs/modules/data_connection/retrievers/parent_document_retriever): This allows you to create multiple embeddings per parent document, allowing you to look up smaller chunks but return larger context.
* [Self Query Retriever](/docs/modules/data_connection/retrievers/self_query)：ユーザーの質問には、単なる意味論的なものではなく、むしろメタデータフィルターとして表現されるべき何らかの論理を参照する内容がしばしば含まれます。Self-queryは、クエリに含まれる*意味論的*な部分とその他の*メタデータフィルター*を解析して分けることができます。
  > [Self Query Retriever](/docs/modules/data_connection/retrievers/self_query): User questions often contain a reference to something that isn't just semantic but rather expresses some logic that can best be represented as a metadata filter. Self-query allows you to parse out the *semantic* part of a query from other *metadata filters* present in the query.
* [Ensemble Retriever](/docs/modules/data_connection/retrievers/ensemble)：時には、複数の異なるソースから、または複数の異なるアルゴリズムを使用してドキュメントを取得したい場合があります。Ensemble Retrieverを使用すると、これを簡単に行うことができます。
  > [Ensemble Retriever](/docs/modules/data_connection/retrievers/ensemble): Sometimes you may want to retrieve documents from multiple different sources, or using multiple different algorithms. The ensemble retriever allows you to easily do this.
* その他にも！
  > And more!

**[インデキシング](/docs/modules/data_connection/indexing)**

> **[Indexing](/docs/modules/data_connection/indexing)**

LangChainの**インデキシング API**は、どんなソースからでもあなたのデータをベクターストアに同期させ、以下のことを支援します：

> The LangChain **Indexing API** syncs your data from any source into a vector store,
> helping you:

* ベクターストアに重複したコンテンツを書き込まないようにしてください
  > Avoid writing duplicated content into the vector store
* 変更されていないコンテンツの再執筆を避ける
  > Avoid re-writing unchanged content
* 変更されていないコンテンツに対して埋め込みを再計算しないようにしてください
  > Avoid re-computing embeddings over unchanged content

これにより、時間とお金の節約に加えて、ベクター検索の結果も向上するはずです。

> All of which should save you time and money, as well as improve your vector search results.
