# Clarifai | Clarifai

> [Clarifai](https://clarifai.com)は、2013年に設立された最初のディープラーニングプラットフォームの一つです。Clarifaiは、画像、ビデオ、テキスト、オーディオデータを扱うためのデータ探索、データラベリング、モデルトレーニング、評価、推論まで、AIライフサイクル全体をサポートするAIプラットフォームを提供しています。LangChainエコシステムにおいて、私たちの知る限り、ClarifaiはLLMs、エンベッディング、ベクターストアを一つのプロダクションスケールプラットフォームでサポートしている唯一のプロバイダーであり、LangChainの実装を運用化するための優れた選択肢です。
>
> > [Clarifai](https://clarifai.com) is one of first deep learning platforms having been founded in 2013. Clarifai provides an AI platform with the full AI lifecycle for data exploration, data labeling, model training, evaluation and inference around images, video, text and audio data. In the LangChain ecosystem, as far as we're aware, Clarifai is the only provider that supports LLMs, embeddings and a vector store in one production scale platform, making it an excellent choice to operationalize your LangChain implementations.

## Installation and Setup | インストールとセットアップ

* Python SDKをインストールする：
  > Install the Python SDK:

```bash
pip install clarifai
```

[Clarifaiアカウントにサインアップ](https://clarifai.com/signup)して、[セキュリティ設定](https://clarifai.com/settings/security)からClarifai APIにアクセスするための個人アクセストークンを取得し、環境変数(`CLARIFAI_PAT`)として設定してください。

> [Sign-up](https://clarifai.com/signup) for a Clarifai account, then get a personal access token to access the Clarifai API from your [security settings](https://clarifai.com/settings/security) and set it as an environment variable (`CLARIFAI_PAT`).

## Models | モデル

Clarifaiは、さまざまな用途に対応する数千ものAIモデルを提供しています。[こちら](https://clarifai.com/explore)でそれらを探索して、あなたの用途に最も適したモデルを見つけてください。これらのモデルには、OpenAI、Anthropic、Cohere、AI21など他のプロバイダーによって作成されたものや、Falcon、InstructorXLなどのオープンソースからの最先端のものも含まれており、あなたの製品に最高のAIを組み込むことができます。これらは、作成者のuser\_idによって、また私たちがアプリケーションと呼ぶプロジェクトによって整理されており、それらはapp\_idで識別されます。これらのIDは、model\_idとオプションでversion\_idに加えて必要になるので、あなたの用途に最適なモデルを見つけたら、これらのIDをすべてメモしておいてください。

> Clarifai provides 1,000s of AI models for many different use cases. You can [explore them here](https://clarifai.com/explore) to find the one most suited for your use case. These models include those created by other providers such as OpenAI, Anthropic, Cohere, AI21, etc. as well as state of the art from open source such as Falcon, InstructorXL, etc. so that you build the best in AI into your products. You'll find these organized by the creator's user\_id and into projects we call applications denoted by their app\_id. Those IDs will be needed in additional to the model\_id and optionally the version\_id, so make note of all these IDs once you found the best model for your use case!

また、画像、ビデオ、テキスト、オーディオ理解のための多様なモデルが存在することを踏まえると、これらのデータタイプを理解する専門家として様々なAIモデルを利用した興味深いAIエージェントを構築することが可能です。

> Also note that given there are many models for images, video, text and audio understanding, you can build some interested AI agents that utilize the variety of AI models as experts to understand those data types.

### LLMs | LLMs

ClarifaiプラットフォームでLLMsの選択肢を見つけるには、[こちら](https://clarifai.com/explore/models?filterData=%5B%7B%22field%22%3A%22model_type_id%22%2C%22value%22%3A%5B%22text-to-text%22%5D%7D%5D\&page=1\&perPage=24)でテキストからテキストへのモデルタイプを選択してください。

> To find the selection of LLMs in the Clarifai platform you can select the text to text model type [here](https://clarifai.com/explore/models?filterData=%5B%7B%22field%22%3A%22model_type_id%22%2C%22value%22%3A%5B%22text-to-text%22%5D%7D%5D\&page=1\&perPage=24).

```python
from langchain.llms import Clarifai
llm = Clarifai(pat=CLARIFAI_PAT, user_id=USER_ID, app_id=APP_ID, model_id=MODEL_ID)
```

詳細については、Clarifai LLMラッパーに関するドキュメントで、[詳細なウォークスルー](/docs/integrations/llms/clarifai)を提供しています。

> For more details, the docs on the Clarifai LLM wrapper provide a [detailed walkthrough](/docs/integrations/llms/clarifai).

### Text Embedding Models | テキスト埋め込みモデル

Clarifaiプラットフォームでテキスト埋め込みモデルの選択肢を見つけるには、[こちら](https://clarifai.com/explore/models?page=1\&perPage=24\&filterData=%5B%7B%22field%22%3A%22model_type_id%22%2C%22value%22%3A%5B%22text-embedder%22%5D%7D%5D)からテキスト埋め込みモデルタイプを選択してください。

> To find the selection of text embeddings models in the Clarifai platform you can select the text to embedding model type [here](https://clarifai.com/explore/models?page=1\&perPage=24\&filterData=%5B%7B%22field%22%3A%22model_type_id%22%2C%22value%22%3A%5B%22text-embedder%22%5D%7D%5D).

LangChainにはClarifai Embeddingモデルがあり、以下の方法でアクセスできます：

> There is a Clarifai Embedding model in LangChain, which you can access with:

```python
from langchain.embeddings import ClarifaiEmbeddings
embeddings = ClarifaiEmbeddings(pat=CLARIFAI_PAT, user_id=USER_ID, app_id=APP_ID, model_id=MODEL_ID)
```

詳細については、Clarifai Embeddingsラッパーに関するドキュメントで、[詳細なウォークスルー](/docs/integrations/text_embedding/clarifai)が提供されています。

> For more details, the docs on the Clarifai Embeddings wrapper provide a [detailed walkthrough](/docs/integrations/text_embedding/clarifai).

## Vectorstore | Vectorstore

ClarifaiのベクターDBは2016年に立ち上げられ、リアルタイムの検索クエリに対応するよう最適化されています。Clarifaiプラットフォーム内のワークフローを使用すると、データは自動的に埋め込みモデルによってインデックス化され、オプションで他のモデルも使用してその情報をDBで検索可能にします。DBへのクエリはベクターを介してだけでなく、メタデータの一致によるフィルタリング、他のAIが予測したコンセプト、さらには地理座標検索も行うことができます。アプリケーションを作成し、データタイプに適したベースワークフローを選択し、API（[こちらのドキュメント](https://docs.clarifai.com/api-guide/data/create-get-update-delete)に記載されている通り）またはclarifai.comのUIを通じてアップロードしてください。

> Clarifai's vector DB was launched in 2016 and has been optimized to support live search queries. With workflows in the Clarifai platform, you data is automatically indexed by am embedding model and optionally other models as well to index that information in the DB for search. You can query the DB not only via the vectors but also filter by metadata matches, other AI predicted concepts, and even do geo-coordinate search. Simply create an application, select the appropriate base workflow for your type of data, and upload it (through the API as [documented here](https://docs.clarifai.com/api-guide/data/create-get-update-delete) or the UIs at clarifai.com).

LangChainからも直接データを追加することができ、自動インデックス作成が行われます。これは、他のベクトルストアとは少し異なります。他のベクトルストアでは、そのコンストラクタに埋め込みモデルを提供し、LangChainがテキストからの埋め込みを取得してインデックスに書き込むように調整する必要があります。これはより便利なだけでなく、Clarifaiの分散クラウドを使用してバックグラウンドで全てのインデックス処理を行うことで、はるかにスケーラブルです。

> You can also add data directly from LangChain as well, and the auto-indexing will take place for you. You'll notice this is a little different than other vectorstores where you need to provide an embedding model in their constructor and have LangChain coordinate getting the embeddings from text and writing those to the index. Not only is it more convenient, but it's much more scalable to use Clarifai's distributed cloud to do all the index in the background.

```python
from langchain.vectorstores import Clarifai
clarifai_vector_db = Clarifai.from_texts(user_id=USER_ID, app_id=APP_ID, texts=texts, pat=CLARIFAI_PAT, number_of_docs=NUMBER_OF_DOCS, metadatas = metadatas)
```

詳細については、Clarifaiベクターストアに関するドキュメントで[詳細なウォークスルー](/docs/integrations/vectorstores/clarifai)を提供しています。

> For more details, the docs on the Clarifai vector store provide a [detailed walkthrough](/docs/integrations/vectorstores/clarifai).
