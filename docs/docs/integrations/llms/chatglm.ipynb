{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGLM | ChatGLM",
    "",
    "[ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)は、General Language Model (GLM) フレームワークに基づいたオープンなバイリンガル言語モデルで、62億のパラメータを持っています。量子化技術を用いることで、ユーザーは消費者グレードのグラフィックカード上でローカルにデプロイすることができます（INT4量子化レベルでは、GPUメモリは6GBのみが必要です）。",
    "",
    "> [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) is an open bilingual language model based on General Language Model (GLM) framework, with 6.2 billion parameters. With the quantization technique, users can deploy locally on consumer-grade graphics cards (only 6GB of GPU memory is required at the INT4 quantization level).",
    "",
    "[ChatGLM2-6B](https://github.com/THUDM/ChatGLM2-6B)は、オープンソースのバイリンガル（中国語-英語）チャットモデルChatGLM-6Bの第二世代バージョンです。初代モデルのスムーズな会話の流れと低い導入のハードルを維持しつつ、より良いパフォーマンス、より長いコンテキスト、より効率的な推論といった新機能を導入しています。",
    "",
    "> [ChatGLM2-6B](https://github.com/THUDM/ChatGLM2-6B) is the second-generation version of the open-source bilingual (Chinese-English) chat model ChatGLM-6B. It retains the smooth conversation flow and low deployment threshold of the first-generation model, while introducing the new features like better performance, longer context and more efficient inference.",
    "",
    "この例では、テキスト補完のためにLangChainを使用してChatGLM2-6B Inferenceと対話する方法について説明します。ChatGLM-6BとChatGLM2-6Bは同じAPI仕様を持っているので、この例はどちらにも適用可能です。",
    "",
    "> This example goes over how to use LangChain to interact with ChatGLM2-6B Inference for text completion.",
    "> ChatGLM-6B and ChatGLM2-6B has the same api specs, so this example should work with both.",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import ChatGLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{question}\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default endpoint_url for a local deployed ChatGLM api server\n",
    "endpoint_url = \"http://127.0.0.1:8000\"\n",
    "\n",
    "# direct access endpoint in a proxied environment\n",
    "# os.environ['NO_PROXY'] = '127.0.0.1'\n",
    "\n",
    "llm = ChatGLM(\n",
    "    endpoint_url=endpoint_url,\n",
    "    max_token=80000,\n",
    "    history=[\n",
    "        [\"我将从美国到中国来旅游，出行前希望了解中国的城市\", \"欢迎问我任何问题。\"]\n",
    "    ],\n",
    "    top_p=0.9,\n",
    "    model_kwargs={\"sample_model_args\": False},\n",
    ")\n",
    "\n",
    "# turn on with_history only when you want the LLM object to keep track of the conversation history\n",
    "# and send the accumulated context to the backend model api, which make it stateful. By default it is stateless.\n",
    "# llm.with_history = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGLM payload: {'prompt': '北京和上海两座城市有什么不同？', 'temperature': 0.1, 'history': [['我将从美国到中国来旅游，出行前希望了解中国的城市', '欢迎问我任何问题。']], 'max_length': 80000, 'top_p': 0.9, 'sample_model_args': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'北京和上海是中国的两个首都，它们在许多方面都有所不同。\\n\\n北京是中国的政治和文化中心，拥有悠久的历史和灿烂的文化。它是中国最重要的古都之一，也是中国历史上最后一个封建王朝的都城。北京有许多著名的古迹和景点，例如紫禁城、天安门广场和长城等。\\n\\n上海是中国最现代化的城市之一，也是中国商业和金融中心。上海拥有许多国际知名的企业和金融机构，同时也有许多著名的景点和美食。上海的外滩是一个历史悠久的商业区，拥有许多欧式建筑和餐馆。\\n\\n除此之外，北京和上海在交通和人口方面也有很大差异。北京是中国的首都，人口众多，交通拥堵问题较为严重。而上海是中国的商业和金融中心，人口密度较低，交通相对较为便利。\\n\\n总的来说，北京和上海是两个拥有独特魅力和特点的城市，可以根据自己的兴趣和时间来选择前往其中一座城市旅游。'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"北京和上海两座城市有什么不同？\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}