# Anthropic | アントロピック

Anthropicモデルに関連するすべての機能。

> All functionality related to Anthropic models.

[Anthropic](https://www.anthropic.com/)はAIの安全性と研究を行う会社であり、Claudeの開発者です。
このページでは、AnthropicのモデルとLangChainの間のすべての統合について説明しています。

> [Anthropic](https://www.anthropic.com/) is an AI safety and research company, and is the creator of Claude.
> This page covers all integrations between Anthropic models and LangChain.

## Prompting Overview | プロンプトの概要

Claudeはチャットベースのモデルで、会話データに基づいてトレーニングされています。しかし、それはテキストベースのAPIであり、単一の文字列を入力として受け取ります。このAPIは特定の形式の文字列を期待しています。これは、ユーザーがその形式を保証する必要があることを意味します。LangChainは、あなたが書いたプロンプトが - 文字列としても、メッセージのリストとしても - 正しくフォーマットされるようにするためのいくつかのユーティリティとヘルパー関数を提供しています。

> Claude is chat-based model, meaning it is trained on conversation data.
> However, it is a text based API, meaning it takes in single string.
> It expects this string to be in a particular format.
> This means that it is up the user to ensure that is the case.
> LangChain provides several utilities and helper functions to make sure prompts that you write -
> whether formatted as a string or as a list of messages - end up formatted correctly.

具体的には、Claudeは、人間のユーザー（`Human:`）とAIアシスタント（`Assistant:`）の間の進行中の対話の一部として、アシスタントの役割のテキストを補完するように訓練されています。APIを通じて送信されるプロンプトには、\`

Human:`と`

Assistant:`が誰が話しているかを示すシグナルとして含まれている必要があります。最終ターンは常に`

Assistant:`でなければならず、入力文字列の最後に`

Human:\` があってはなりません。

> Specifically, Claude is trained to fill in text for the Assistant role as part of an ongoing dialogue
> between a human user (`Human:`) and an AI assistant (`Assistant:`). Prompts sent via the API must contain
> `\n\nHuman:` and `\n\nAssistant:` as the signals of who's speaking.
> The final turn must always be `\n\nAssistant:` - the input string cannot have `\n\nHuman:` as the final role.

Claudeはチャットベースですが、文字列を入力として受け付けるため、LangChainの`ChatModel`または`LLM`として扱うことができます。これはLangChainに`ChatAnthropic`と`Anthropic`の2つのラッパーがあることを意味しています。一般的には、`ChatAnthropic`ラッパーを使用し、プロンプトを`ChatMessage`としてフォーマットすることをお勧めします（これについては以下で例を示します）。これは、プロンプトを一般的な形式で保持し、必要に応じて他のモデルでも簡単に使用できるようにするためです。しかし、プロンプトをより細かく制御したい場合は、`Anthropic`ラッパーを使用することができます - これについても例を示します。ただし、`Anthropic`ラッパーは非推奨であり、`ChatAnthropic`を使用してより汎用的な方法で全ての機能を実現することができます。

> Because Claude is chat-based but accepts a string as input, it can be treated as either a LangChain `ChatModel` or `LLM`.
> This means there are two wrappers in LangChain - `ChatAnthropic` and `Anthropic`.
> It is generally recommended to use the `ChatAnthropic` wrapper, and format your prompts as `ChatMessage`s (we will show examples of this below).
> This is because it keeps your prompt in a general format that you can easily then also use with other models (should you want to).
> However, if you want more fine-grained control over the prompt, you can use the `Anthropic` wrapper - we will show and example of this as well.
> The `Anthropic` wrapper however is deprecated, as all functionality can be achieved in a more generic way using `ChatAnthropic`.

## Prompting Best Practices | プロンプトのベストプラクティス

Anthropicのモデルは、OpenAIのモデルと比較して、いくつかのプロンプトにおけるベストプラクティスが多くあります。

> Anthropic models have several prompting best practices compared to OpenAI models.

**システムメッセージはありません**

> **No System Messages**

Anthropicモデルは「システムメッセージ」という概念を学習していません。私たちはAnthropicチームと協力して、それらをある程度適切に扱う方法（`admin`タグを持つHumanメッセージ）を考え出しましたが、これは大きな抜け道であり、システムメッセージの使用は推奨されません。

> Anthropic models are not trained on the concept of a "system message".
> We have worked with the Anthropic team to handle them somewhat appropriately (a Human message with an `admin` tag)
> but this is largely a hack and it is recommended that you do not use system messages.

**AIメッセージは続行できます**

> **AI Messages Can Continue**

Claudeからの補完は、文字列の最後のテキストを続けるもので、それによってClaudeの出力をさらに制御できます。例えば、このようなプロンプトでClaudeに言葉を与えることができます：

> A completion from Claude is a continuation of the last text in the string which allows you further control over Claude's output.
> For example, putting words in Claude's mouth in a prompt like this:

人間: クマについての冗談を教えて

アシスタント: 歯がないクマを何と呼ぶ？

> `\n\nHuman: Tell me a joke about bears\n\nAssistant: What do you call a bear with no teeth?`

これにより、全く新しいアシスタントメッセージで異なるランダムな熊のジョークが返されるのではなく、`A gummy bear!` のような完了メッセージが返されます。

> This will return a completion like this `A gummy bear!` instead of a whole new assistant message with a different random bear joke.

## `ChatAnthropic` | ChatAnthropic

`ChatAnthropic`はLangChainの`ChatModel`のサブクラスであり、`ChatPromptTemplate`と最も適切に連携することを意味します。
このラッパーは、以下のコードでインポートすることができます：

> `ChatAnthropic` is a subclass of LangChain's `ChatModel`, meaning it works best with `ChatPromptTemplate`.
> You can import this wrapper with the following code:

```
from langchain.chat_models import ChatAnthropic
model = ChatAnthropic()
```

ChatModelsを使用する際には、プロンプトを`ChatPromptTemplate`として設計することが推奨されます。
以下にその例を示します：

> When working with ChatModels, it is preferred that you design your prompts as `ChatPromptTemplate`s.
> Here is an example below of doing that:

```
from langchain.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful chatbot"),
    ("human", "Tell me a joke about {topic}"),
])
```

次に、これを以下のようにチェーンで使用できます：

> You can then use this in a chain as follows:

```
chain = prompt | model
chain.invoke({"topic": "bears"})
```

プロンプトが内部で実際にどのようにフォーマットされているのか、知りたいですか？以下のコードを実行することでそれを確認できます。

> How is the prompt actually being formatted under the hood? We can see that by running the following code

```
prompt_value = prompt.format_prompt(topic="bears")
model.convert_prompt(prompt_value)
```

これにより、以下のフォーマットされた文字列が生成されます：

> This produces the following formatted string:

```
'\n\nYou are a helpful chatbot\n\nHuman: Tell me a joke about bears\n\nAssistant:'
```

内部的には、LangChainは`SystemMessage`に接頭辞や接尾辞を追加していないことがわかります。これは、Anthropicが`SystemMessage`の概念を持っていないためです。Anthropicは、すべてのプロンプトがアシスタントのメッセージで終わることを要求します。つまり、最後のメッセージがアシスタントのメッセージでない場合、自動的に`Assistant:`という接尾辞が挿入されるということです。

> We can see that under the hood LangChain is not appending any prefix/suffix to `SystemMessage`'s. This is because Anthropic has no concept of `SystemMessage`.
> Anthropic requires all prompts to end with assistant messages. This means if the last message is not an assistant message, the suffix `Assistant:` will automatically be inserted.

もし通常のPromptTemplate（単一の文字列で動作するもの）を使用することにした場合、何が起こるか見てみましょう：

> If you decide instead to use a normal PromptTemplate (one that just works on a single string) let's take a look at
> what happens:

```
from langchain.prompts import PromptTemplate

prompt = PromptTemplate.from_template("Tell me a joke about {topic}")
prompt_value = prompt.format_prompt(topic="bears")
model.convert_prompt(prompt_value)
```

これにより、以下のフォーマットされた文字列が生成されます：

> This produces the following formatted string:

```
'\n\nHuman: Tell me a joke about bears\n\nAssistant:'
```

自動的にHumanとAssistantのタグが追加されていることがわかります。内部で何が起こっているのでしょうか？まず、文字列が単一のHumanメッセージに変換されます。これは一般的な処理です（`ChatModel`のサブクラスを使用しているため）。次に、上記の例と同様に、空のAssistantメッセージが追加されているのです。これはAnthropic特有の仕組みです。

> We can see that it automatically adds the Human and Assistant tags.
> What is happening under the hood?
> First: the string gets converted to a single human message. This happens generically (because we are using a subclass of `ChatModel`).
> Then, similarly to the above example, an empty Assistant message is getting appended.
> This is Anthropic specific.

## \[Deprecated] `Anthropic` | \[非推奨] `Anthropic`

この`Anthropic`ラッパーは`LLM`からサブクラス化されています。
次のようにインポートできます：

> This `Anthropic` wrapper is subclassed from `LLM`.
> We can import it with:

```
from langchain.llms import Anthropic
model = Anthropic()
```

このモデルクラスは通常のPromptTemplatesで動作するように設計されています。その一例を以下に示します：

> This model class is designed to work with normal PromptTemplates. An example of that is below:

```
prompt = PromptTemplate.from_template("Tell me a joke about {topic}")
chain = prompt | model
chain.invoke({"topic": "bears"})
```

プロンプトテンプレートが内部でどのように機能しているのか見てみましょう！

> Let's see what is going on with the prompt templating under the hood!

```
prompt_value = prompt.format_prompt(topic="bears")
model.convert_prompt(prompt_value)
```

これにより、以下が出力されます

> This outputs the following

```
'\n\nHuman: Tell me a joke about bears\n\nAssistant: Sure, here you go:\n'
```

文字列の先頭に「Human」というタグが追加され、最後に「\n\nAssistant: Sure, here you go:」で終わることに注意してください。「Sure, here you go」はAnthropicチームによって意図的に追加されたものです。

> Notice that it adds the Human tag at the start of the string, and then finishes it with `\n\nAssistant: Sure, here you go:`.
> The extra `Sure, here you go` was added on purpose by the Anthropic team.

プロンプトに直接それらの記号が含まれていたらどうなりますか？

> What happens if we have those symbols in the prompt directly?

```
prompt = PromptTemplate.from_template("Human: Tell me a joke about {topic}")
prompt_value = prompt.format_prompt(topic="bears")
model.convert_prompt(prompt_value)
```

これにより出力されます：

> This outputs:

```
'\n\nHuman: Tell me a joke about bears'
```

特殊トークンの使用を試みているユーザーを検出すると、フォーマットを行わないようにしていることがわかります。

> We can see that we detect that the user is trying to use the special tokens, and so we don't do any formatting.

## `ChatAnthropicMessages` (Beta) | `ChatAnthropicMessages`（ベータ版）

`ChatAnthropicMessages`は、Anthropicの新しいMessages APIのベータ版を使用しています。

> `ChatAnthropicMessages` uses the beta release of Anthropic's new Messages API.

`langchain-anthropic`パッケージを使用でき、`pip install langchain-anthropic`でインストールすることができます。

> You can use it from the `langchain-anthropic` package, which you can install with `pip install langchain-anthropic`.

詳細については、[ChatAnthropicMessagesのドキュメント](../chat/anthropic#chatanthropicmessages)をご覧ください。

> For more information, see the [ChatAnthropicMessages docs](../chat/anthropic#chatanthropicmessages)
