{
 "cells": [
  {
   "cell_type": "raw",
   "id": "77dd0c90-94d7-4acd-a360-e977b39d0a8f",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 0\n",
    "title: Prompt templates\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98412d-fc53-42c1-aed8-f1f8eb9ada58",
   "metadata": {},
   "source": [
    "プロンプトテンプレートは、言語モデル用のプロンプトを生成するための事前定義されたレシピです。\n",
    "\n",
    "> Prompt templates are predefined recipes for generating prompts for language models.\n",
    "\n",
    "テンプレートには、指示、数ショットの例、特定のコンテキスト、および特定のタスクに適した質問が含まれることがあります。\n",
    "\n",
    "> A template may include instructions, few-shot examples, and specific context and\n",
    "> questions appropriate for a given task.\n",
    "\n",
    "LangChainは、プロンプトテンプレートを作成し、作業するためのツールを提供します。\n",
    "\n",
    "> LangChain provides tooling to create and work with prompt templates.\n",
    "\n",
    "LangChainは、異なる言語モデル間で既存のテンプレートを簡単に再利用できるように、モデル非依存のテンプレートを作成することに努めています。\n",
    "\n",
    "> LangChain strives to create model agnostic templates to make it easy to reuse\n",
    "> existing templates across different language models.\n",
    "\n",
    "通常、言語モデルはプロンプトが文字列であるか、あるいはチャットメッセージのリストであることを期待しています。\n",
    "\n",
    "> Typically, language models expect the prompt to either be a string or else a list of chat messages.\n",
    "\n",
    "## `PromptTemplate` | `PromptTemplate`\n",
    "\n",
    "`PromptTemplate`を使用して、文字列プロンプトのテンプレートを作成します。\n",
    "\n",
    "> Use `PromptTemplate` to create a template for a string prompt.\n",
    "\n",
    "デフォルトでは、`PromptTemplate`は[Pythonのstr.format](https://docs.python.org/3/library/stdtypes.html#str.format)の構文をテンプレートに使用します。\n",
    "\n",
    "> By default, `PromptTemplate` uses [Python's str.format](https://docs.python.org/3/library/stdtypes.html#str.format)\n",
    "> syntax for templating.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5bc258b-87d2-486b-9785-edf5b23fd179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c803c-0f80-412d-9156-b8390e0265c0",
   "metadata": {},
   "source": [
    "このテンプレートは、変数がない場合を含め、任意の数の変数をサポートしています。\n",
    "\n",
    "> The template supports any number of variables, including no variables:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63bd7ac3-5cf6-4eb2-8205-d1a01029b56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke\")\n",
    "prompt_template.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7c948-9f78-431a-a466-8038e6b6f856",
   "metadata": {},
   "source": [
    "さらなる検証のために、`input_variables`を明示的に指定してください。これらの変数は、インスタンス化の際にテンプレート文字列内に存在する変数と比較され、**不一致がある場合には例外が投げられます**。例えば：\n",
    "\n",
    "> For additional validation, specify `input_variables` explicitly. These variables\n",
    "> will be compared against the variables present in the template string during instantiation, **raising an exception if\n",
    "> there is a mismatch**. For example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "617d7b2c-7308-4e74-9cc9-96ee0b7a13ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for PromptTemplate\n__root__\n  Invalid prompt schema; check for mismatched or missing input parameters. 'content' (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[0;32m----> 3\u001b[0m invalid_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madjective\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTell me a \u001b[39;49m\u001b[38;5;132;43;01m{adjective}\u001b[39;49;00m\u001b[38;5;124;43m joke about \u001b[39;49m\u001b[38;5;132;43;01m{content}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/langchain/libs/langchain/langchain/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/langchain/.venv/lib/python3.9/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for PromptTemplate\n__root__\n  Invalid prompt schema; check for mismatched or missing input parameters. 'content' (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "invalid_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\"],\n",
    "    template=\"Tell me a {adjective} joke about {content}.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715fd80-e294-49ca-9fc2-5a012949ed8a",
   "metadata": {},
   "source": [
    "好きな方法でプロンプトをフォーマットするカスタムプロンプトテンプレートを作成できます。詳細は、[カスタムプロンプトテンプレート](./custom_prompt_template.html)を参照してください。\n",
    "\n",
    "> You can create custom prompt templates that format the prompt in any way you want.\n",
    "> For more information, see [Custom Prompt Templates](./custom_prompt_template.html).\n",
    "\n",
    "## `ChatPromptTemplate` | `ChatPromptTemplate`\n",
    "\n",
    "[チャットモデル](../models/chat)へのプロンプトは、チャットメッセージのリストです。\n",
    "\n",
    "> The prompt to [chat models](../models/chat) is a list of chat messages.\n",
    "\n",
    "各チャットメッセージにはコンテンツが関連付けられており、`role` という追加のパラメーターがあります。例えば、OpenAI の [Chat Completions API](https://platform.openai.com/docs/guides/chat/introduction) では、チャットメッセージは AI アシスタント、人間、またはシステムの役割に割り当てられます。\n",
    "\n",
    "> Each chat message is associated with content, and an additional parameter called `role`.\n",
    "> For example, in the OpenAI [Chat Completions API](https://platform.openai.com/docs/guides/chat/introduction), a chat message can be associated with an AI assistant, a human or a system role.\n",
    "\n",
    "このようなチャットプロンプトのテンプレートを作成してください：\n",
    "\n",
    "> Create a chat prompt template like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d088d53c-0e20-4fb9-9d54-b0e989b998b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e7e3ef-ba7d-4ca5-a95c-a0488c9679e5",
   "metadata": {},
   "source": [
    "`ChatPromptTemplate.from_messages`は、さまざまなメッセージ表現を受け入れます。\n",
    "\n",
    "> `ChatPromptTemplate.from_messages` accepts a variety of message representations.\n",
    "\n",
    "たとえば、上記で使用された（type, content）の2タプル表現に加えて、`MessagePromptTemplate` や `BaseMessage` のインスタンスを渡すことができます。\n",
    "\n",
    "> For example, in addition to using the 2-tuple representation of (type, content) used\n",
    "> above, you could pass in an instance of `MessagePromptTemplate` or `BaseMessage`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6632eda-582f-4f29-882f-108587f0397c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I absolutely love indulging in delicious treats!')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that re-writes the user's text to \"\n",
    "                \"sound more upbeat.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm(chat_template.format_messages(text=\"i dont like eating tasty things.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b46da-d51b-4801-955f-ba4bf139162f",
   "metadata": {},
   "source": [
    "これにより、チャットプロンプトを構築する方法において、大きな柔軟性が得られます。\n",
    "\n",
    "> This provides you with a lot of flexibility in how you construct your chat prompts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5fe78c-572c-4e87-b02f-7d33126fb605",
   "metadata": {},
   "source": [
    "## LCEL | LCEL\n",
    "\n",
    "`PromptTemplate`と`ChatPromptTemplate`は、[LangChain Expression Language (LCEL)](/docs/expression_language/)の基本的な構成要素である[Runnable interface](/docs/expression_language/interface)を実装しています。これは、`invoke`、`ainvoke`、`stream`、`astream`、`batch`、`abatch`、`astream_log`の呼び出しをサポートしていることを意味します。\n",
    "\n",
    "> `PromptTemplate` and `ChatPromptTemplate` implement the [Runnable interface](/docs/expression_language/interface), the basic building block of the [LangChain Expression Language (LCEL)](/docs/expression_language/). This means they support `invoke`, `ainvoke`, `stream`, `astream`, `batch`, `abatch`, `astream_log` calls.\n",
    "\n",
    "`PromptTemplate`はプロンプト変数の辞書を受け取り、`StringPromptValue`を返します。`ChatPromptTemplate`は辞書を受け取り、`ChatPromptValue`を返します。\n",
    "\n",
    "> `PromptTemplate` accepts a dictionary (of the prompt variables) and returns a `StringPromptValue`. A `ChatPromptTemplate` accepts a dictionary and returns a `ChatPromptValue`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f0e860b-95e0-4653-8bab-c5d58b0f7d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Tell me a joke')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_val = prompt_template.invoke({\"adjective\": \"funny\", \"content\": \"chickens\"})\n",
    "prompt_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0dac782-5144-4489-8d77-eba47f1cd1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_val.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8e3ac32-f690-4d3d-bcb2-27b7931beab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me a joke')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_val.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4516257f-0c3b-4851-9e82-8c9e09111444",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_val = chat_template.invoke({\"text\": \"i dont like eating tasty things.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7adfe927-ba1d-425f-904c-0328e1a10c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more upbeat.\"),\n",
       " HumanMessage(content='i dont like eating tasty things.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_val.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37c9e2e4-a2e8-48a9-a732-01c025a21362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"System: You are a helpful assistant that re-writes the user's text to sound more upbeat.\\nHuman: i dont like eating tasty things.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_val.to_string()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-venv",
   "language": "python",
   "name": "poetry-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}