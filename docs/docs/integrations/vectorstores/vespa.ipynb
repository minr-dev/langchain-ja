{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0f17b9",
   "metadata": {},
   "source": [
    "# Vespa | Vespa\n",
    "\n",
    "> [Vespa](https://vespa.ai/)は、フル機能を備えた検索エンジンおよびベクターデータベースです。ベクター検索（近似最近傍探索：ANN）、レキシカル検索、構造化データ内の検索を、同一のクエリでサポートしています。\n",
    ">\n",
    "> > [Vespa](https://vespa.ai/) is a fully featured search engine and vector database. It supports vector search (ANN), lexical search, and search in structured data, all in the same query.\n",
    "\n",
    "このノートブックは、`Vespa.ai`をLangChainベクターストアとして使用する方法を示しています。\n",
    "\n",
    "> This notebook shows how to use `Vespa.ai` as a LangChain vector store.\n",
    "\n",
    "ベクトルストアを作成するために、[pyvespa](https://pyvespa.readthedocs.io/en/latest/index.html) を使用して `Vespa` サービスへの接続を行います。\n",
    "\n",
    "> In order to create the vector store, we use\n",
    "> [pyvespa](https://pyvespa.readthedocs.io/en/latest/index.html) to create a\n",
    "> connection a `Vespa` service.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a11ab-38bd-4920-ba11-60cb2f075754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pyvespa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283b49c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`pyvespa`パッケージを使用することで、[Vespa Cloud インスタンス](https://pyvespa.readthedocs.io/en/latest/deploy-vespa-cloud.html)またはローカルの[Docker インスタンス](https://pyvespa.readthedocs.io/en/latest/deploy-docker.html)に接続できます。ここでは、新しいVespaアプリケーションを作成し、Dockerを使用してデプロイする手順を説明します。\n",
    "\n",
    "> Using the `pyvespa` package, you can either connect to a\n",
    "> [Vespa Cloud instance](https://pyvespa.readthedocs.io/en/latest/deploy-vespa-cloud.html)\n",
    "> or a local\n",
    "> [Docker instance](https://pyvespa.readthedocs.io/en/latest/deploy-docker.html).\n",
    "> Here, we will create a new Vespa application and deploy that using Docker.\n",
    "\n",
    "#### Creating a Vespa application | Vespaアプリケーションの作成\n",
    "\n",
    "まず、アプリケーションパッケージを作成する必要があります。\n",
    "\n",
    "> First, we need to create an application package:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91150665",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from vespa.package import ApplicationPackage, Field, RankProfile\n",
    "\n",
    "app_package = ApplicationPackage(name=\"testapp\")\n",
    "app_package.schema.add_fields(\n",
    "    Field(\n",
    "        name=\"text\", type=\"string\", indexing=[\"index\", \"summary\"], index=\"enable-bm25\"\n",
    "    ),\n",
    "    Field(\n",
    "        name=\"embedding\",\n",
    "        type=\"tensor<float>(x[384])\",\n",
    "        indexing=[\"attribute\", \"summary\"],\n",
    "        attribute=[\"distance-metric: angular\"],\n",
    "    ),\n",
    ")\n",
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(\n",
    "        name=\"default\",\n",
    "        first_phase=\"closeness(field, embedding)\",\n",
    "        inputs=[(\"query(query_embedding)\", \"tensor<float>(x[384])\")],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15477106",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "これにより、ドキュメントのテキストを保持するための `text` フィールドと、埋め込みベクトルを保持するための `embedding` フィールドを含む、各ドキュメントのスキーマを持つVespaアプリケーションが設定されます。`text` フィールドは、効率的なテキスト検索のために BM25 インデックスを使用するように設定されており、この使用方法とハイブリッド検索については後ほど詳しく見ていきます。\n",
    "\n",
    "> This sets up a Vespa application with a schema for each document that contains\n",
    "> two fields: `text` for holding the document text and `embedding` for holding\n",
    "> the embedding vector. The `text` field is set up to use a BM25 index for\n",
    "> efficient text retrieval, and we'll see how to use this and hybrid search a\n",
    "> bit later.\n",
    "\n",
    "`embedding` フィールドは、テキストの埋め込み表現を保持するために、長さ384のベクトルで設定されています。Vespaにおけるテンソルの詳細については、[Vespaのテンソルガイド](https://docs.vespa.ai/en/tensor-user-guide.html)を参照してください。\n",
    "\n",
    "> The `embedding` field is set up with a vector of length 384 to hold the\n",
    "> embedding representation of the text. See\n",
    "> [Vespa's Tensor Guide](https://docs.vespa.ai/en/tensor-user-guide.html)\n",
    "> for more on tensors in Vespa.\n",
    "\n",
    "最後に、ドキュメントの順序付けを指示するために、[ランクプロファイル](https://docs.vespa.ai/en/ranking.html)を追加します。ここでは、これを[最近傍探索](https://docs.vespa.ai/en/nearest-neighbor-search.html)を用いて設定します。\n",
    "\n",
    "> Lastly, we add a [rank profile](https://docs.vespa.ai/en/ranking.html) to\n",
    "> instruct Vespa how to order documents. Here we set this up with a\n",
    "> [nearest neighbor search](https://docs.vespa.ai/en/nearest-neighbor-search.html).\n",
    "\n",
    "これで、このアプリケーションをローカルにデプロイできます。\n",
    "\n",
    "> Now we can deploy this application locally:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10dd962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "vespa_docker = VespaDocker()\n",
    "vespa_app = vespa_docker.deploy(application_package=app_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4ce53",
   "metadata": {},
   "source": [
    "これにより、`Vespa`サービスへの接続がデプロイおよび作成されます。既に例えばクラウド上でVespaアプリケーションを実行中の場合は、接続方法についてPyVespaアプリケーションを参照してください。\n",
    "\n",
    "> This deploys and creates a connection to a `Vespa` service. In case you\n",
    "> already have a Vespa application running, for instance in the cloud,\n",
    "> please refer to the PyVespa application for how to connect.\n",
    "\n",
    "#### Creating a Vespa vector store | Vespaベクトルストアの作成\n",
    "\n",
    "それでは、いくつかのドキュメントを読み込みましょう：\n",
    "\n",
    "> Now, let's load some documents:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abde491",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"../../modules/state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42365c7",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ここでは、テキストを埋め込みベクトルに変換するローカルのセンテンス埋め込み装置を設定しています。OpenAIの埋め込みを使用することもできますが、その埋め込みのサイズが大きいため、ベクトルの長さを`1536`に変更する必要があります。\n",
    "\n",
    "> Here, we also set up local sentence embedder to transform the text to embedding\n",
    "> vectors. One could also use OpenAI embeddings, but the vector length needs to\n",
    "> be updated to `1536` to reflect the larger size of that embedding.\n",
    "\n",
    "これらをVespaに供給するためには、ベクトルストアがVespaアプリケーションのフィールドにどのようにマッピングされるべきかを設定する必要があります。その後、このドキュメントの集合から直接ベクトルストアを作成します。\n",
    "\n",
    "> To feed these to Vespa, we need to configure how the vector store should map to\n",
    "> fields in the Vespa application. Then we create the vector store directly from\n",
    "> this set of documents:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b647878",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vespa_config = dict(\n",
    "    page_content_field=\"text\",\n",
    "    embedding_field=\"embedding\",\n",
    "    input_field=\"query_embedding\",\n",
    ")\n",
    "\n",
    "from langchain.vectorstores import VespaStore\n",
    "\n",
    "db = VespaStore.from_documents(docs, embedding_function, app=vespa_app, **vespa_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd0aab",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "これによりVespaベクトルストアが作成され、そのドキュメントセットがVespaに供給されます。ベクトルストアは、各ドキュメントに対して埋め込み関数を呼び出す役割を担い、それらをデータベースに挿入します。\n",
    "\n",
    "> This creates a Vespa vector store and feeds that set of documents to Vespa.\n",
    "> The vector store takes care of calling the embedding function for each document\n",
    "> and inserts them into the database.\n",
    "\n",
    "これでベクターストアにクエリを実行できるようになりました：\n",
    "\n",
    "> We can now query the vector store:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccca1f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "results = db.similarity_search(query)\n",
    "\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7e34e1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "上記で説明した埋め込み機能を使用してクエリの表現を作成し、それを用いてVespaで検索します。ここで使用されるのは、先にアプリケーションパッケージで設定した`default`ランキング関数です。`similarity_search`の`ranking`引数を用いることで、使用するランキング関数を指定できます。\n",
    "\n",
    "> This will use the embedding function given above to create a representation\n",
    "> for the query and use that to search Vespa. Note that this will use the\n",
    "> `default` ranking function, which we set up in the application package\n",
    "> above. You can use the `ranking` argument to `similarity_search` to\n",
    "> specify which ranking function to use.\n",
    "\n",
    "詳細については、[pyvespaのドキュメント](https://pyvespa.readthedocs.io/en/latest/getting-started-pyvespa.html#Query)を参照してください。\n",
    "\n",
    "> Please refer to the [pyvespa documentation](https://pyvespa.readthedocs.io/en/latest/getting-started-pyvespa.html#Query)\n",
    "> for more information.\n",
    "\n",
    "これはLangChain内でのVespaストアの基本的な使い方をカバーしています。\n",
    "これで結果を返して、LangChainでの使用を続けることができます。\n",
    "\n",
    "> This covers the basic usage of the Vespa store in LangChain.\n",
    "> Now you can return the results and continue using these in LangChain.\n",
    "\n",
    "#### Updating documents | ドキュメントの更新\n",
    "\n",
    "`from_documents`を呼び出す代わりに、ベクトルストアを直接作成してそこから`add_texts`を呼び出すことができます。これはドキュメントの更新にも使用できます。\n",
    "\n",
    "> An alternative to calling `from_documents`, you can create the vector\n",
    "> store directly and call `add_texts` from that. This can also be used to update\n",
    "> documents:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5256284",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "results = db.similarity_search(query)\n",
    "result = results[0]\n",
    "\n",
    "result.page_content = \"UPDATED: \" + result.page_content\n",
    "db.add_texts([result.page_content], [result.metadata], result.metadata[\"id\"])\n",
    "\n",
    "results = db.similarity_search(query)\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2526b50e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "しかし、`pyvespa`ライブラリにはVespa上のコンテンツを操作するメソッドが含まれており、直接使用することができます。\n",
    "\n",
    "> However, the `pyvespa` library contains methods to manipulate\n",
    "> content on Vespa which you can use directly.\n",
    "\n",
    "#### Deleting documents | ドキュメントの削除\n",
    "\n",
    "`delete` 関数を使用してドキュメントを削除できます：\n",
    "\n",
    "> You can delete documents using the `delete` function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cab87e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = db.similarity_search(query)\n",
    "# docs[0].metadata[\"id\"] == \"id:testapp:testapp::32\"\n",
    "\n",
    "db.delete([\"32\"])\n",
    "result = db.similarity_search(query)\n",
    "# docs[0].metadata[\"id\"] != \"id:testapp:testapp::32\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deffaba5",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`pyvespa`接続には、ドキュメントを削除するメソッドも含まれています。\n",
    "\n",
    "> Again, the `pyvespa` connection contains methods to delete documents as well.\n",
    "\n",
    "### Returning with scores | スコアを持って帰ってくる\n",
    "\n",
    "`similarity_search`メソッドは、関連性の順番でドキュメントを返すだけです。実際のスコアを取得するには：\n",
    "\n",
    "> The `similarity_search` method only returns the documents in order of\n",
    "> relevancy. To retrieve the actual scores:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ae173",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = db.similarity_search_with_score(query)\n",
    "result = results[0]\n",
    "# result[1] ~= 0.463"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7257d67a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`\"all-MiniLM-L6-v2\"` 埋め込みモデルを使用し、アプリケーション関数の引数 `angular` で指定されたコサイン距離関数を用いた結果です。\n",
    "\n",
    "> This is a result of using the `\"all-MiniLM-L6-v2\"` embedding model using the\n",
    "> cosine distance function (as given by the argument `angular` in the\n",
    "> application function).\n",
    "\n",
    "異なる埋め込み関数には異なる距離関数が必要であり、Vespaはドキュメントを順序付けする際にどの距離関数を使用するかを知る必要があります。詳細については、[距離関数に関するドキュメント](https://docs.vespa.ai/en/reference/schema-reference.html#distance-metric)を参照してください。\n",
    "\n",
    "> Different embedding functions need different distance functions, and Vespa\n",
    "> needs to know which distance function to use when orderings documents.\n",
    "> Please refer to the\n",
    "> [documentation on distance functions](https://docs.vespa.ai/en/reference/schema-reference.html#distance-metric)\n",
    "> for more information.\n",
    "\n",
    "### As retriever | リトリーバーとして\n",
    "\n",
    "このベクトルストアを[LangChain retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/)として使用するには、標準のベクトルストアメソッドである`as_retriever`関数を単に呼び出すだけです。\n",
    "\n",
    "> To use this vector store as a\n",
    "> [LangChain retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/)\n",
    "> simply call the `as_retriever` function, which is a standard vector store\n",
    "> method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb717a9",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "db = VespaStore.from_documents(docs, embedding_function, app=vespa_app, **vespa_config)\n",
    "retriever = db.as_retriever()\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "# results[0].metadata[\"id\"] == \"id:testapp:testapp::32\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7f07e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "これにより、ベクトルストアからのより一般的で非構造化された検索が可能になります。\n",
    "\n",
    "> This allows for more general, unstructured, retrieval from the vector store.\n",
    "\n",
    "### Metadata | メタデータ\n",
    "\n",
    "これまでの例では、テキストとそのテキストの埋め込みのみを使用してきました。ドキュメントには通常、追加の情報が含まれており、LangChainではこれをメタデータと呼んでいます。\n",
    "\n",
    "> In the example so far, we've only used the text and the embedding for that\n",
    "> text. Documents usually contain additional information, which in LangChain\n",
    "> is referred to as metadata.\n",
    "\n",
    "Vespaは、アプリケーションパッケージにそれらを追加することで、異なるタイプの多くのフィールドを含むことができます：\n",
    "\n",
    "> Vespa can contain many fields with different types by adding them to the application\n",
    "> package:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cffcf2",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "app_package.schema.add_fields(\n",
    "    # ...\n",
    "    Field(name=\"date\", type=\"string\", indexing=[\"attribute\", \"summary\"]),\n",
    "    Field(name=\"rating\", type=\"int\", indexing=[\"attribute\", \"summary\"]),\n",
    "    Field(name=\"author\", type=\"string\", indexing=[\"attribute\", \"summary\"]),\n",
    "    # ...\n",
    ")\n",
    "vespa_app = vespa_docker.deploy(application_package=app_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebef70c",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ドキュメントにいくつかのメタデータフィールドを追加することができます：\n",
    "\n",
    "> We can add some metadata fields in the documents:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21efbfa",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add metadata\n",
    "for i, doc in enumerate(docs):\n",
    "    doc.metadata[\"date\"] = f\"2023-{(i % 12)+1}-{(i % 28)+1}\"\n",
    "    doc.metadata[\"rating\"] = range(1, 6)[i % 5]\n",
    "    doc.metadata[\"author\"] = [\"Joe Biden\", \"Unknown\"][min(i, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b42bd4d",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "これらのフィールドをVespaベクターストアに知らせてください：\n",
    "\n",
    "> And let the Vespa vector store know about these fields:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb272f6",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vespa_config.update(dict(metadata_fields=[\"date\", \"rating\", \"author\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43818655",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "これらのドキュメントを検索する際には、これらのフィールドが返されます。また、これらのフィールドをフィルタリングすることもできます：\n",
    "\n",
    "> Now, when searching for these documents, these fields will be returned.\n",
    "> Also, these fields can be filtered on:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831759f3",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "db = VespaStore.from_documents(docs, embedding_function, app=vespa_app, **vespa_config)\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "results = db.similarity_search(query, filter=\"rating > 3\")\n",
    "# results[0].metadata[\"id\"] == \"id:testapp:testapp::34\"\n",
    "# results[0].metadata[\"author\"] == \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49aad6e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Custom query | カスタムクエリ\n",
    "\n",
    "類似性検索のデフォルトの動作があなたの要件に合わない場合、自分でクエリを提供することができます。ですから、ベクトルストアに全ての設定を提供する必要はなく、自分でこれを書くだけで済むのです。\n",
    "\n",
    "> If the default behavior of the similarity search does not fit your\n",
    "> requirements, you can always provide your own query. Thus, you don't\n",
    "> need to provide all of the configuration to the vector store, but\n",
    "> rather just write this yourself.\n",
    "\n",
    "まず、BM25ランキング機能を私たちのアプリケーションに追加しましょう。\n",
    "\n",
    "> First, let's add a BM25 ranking function to our application:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb0562",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from vespa.package import FieldSet\n",
    "\n",
    "app_package.schema.add_field_set(FieldSet(name=\"default\", fields=[\"text\"]))\n",
    "app_package.schema.add_rank_profile(RankProfile(name=\"bm25\", first_phase=\"bm25(text)\"))\n",
    "vespa_app = vespa_docker.deploy(application_package=app_package)\n",
    "db = VespaStore.from_documents(docs, embedding_function, app=vespa_app, **vespa_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe607747",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "次に、BM25に基づいた通常のテキスト検索を実行するには：\n",
    "\n",
    "> Then, to perform a regular text search based on BM25:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee245c3",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "custom_query = {\n",
    "    \"yql\": \"select * from sources * where userQuery()\",\n",
    "    \"query\": query,\n",
    "    \"type\": \"weakAnd\",\n",
    "    \"ranking\": \"bm25\",\n",
    "    \"hits\": 4,\n",
    "}\n",
    "results = db.similarity_search_with_score(query, custom_query=custom_query)\n",
    "# results[0][0].metadata[\"id\"] == \"id:testapp:testapp::32\"\n",
    "# results[0][1] ~= 14.384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4c081",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Vespaの強力な検索機能やクエリ機能は、カスタムクエリを使用することで利用できます。詳細については、Vespaの[クエリAPI](https://docs.vespa.ai/en/query-api.html)のドキュメントを参照してください。\n",
    "\n",
    "> All of the powerful search and query capabilities of Vespa can be used\n",
    "> by using a custom query. Please refer to the Vespa documentation on it's\n",
    "> [Query API](https://docs.vespa.ai/en/query-api.html) for more details.\n",
    "\n",
    "### Hybrid search | ハイブリッド検索\n",
    "\n",
    "ハイブリッド検索とは、BM25のような従来の用語ベースの検索とベクター検索を使用し、その結果を組み合わせることを意味します。Vespa上でハイブリッド検索用の新しいランクプロファイルを作成する必要があります。\n",
    "\n",
    "> Hybrid search means using both a classic term-based search such as\n",
    "> BM25 and a vector search and combining the results. We need to create\n",
    "> a new rank profile for hybrid search on Vespa:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf73efc1",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(\n",
    "        name=\"hybrid\",\n",
    "        first_phase=\"log(bm25(text)) + 0.5 * closeness(field, embedding)\",\n",
    "        inputs=[(\"query(query_embedding)\", \"tensor<float>(x[384])\")],\n",
    "    )\n",
    ")\n",
    "vespa_app = vespa_docker.deploy(application_package=app_package)\n",
    "db = VespaStore.from_documents(docs, embedding_function, app=vespa_app, **vespa_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f48711",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ここでは、各ドキュメントをBM25スコアと距離スコアの組み合わせで評価します。カスタムクエリを使用してクエリを実行できます。\n",
    "\n",
    "> Here, we score each document as a combination of it's BM25 score and its\n",
    "> distance score. We can query using a custom query:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e289f0",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "query_embedding = embedding_function.embed_query(query)\n",
    "nearest_neighbor_expression = (\n",
    "    \"{targetHits: 4}nearestNeighbor(embedding, query_embedding)\"\n",
    ")\n",
    "custom_query = {\n",
    "    \"yql\": f\"select * from sources * where {nearest_neighbor_expression} and userQuery()\",\n",
    "    \"query\": query,\n",
    "    \"type\": \"weakAnd\",\n",
    "    \"input.query(query_embedding)\": query_embedding,\n",
    "    \"ranking\": \"hybrid\",\n",
    "    \"hits\": 4,\n",
    "}\n",
    "results = db.similarity_search_with_score(query, custom_query=custom_query)\n",
    "# results[0][0].metadata[\"id\"], \"id:testapp:testapp::32\")\n",
    "# results[0][1] ~= 2.897"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958e269f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Native embedders in Vespa | Vespaのネイティブ埋め込み機能\n",
    "\n",
    "これまで私たちはテキストの埋め込みを提供するためにPythonの埋め込み関数を使用してきました。Vespaは埋め込み関数をネイティブにサポートしているので、この計算をVespaに任せることができます。その利点の一つは、大規模なコレクションを持っている場合、ドキュメントの埋め込みにGPUを使用する能力があることです。\n",
    "\n",
    "> Up until this point we've used an embedding function in Python to provide\n",
    "> embeddings for the texts. Vespa supports embedding function natively, so\n",
    "> you can defer this calculation in to Vespa. One benefit is the ability to use\n",
    "> GPUs when embedding documents if you have a large collections.\n",
    "\n",
    "詳細については、[Vespaのエンベディング](https://docs.vespa.ai/en/embedding.html)に関する情報をご参照ください。\n",
    "\n",
    "> Please refer to [Vespa embeddings](https://docs.vespa.ai/en/embedding.html)\n",
    "> for more information.\n",
    "\n",
    "まず、私たちはアプリケーションパッケージを変更する必要があります。\n",
    "\n",
    "> First, we need to modify our application package:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9686c",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from vespa.package import Component, Parameter\n",
    "\n",
    "app_package.components = [\n",
    "    Component(\n",
    "        id=\"hf-embedder\",\n",
    "        type=\"hugging-face-embedder\",\n",
    "        parameters=[\n",
    "            Parameter(\"transformer-model\", {\"path\": \"...\"}),\n",
    "            Parameter(\"tokenizer-model\", {\"url\": \"...\"}),\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "Field(\n",
    "    name=\"hfembedding\",\n",
    "    type=\"tensor<float>(x[384])\",\n",
    "    is_document_field=False,\n",
    "    indexing=[\"input text\", \"embed hf-embedder\", \"attribute\", \"summary\"],\n",
    "    attribute=[\"distance-metric: angular\"],\n",
    ")\n",
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(\n",
    "        name=\"hf_similarity\",\n",
    "        first_phase=\"closeness(field, hfembedding)\",\n",
    "        inputs=[(\"query(query_embedding)\", \"tensor<float>(x[384])\")],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd721a8",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "エンベッダーモデルやトークナイザーをアプリケーションに追加する方法については、エンベッディングのドキュメンテーションを参照してください。`hfembedding`フィールドには、`hf-embedder`を使用してエンベッディングを行うための指示が含まれていることに注意してください。\n",
    "\n",
    "> Please refer to the embeddings documentation on adding embedder models\n",
    "> and tokenizers to the application. Note that the `hfembedding` field\n",
    "> includes instructions for embedding using the `hf-embedder`.\n",
    "\n",
    "これでカスタムクエリを使用してクエリを実行できます：\n",
    "\n",
    "> Now we can query with a custom query:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da631d13",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "nearest_neighbor_expression = (\n",
    "    \"{targetHits: 4}nearestNeighbor(internalembedding, query_embedding)\"\n",
    ")\n",
    "custom_query = {\n",
    "    \"yql\": f\"select * from sources * where {nearest_neighbor_expression}\",\n",
    "    \"input.query(query_embedding)\": f'embed(hf-embedder, \"{query}\")',\n",
    "    \"ranking\": \"internal_similarity\",\n",
    "    \"hits\": 4,\n",
    "}\n",
    "results = db.similarity_search_with_score(query, custom_query=custom_query)\n",
    "# results[0][0].metadata[\"id\"], \"id:testapp:testapp::32\")\n",
    "# results[0][1] ~= 0.630"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333b553",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ここでのクエリには、ドキュメントと同じモデルを使用してクエリを埋め込むための `embed` 命令が含まれていることに注意してください。\n",
    "\n",
    "> Note that the query here includes an `embed` instruction to embed the query\n",
    "> using the same model as for the documents.\n",
    "\n",
    "### Approximate nearest neighbor | 近似最近傍探索\n",
    "\n",
    "上記のすべての例で、私たちは正確な最近傍探索を使用して結果を見つけています。しかし、大規模な文書集合では、最良の一致を見つけるために全文書を調べることは実行不可能です。この問題を解決するために、[近似最近傍探索](https://docs.vespa.ai/en/approximate-nn-hnsw.html)を使用することができます。\n",
    "\n",
    "> In all of the above examples, we've used exact nearest neighbor to\n",
    "> find results. However, for large collections of documents this is\n",
    "> not feasible as one has to scan through all documents to find the\n",
    "> best matches. To avoid this, we can use\n",
    "> [approximate nearest neighbors](https://docs.vespa.ai/en/approximate-nn-hnsw.html).\n",
    "\n",
    "まず、HNSWインデックスを作成するために埋め込みフィールドを変更できます：\n",
    "\n",
    "> First, we can change the embedding field to create a HNSW index:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee955c8",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from vespa.package import HNSW\n",
    "\n",
    "app_package.schema.add_fields(\n",
    "    Field(\n",
    "        name=\"embedding\",\n",
    "        type=\"tensor<float>(x[384])\",\n",
    "        indexing=[\"attribute\", \"summary\", \"index\"],\n",
    "        ann=HNSW(\n",
    "            distance_metric=\"angular\",\n",
    "            max_links_per_node=16,\n",
    "            neighbors_to_explore_at_insert=200,\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed1c224",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "これにより、埋め込みデータにHNSWインデックスが作成され、効率的な検索が可能になります。この設定を行うことで、`approximate` 引数を `True` にすることにより、近似最近傍探索（ANN）を使用した簡単な検索が行えます：\n",
    "\n",
    "> This creates a HNSW index on the embedding data which allows for efficient\n",
    "> searching. With this set, we can easily search using ANN by setting\n",
    "> the `approximate` argument to `True`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7981739a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "results = db.similarity_search(query, approximate=True)\n",
    "# results[0][0].metadata[\"id\"], \"id:testapp:testapp::32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24791204",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "これには、LangChainのVespaベクターストアのほとんどの機能が含まれています。\n",
    "\n",
    "> This covers most of the functionality in the Vespa vector store in LangChain.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}