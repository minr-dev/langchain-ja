{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e33ebe",
   "metadata": {},
   "source": [
    "# Custom Memory | カスタムメモリ\n",
    "\n",
    "LangChainにはいくつかの事前定義されたメモリタイプがありますが、あなたのアプリケーションに最適なメモリタイプを自分で追加したくなる可能性が高いです。このノートブックでは、そのやり方を説明しています。\n",
    "\n",
    "> Although there are a few predefined types of memory in LangChain, it is highly possible you will want to add your own type of memory that is optimal for your application. This notebook covers how to do that.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd0305",
   "metadata": {},
   "source": [
    "このノートブックでは、`ConversationChain`にカスタムメモリタイプを追加します。カスタムメモリクラスを追加するには、ベースメモリクラスをインポートし、それをサブクラス化する必要があります。\n",
    "\n",
    "> For this notebook, we will add a custom memory type to `ConversationChain`. In order to add a custom memory class, we need to import the base memory class and subclass it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d787ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.schema import BaseMemory\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489e5e1",
   "metadata": {},
   "source": [
    "この例では、spaCyを使用してエンティティを抽出し、それに関する情報をシンプルなハッシュテーブルに保存するカスタムメモリクラスを作成します。その後、会話の中で入力テキストを見て、エンティティを抽出し、それに関する情報をコンテキストに加えます。\n",
    "\n",
    "> In this example, we will write a custom memory class that uses spaCy to extract entities and save information about them in a simple hash table. Then, during the conversation, we will look at the input text, extract any entities, and put any information about them into the context.\n",
    "\n",
    "* この実装は非常にシンプルで壊れやすく、本番環境での使用には適していない可能性が高いことに注意してください。その目的は、カスタムメモリ実装を追加できることを示すことにあります。\n",
    "\n",
    "  > Please note that this implementation is pretty simple and brittle and probably not useful in a production setting. Its purpose is to showcase that you can add custom memory implementations.\n",
    "\n",
    "\n",
    "これには、spaCyが必要になります。\n",
    "\n",
    "> For this, we will need spaCy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a5dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff065f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d45d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacyEntityMemory(BaseMemory, BaseModel):\n",
    "    \"\"\"Memory class for storing information about entities.\"\"\"\n",
    "\n",
    "    # Define dictionary to store information about entities.\n",
    "    entities: dict = {}\n",
    "    # Define key to pass information about entities into prompt.\n",
    "    memory_key: str = \"entities\"\n",
    "\n",
    "    def clear(self):\n",
    "        self.entities = {}\n",
    "\n",
    "    @property\n",
    "    def memory_variables(self) -> List[str]:\n",
    "        \"\"\"Define the variables we are providing to the prompt.\"\"\"\n",
    "        return [self.memory_key]\n",
    "\n",
    "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, str]:\n",
    "        \"\"\"Load the memory variables, in this case the entity key.\"\"\"\n",
    "        # Get the input text and run through spaCy\n",
    "        doc = nlp(inputs[list(inputs.keys())[0]])\n",
    "        # Extract known information about entities, if they exist.\n",
    "        entities = [\n",
    "            self.entities[str(ent)] for ent in doc.ents if str(ent) in self.entities\n",
    "        ]\n",
    "        # Return combined information about entities to put into context.\n",
    "        return {self.memory_key: \"\\n\".join(entities)}\n",
    "\n",
    "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
    "        \"\"\"Save context from this conversation to buffer.\"\"\"\n",
    "        # Get the input text and run through spaCy\n",
    "        text = inputs[list(inputs.keys())[0]]\n",
    "        doc = nlp(text)\n",
    "        # For each entity that was mentioned, save this information to the dictionary.\n",
    "        for ent in doc.ents:\n",
    "            ent_str = str(ent)\n",
    "            if ent_str in self.entities:\n",
    "                self.entities[ent_str] += f\"\\n{text}\"\n",
    "            else:\n",
    "                self.entities[ent_str] = text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ba264",
   "metadata": {},
   "source": [
    "エンティティに関する情報とユーザー入力を取り込むプロンプトを定義します。\n",
    "\n",
    "> We now define a prompt that takes in information about entities as well as user input.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c05159b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. You are provided with information about entities the Human mentions, if relevant.\n",
    "\n",
    "Relevant entity information:\n",
    "{entities}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"entities\", \"input\"], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db611041",
   "metadata": {},
   "source": [
    "さあ、全てを組み合わせましょう！\n",
    "\n",
    "> And now we put it all together!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08dc8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, prompt=prompt, verbose=True, memory=SpacyEntityMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5f685",
   "metadata": {},
   "source": [
    "最初の例では、ハリソンに関する事前知識がないため、「関連するエンティティ情報」セクションは空です。\n",
    "\n",
    "> In the first example, with no prior knowledge about Harrison, the \"Relevant entity information\" section is empty.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b96e836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. You are provided with information about entities the Human mentions, if relevant.\n",
      "\n",
      "Relevant entity information:\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: Harrison likes machine learning\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished ConversationChain chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's great to hear! Machine learning is a fascinating field of study. It involves using algorithms to analyze data and make predictions. Have you ever studied machine learning, Harrison?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Harrison likes machine learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1faa743",
   "metadata": {},
   "source": [
    "2つ目の例では、ハリソンに関する情報が取り込まれていることがわかります。\n",
    "\n",
    "> Now in the second example, we can see that it pulls in information about Harrison.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bca7070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. You are provided with information about entities the Human mentions, if relevant.\n",
      "\n",
      "Relevant entity information:\n",
      "Harrison likes machine learning\n",
      "\n",
      "Conversation:\n",
      "Human: What do you think Harrison's favorite subject in college was?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished ConversationChain chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' From what I know about Harrison, I believe his favorite subject in college was machine learning. He has expressed a strong interest in the subject and has mentioned it often.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(\n",
    "    input=\"What do you think Harrison's favorite subject in college was?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b856e3",
   "metadata": {},
   "source": [
    "再度申し上げますが、この実装は非常にシンプルで壊れやすく、実際のプロダクション環境で役立つとは限りません。その目的は、カスタムメモリ実装を追加できることを示すためのものです。\n",
    "\n",
    "> Again, please note that this implementation is pretty simple and brittle and probably not useful in a production setting. Its purpose is to showcase that you can add custom memory implementations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1994600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}