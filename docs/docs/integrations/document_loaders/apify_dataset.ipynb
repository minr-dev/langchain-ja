{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apify Dataset | Apify Dataset",
    "",
    "> [Apify Dataset](https://docs.apify.com/platform/storage/dataset)は、製品リストやGoogleの検索結果ページ（SERP）などの構造化されたウェブスクレイピング結果を保存し、それらをJSON、CSV、Excelなど様々な形式でエクスポートするために設計された、シーケンシャルアクセスを可能とするスケーラブルな追記専用ストレージです。データセットは主に、様々なウェブスクレイピング、クローリング、データ抽出のユースケースに適用されるサーバーレスクラウドプログラムである[Apify Actors](https://apify.com/store)の結果を保存するために使用されます。",
    ">",
    "> > [Apify Dataset](https://docs.apify.com/platform/storage/dataset) is a scalable append-only storage with sequential access built for storing structured web scraping results, such as a list of products or Google SERPs, and then export them to various formats like JSON, CSV, or Excel. Datasets are mainly used to save results of [Apify Actors](https://apify.com/store)—serverless cloud programs for various web scraping, crawling, and data extraction use cases.",
    "",
    "このノートブックは、ApifyのデータセットをLangChainに読み込む方法を示しています。",
    "",
    "> This notebook shows how to load Apify datasets to LangChain.",
    "",
    "## Prerequisites | 前提条件",
    "",
    "Apifyプラットフォーム上に既存のデータセットを持っている必要があります。もし持っていない場合は、まず[このノートブック](/docs/integrations/tools/apify)をチェックして、ドキュメンテーション、ナレッジベース、ヘルプセンター、またはブログからコンテンツを抽出する方法について学んでください。",
    "",
    "> You need to have an existing dataset on the Apify platform. If you don't have one, please first check out [this notebook](/docs/integrations/tools/apify) on how to use Apify to extract content from documentation, knowledge bases, help centers, or blogs.",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install apify-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、`ApifyDatasetLoader`をソースコードにインポートしてください：",
    "",
    "> First, import `ApifyDatasetLoader` into your source code:",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import ApifyDatasetLoader\n",
    "from langchain.document_loaders.base import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その後、ApifyデータセットレコードのフィールドをLangChainの`Document`フォーマットにマッピングする関数を提供してください。",
    "",
    "> Then provide a function that maps Apify dataset record fields to LangChain `Document` format.",
    "",
    "例えば、あなたのデータセットのアイテムがこのように構造化されているとします：",
    "",
    "> For example, if your dataset items are structured like this:",
    "",
    "```json",
    "{",
    "    \"url\": \"https://apify.com\",",
    "    \"text\": \"Apify is the best web scraping and automation platform.\"",
    "}",
    "```",
    "",
    "以下のコードにおけるマッピング関数は、それらをLangChainの`Document`形式に変換し、その後任意のLLMモデル（例えば質問応答用など）で使用できるようにします。",
    "",
    "> The mapping function in the code below will convert them to LangChain `Document` format, so that you can use them further with any LLM model (e.g. for question answering).",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ApifyDatasetLoader(\n",
    "    dataset_id=\"your-dataset-id\",\n",
    "    dataset_mapping_function=lambda dataset_item: Document(\n",
    "        page_content=dataset_item[\"text\"], metadata={\"source\": dataset_item[\"url\"]}\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example with question answering | 質問応答の例",
    "",
    "この例では、データセットからのデータを使用して質問に答えます。",
    "",
    "> In this example, we use data from a dataset to answer a question.",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import ApifyDatasetLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ApifyDatasetLoader(\n",
    "    dataset_id=\"your-dataset-id\",\n",
    "    dataset_mapping_function=lambda item: Document(\n",
    "        page_content=item[\"text\"] or \"\", metadata={\"source\": item[\"url\"]}\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Apify?\"\n",
    "result = index.query_with_sources(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Apify is a platform for developing, running, and sharing serverless cloud programs. It enables users to create web scraping and automation tools and publish them on the Apify platform.\n",
      "\n",
      "https://docs.apify.com/platform/actors, https://docs.apify.com/platform/actors/running/actors-in-store, https://docs.apify.com/platform/security, https://docs.apify.com/platform/actors/examples\n"
     ]
    }
   ],
   "source": [
    "print(result[\"answer\"])\n",
    "print(result[\"sources\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}