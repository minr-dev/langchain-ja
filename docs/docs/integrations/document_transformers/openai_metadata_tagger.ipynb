{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI metadata tagger | OpenAI メタデータタガー\n",
    "\n",
    "文書を取り込む際に、タイトル、トーン、文書の長さなどの構造化されたメタデータでタグ付けすることは、後でよりターゲットを絞った類似性検索を行う際にしばしば役立ちます。しかし、大量の文書に対してこのラベリングプロセスを手作業で行うのは退屈で面倒な作業になりがちです。\n",
    "\n",
    "> It can often be useful to tag ingested documents with structured metadata, such as the title, tone, or length of a document, to allow for a more targeted similarity search later. However, for large numbers of documents, performing this labelling process manually can be tedious.\n",
    "\n",
    "`OpenAIMetadataTagger` ドキュメントトランスフォーマーは、提供されたスキーマに従って各ドキュメントからメタデータを抽出するプロセスを自動化します。内部では設定可能な `OpenAI Functions` 駆動のチェーンを使用しているので、カスタムLLMインスタンスを渡す場合、それは関数サポート付きの `OpenAI` モデルでなければなりません。\n",
    "\n",
    "> The `OpenAIMetadataTagger` document transformer automates this process by extracting metadata from each provided document according to a provided schema. It uses a configurable `OpenAI Functions`-powered chain under the hood, so if you pass a custom LLM instance, it must be an `OpenAI` model with functions support.\n",
    "\n",
    "注意：このドキュメントトランスフォーマーは完全なドキュメントで最も効果的に機能するため、他の分割や処理を行う前に、まず完全なドキュメントで実行することが最善です！\n",
    "\n",
    "> **Note:** This document transformer works best with complete documents, so it's best to run it first with whole documents before doing any other splitting or processing!\n",
    "\n",
    "例えば、映画レビューの集まりをインデックス化したいとしましょう。次のように有効な `JSON Schema` オブジェクトを用いてドキュメントトランスフォーマーを初期化することができます：\n",
    "\n",
    "> For example, let's say you wanted to index a set of movie reviews. You could initialize the document transformer with a valid `JSON Schema` object as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_transformers.openai_functions import create_metadata_tagger\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"movie_title\": {\"type\": \"string\"},\n",
    "        \"critic\": {\"type\": \"string\"},\n",
    "        \"tone\": {\"type\": \"string\", \"enum\": [\"positive\", \"negative\"]},\n",
    "        \"rating\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"The number of stars the critic rated the movie\",\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"movie_title\", \"critic\", \"tone\"],\n",
    "}\n",
    "\n",
    "# Must be an OpenAI model that supports functions\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "document_transformer = create_metadata_tagger(metadata_schema=schema, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その後、ドキュメントトランスフォーマーにドキュメントのリストを渡すだけで、それが内容からメタデータを抽出します。\n",
    "\n",
    "> You can then simply pass the document transformer a list of documents, and it will extract metadata from the contents:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_documents = [\n",
    "    Document(\n",
    "        page_content=\"Review of The Bee Movie\\nBy Roger Ebert\\n\\nThis is the greatest movie ever made. 4 out of 5 stars.\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Review of The Godfather\\nBy Anonymous\\n\\nThis movie was super boring. 1 out of 5 stars.\",\n",
    "        metadata={\"reliable\": False},\n",
    "    ),\n",
    "]\n",
    "\n",
    "enhanced_documents = document_transformer.transform_documents(original_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review of The Bee Movie\n",
      "By Roger Ebert\n",
      "\n",
      "This is the greatest movie ever made. 4 out of 5 stars.\n",
      "\n",
      "{\"movie_title\": \"The Bee Movie\", \"critic\": \"Roger Ebert\", \"tone\": \"positive\", \"rating\": 4}\n",
      "\n",
      "---------------\n",
      "\n",
      "Review of The Godfather\n",
      "By Anonymous\n",
      "\n",
      "This movie was super boring. 1 out of 5 stars.\n",
      "\n",
      "{\"movie_title\": \"The Godfather\", \"critic\": \"Anonymous\", \"tone\": \"negative\", \"rating\": 1, \"reliable\": false}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(\n",
    "    *[d.page_content + \"\\n\\n\" + json.dumps(d.metadata) for d in enhanced_documents],\n",
    "    sep=\"\\n\\n---------------\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新しいドキュメントは、ベクトルストアにロードされる前にテキストスプリッターでさらに処理されることができます。抽出されたフィールドは、既存のメタデータを上書きすることはありません。\n",
    "\n",
    "> The new documents can then be further processed by a text splitter before being loaded into a vector store. Extracted fields will not overwrite existing metadata.\n",
    "\n",
    "ドキュメントトランスフォーマーをPydanticスキーマで初期化することもできます：\n",
    "\n",
    "> You can also initialize the document transformer with a Pydantic schema:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review of The Bee Movie\n",
      "By Roger Ebert\n",
      "\n",
      "This is the greatest movie ever made. 4 out of 5 stars.\n",
      "\n",
      "{\"movie_title\": \"The Bee Movie\", \"critic\": \"Roger Ebert\", \"tone\": \"positive\", \"rating\": 4}\n",
      "\n",
      "---------------\n",
      "\n",
      "Review of The Godfather\n",
      "By Anonymous\n",
      "\n",
      "This movie was super boring. 1 out of 5 stars.\n",
      "\n",
      "{\"movie_title\": \"The Godfather\", \"critic\": \"Anonymous\", \"tone\": \"negative\", \"rating\": 1, \"reliable\": false}\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Properties(BaseModel):\n",
    "    movie_title: str\n",
    "    critic: str\n",
    "    tone: Literal[\"positive\", \"negative\"]\n",
    "    rating: int = Field(description=\"Rating out of 5 stars\")\n",
    "\n",
    "\n",
    "document_transformer = create_metadata_tagger(Properties, llm)\n",
    "enhanced_documents = document_transformer.transform_documents(original_documents)\n",
    "\n",
    "print(\n",
    "    *[d.page_content + \"\\n\\n\" + json.dumps(d.metadata) for d in enhanced_documents],\n",
    "    sep=\"\\n\\n---------------\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization | カスタマイズ\n",
    "\n",
    "ドキュメントトランスフォーマーのコンストラクタでは、基本となるタギングチェーンに標準的なLLMChain引数を渡すことができます。例えば、入力ドキュメント内の特定の詳細にLLMに注目してもらいたい場合や、特定のスタイルでメタデータを抽出したい場合は、カスタムプロンプトを渡すことができます。\n",
    "\n",
    "> You can pass the underlying tagging chain the standard LLMChain arguments in the document transformer constructor. For example, if you wanted to ask the LLM to focus specific details in the input documents, or extract metadata in a certain style, you could pass in a custom prompt:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review of The Bee Movie\n",
      "By Roger Ebert\n",
      "\n",
      "This is the greatest movie ever made. 4 out of 5 stars.\n",
      "\n",
      "{\"movie_title\": \"The Bee Movie\", \"critic\": \"Roger Ebert\", \"tone\": \"positive\", \"rating\": 4}\n",
      "\n",
      "---------------\n",
      "\n",
      "Review of The Godfather\n",
      "By Anonymous\n",
      "\n",
      "This movie was super boring. 1 out of 5 stars.\n",
      "\n",
      "{\"movie_title\": \"The Godfather\", \"critic\": \"Roger Ebert\", \"tone\": \"negative\", \"rating\": 1, \"reliable\": false}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Extract relevant information from the following text.\n",
    "Anonymous critics are actually Roger Ebert.\n",
    "\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "document_transformer = create_metadata_tagger(schema, llm, prompt=prompt)\n",
    "enhanced_documents = document_transformer.transform_documents(original_documents)\n",
    "\n",
    "print(\n",
    "    *[d.page_content + \"\\n\\n\" + json.dumps(d.metadata) for d in enhanced_documents],\n",
    "    sep=\"\\n\\n---------------\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}