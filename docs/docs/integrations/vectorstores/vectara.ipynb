{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683953b3",
   "metadata": {},
   "source": [
    "# Vectara | Vectara\n",
    "\n",
    "> [Vectara](https://vectara.com/)は、ドキュメントのインデックス作成と問い合わせのための使いやすいAPIを提供する信頼できるGenAIプラットフォームです。\n",
    ">\n",
    "> > [Vectara](https://vectara.com/) is the trusted GenAI platform that provides an easy-to-use API for document indexing and querying.\n",
    "\n",
    "Vectaraは、検索強化生成（Retrieval Augmented Generation）または[RAG](https://vectara.com/grounded-generation/)のエンドツーエンドのマネージドサービスを提供しており、その内容には以下が含まれます：\n",
    "\n",
    "> Vectara provides an end-to-end managed service for Retrieval Augmented Generation or [RAG](https://vectara.com/grounded-generation/), which includes:\n",
    "\n",
    "1. ドキュメントファイルからテキストを抽出し、それを文に分割する方法。\n",
    "\n",
    "   > A way to extract text from document files and chunk them into sentences.\n",
    "\n",
    "2. 最先端の[Boomerang](https://vectara.com/how-boomerang-takes-retrieval-augmented-generation-to-the-next-level-via-grounded-generation/)埋め込みモデルです。各テキストチャンクはBoomerangを使用してベクトル埋め込みにエンコードされ、Vectaraの内部知識（ベクトルとテキスト）ストアに格納されます。\n",
    "\n",
    "   > The state-of-the-art [Boomerang](https://vectara.com/how-boomerang-takes-retrieval-augmented-generation-to-the-next-level-via-grounded-generation/) embeddings model. Each text chunk is encoded into a vector embedding using Boomerang, and stored in the Vectara internal knowledge (vector+text) store\n",
    "\n",
    "3. クエリを自動的に埋め込み表現にエンコードし、最も関連性の高いテキストセグメントを検索するクエリサービス（[ハイブリッド検索](https://docs.vectara.com/docs/api-reference/search-apis/lexical-matching)と[MMR](https://vectara.com/get-diverse-results-and-comprehensive-summaries-with-vectaras-mmr-reranker/)のサポートを含む）\n",
    "\n",
    "   > A query service that automatically encodes the query into embedding, and retrieves the most relevant text segments (including support for [Hybrid Search](https://docs.vectara.com/docs/api-reference/search-apis/lexical-matching) and [MMR](https://vectara.com/get-diverse-results-and-comprehensive-summaries-with-vectaras-mmr-reranker/))\n",
    "\n",
    "4. 取得した文書に基づき、引用を含めた[生成的要約](https://docs.vectara.com/docs/learn/grounded-generation/grounded-generation-overview)を作成するオプション。\n",
    "\n",
    "   > An option to create [generative summary](https://docs.vectara.com/docs/learn/grounded-generation/grounded-generation-overview), based on the retrieved documents, including citations.\n",
    "\n",
    "\n",
    "APIの使用方法についての詳細は、[Vectara APIドキュメント](https://docs.vectara.com/docs/)をご覧ください。\n",
    "\n",
    "> See the [Vectara API documentation](https://docs.vectara.com/docs/) for more information on how to use the API.\n",
    "\n",
    "このノートブックでは、Vectaraを単なるベクターストアとして使用する場合（要約を行わない場合）の基本的な検索機能の使用方法を示しています。これには、`similarity_search`や`similarity_search_with_score`の機能が含まれており、LangChainの`as_retriever`機能の使用方法も説明されています。\n",
    "\n",
    "> This notebook shows how to use the basic retrieval functionality, when utilizing Vectara just as a Vector Store (without summarization), incuding: `similarity_search` and `similarity_search_with_score` as well as using the LangChain `as_retriever` functionality.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f4344",
   "metadata": {},
   "source": [
    "# Setup | セットアップ\n",
    "\n",
    "LangChainでVectaraを使用するには、Vectaraのアカウントが必要です。始めるためには、以下の手順に従ってください：\n",
    "\n",
    "> You will need a Vectara account to use Vectara with LangChain. To get started, use the following steps:\n",
    "\n",
    "1. まだVectaraアカウントをお持ちでない場合は、[サインアップ](https://www.vectara.com/integrations/langchain)してください。サインアップが完了すると、Vectaraの顧客IDが発行されます。顧客IDは、Vectaraコンソールウィンドウの右上にあるあなたの名前をクリックすることで確認できます。\n",
    "\n",
    "   > [Sign up](https://www.vectara.com/integrations/langchain) for a Vectara account if you don't already have one. Once you have completed your sign up you will have a Vectara customer ID. You can find your customer ID by clicking on your name, on the top-right of the Vectara console window.\n",
    "\n",
    "2. アカウント内で、1つまたは複数のコーパスを作成できます。各コーパスは、入力ドキュメントから取り込まれたテキストデータを格納するエリアを表します。コーパスを作成するには、\\*\\*「Create Corpus」\\*\\*ボタンを使用します。その後、コーパスに名前と説明を提供します。オプションで、フィルタリング属性を定義したり、いくつかの高度なオプションを適用することもできます。作成したコーパスをクリックすると、その名前とコーパスIDがすぐに上部に表示されます。\n",
    "\n",
    "   > Within your account you can create one or more corpora. Each corpus represents an area that stores text data upon ingest from input documents. To create a corpus, use the **\"Create Corpus\"** button. You then provide a name to your corpus as well as a description. Optionally you can define filtering attributes and apply some advanced options. If you click on your created corpus, you can see its name and corpus ID right on the top.\n",
    "\n",
    "3. 次に、コーパスにアクセスするためのAPIキーを作成する必要があります。コーパスビューの\\*\\*「Authorization」**タブをクリックし、その後**「Create API Key」\\*\\*ボタンをクリックします。キーに名前を付け、キーの権限としてクエリのみ、またはクエリ+インデックスのどちらかを選択します。「Create」をクリックすると、アクティブなAPIキーが作成されます。このキーは機密情報として保管してください。\n",
    "\n",
    "   > Next you'll need to create API keys to access the corpus. Click on the **\"Authorization\"** tab in the corpus view and then the **\"Create API Key\"** button. Give your key a name, and choose whether you want query only or query+index for your key. Click \"Create\" and you now have an active API key. Keep this key confidential.\n",
    "\n",
    "\n",
    "LangChainをVectaraと共に使用するには、顧客ID、コーパスID、およびapi\\_keyの3つの値が必要です。これらをLangChainに提供する方法は2通りあります：\n",
    "\n",
    "> To use LangChain with Vectara, you'll need to have these three values: customer ID, corpus ID and api\\_key.\n",
    "> You can provide those to LangChain in two ways:\n",
    "\n",
    "1. 環境変数には、これら三つの変数`VECTARA_CUSTOMER_ID`、`VECTARA_CORPUS_ID`、`VECTARA_API_KEY`を含めてください。\n",
    "\n",
    "   > Include in your environment these three variables: `VECTARA_CUSTOMER_ID`, `VECTARA_CORPUS_ID` and `VECTARA_API_KEY`.\n",
    "\n",
    "\n",
    "> 例えば、次のようにos.environとgetpassを使用してこれらの変数を設定できます：\n",
    ">\n",
    "> > For example, you can set these variables using os.environ and getpass as follows:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"VECTARA_CUSTOMER_ID\"] = getpass.getpass(\"Vectara Customer ID:\")\n",
    "os.environ[\"VECTARA_CORPUS_ID\"] = getpass.getpass(\"Vectara Corpus ID:\")\n",
    "os.environ[\"VECTARA_API_KEY\"] = getpass.getpass(\"Vectara API Key:\")\n",
    "```\n",
    "\n",
    "2. Vectaraベクターストアのコンストラクタにそれらを追加してください：\n",
    "\n",
    "   > Add them to the Vectara vectorstore constructor:\n",
    "\n",
    "\n",
    "```python\n",
    "vectorstore = Vectara(\n",
    "                vectara_customer_id=vectara_customer_id,\n",
    "                vectara_corpus_id=vectara_corpus_id,\n",
    "                vectara_api_key=vectara_api_key\n",
    "            )\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeead681",
   "metadata": {},
   "source": [
    "## Connecting to Vectara from LangChain | LangChainからVectaraへの接続\n",
    "\n",
    "始めに、from\\_documents() メソッドを使用してドキュメントを取り込みましょう。ここでは、VECTARA\\_CUSTOMER\\_ID、VECTARA\\_CORPUS\\_ID、およびクエリとインデキシング用の VECTARA\\_API\\_KEY を環境変数として設定済みであることを前提としています。\n",
    "\n",
    "> To get started, let's ingest the documents using the from\\_documents() method.\n",
    "> We assume here that you've added your VECTARA\\_CUSTOMER\\_ID, VECTARA\\_CORPUS\\_ID and query+indexing VECTARA\\_API\\_KEY as environment variables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a1f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.fake import FakeEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Vectara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0a4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8429667e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:51:22.525091Z",
     "start_time": "2023-04-04T10:51:22.522015Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectara = Vectara.from_documents(\n",
    "    docs,\n",
    "    embedding=FakeEmbeddings(size=768),\n",
    "    doc_metadata={\"speech\": \"state-of-the-union\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dbf3e7",
   "metadata": {},
   "source": [
    "VectaraのインデキシングAPIは、ファイルを直接Vectaraが処理し、事前処理を行い、最適に分割してVectaraベクターストアに追加するファイルアップロードAPIを提供しています。これを使用するために、add\\_files()メソッド（およびfrom\\_files()メソッド）を追加しました。\n",
    "\n",
    "> Vectara's indexing API provides a file upload API where the file is handled directly by Vectara - pre-processed, chunked optimally and added to the Vectara vector store.\n",
    "> To use this, we added the add\\_files() method (as well as from\\_files()).\n",
    "\n",
    "実際に試してみましょう。アップロードする2つのPDFドキュメントを選びます：\n",
    "\n",
    "> Let's see this in action. We pick two PDF documents to upload:\n",
    "\n",
    "1. キング博士の「I have a dream」スピーチ\n",
    "\n",
    "   > The \"I have a dream\" speech by Dr. King\n",
    "\n",
    "2. チャーチルの「我々はビーチで戦う」演説\n",
    "\n",
    "   > Churchill's \"We Shall Fight on the Beaches\" speech\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ef3468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import urllib.request\n",
    "\n",
    "urls = [\n",
    "    [\n",
    "        \"https://www.gilderlehrman.org/sites/default/files/inline-pdfs/king.dreamspeech.excerpts.pdf\",\n",
    "        \"I-have-a-dream\",\n",
    "    ],\n",
    "    [\n",
    "        \"https://www.parkwayschools.net/cms/lib/MO01931486/Centricity/Domain/1578/Churchill_Beaches_Speech.pdf\",\n",
    "        \"we shall fight on the beaches\",\n",
    "    ],\n",
    "]\n",
    "files_list = []\n",
    "for url, _ in urls:\n",
    "    name = tempfile.NamedTemporaryFile().name\n",
    "    urllib.request.urlretrieve(url, name)\n",
    "    files_list.append(name)\n",
    "\n",
    "docsearch: Vectara = Vectara.from_files(\n",
    "    files=files_list,\n",
    "    embedding=FakeEmbeddings(size=768),\n",
    "    metadatas=[{\"url\": url, \"speech\": title} for url, title in urls],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9215c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T09:27:29.920258Z",
     "start_time": "2023-04-04T09:27:29.913714Z"
    }
   },
   "source": [
    "## Similarity search | 類似性検索\n",
    "\n",
    "Vectaraを使用する最もシンプルなシナリオは、類似性検索を実行することです。\n",
    "\n",
    "> The simplest scenario for using Vectara is to perform a similarity search.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c513ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:51:25.204469Z",
     "start_time": "2023-04-04T10:51:24.855618Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "found_docs = vectara.similarity_search(\n",
    "    query, n_sentence_context=0, filter=\"doc.speech = 'state-of-the-union'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53324492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson.', metadata={'source': 'langchain', 'lang': 'eng', 'offset': '596', 'len': '97', 'speech': 'state-of-the-union'}),\n",
       " Document(page_content='In this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.”', metadata={'source': 'langchain', 'lang': 'eng', 'offset': '141', 'len': '117', 'speech': 'state-of-the-union'}),\n",
       " Document(page_content='As Ohio Senator Sherrod Brown says, “It’s time to bury the label “Rust Belt.”', metadata={'source': 'langchain', 'lang': 'eng', 'offset': '0', 'len': '77', 'speech': 'state-of-the-union'}),\n",
       " Document(page_content='Last month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago.', metadata={'source': 'langchain', 'lang': 'eng', 'offset': '0', 'len': '122', 'speech': 'state-of-the-union'}),\n",
       " Document(page_content='He thought he could roll into Ukraine and the world would roll over.', metadata={'source': 'langchain', 'lang': 'eng', 'offset': '664', 'len': '68', 'speech': 'state-of-the-union'}),\n",
       " Document(page_content='That’s why one of the first things I did as President was fight to pass the American Rescue Plan.', metadata={'source': 'langchain', 'lang': 'eng', 'offset': '314', 'len': '97', 'speech': 'state-of-the-union'}),\n",
       " Document(page_content='And he thought he could divide us at home.', metadata={'source': 'langchain', 'lang': 'eng', 'offset': '160', 'len': '42', 'speech': 'state-of-the-union'}),\n",
       " Document(page_content='He met the Ukrainian people.', metadata={'source': 'langchain', 'lang': 'eng', 'offset': '788', 'len': '28', 'speech': 'state-of-the-union'}),\n",
       " Document(page_content='He thought the West and NATO wouldn’t respond.', metadata={'source': 'langchain', 'lang': 'eng', 'offset': '113', 'len': '46', 'speech': 'state-of-the-union'}),\n",
       " Document(page_content='In this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things.', metadata={'source': 'langchain', 'lang': 'eng', 'offset': '772', 'len': '131', 'speech': 'state-of-the-union'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc516993",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:51:25.220984Z",
     "start_time": "2023-04-04T10:51:25.213943Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson.\n"
     ]
    }
   ],
   "source": [
    "print(found_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda9bf5",
   "metadata": {},
   "source": [
    "## Similarity search with score | スコア付き類似性検索\n",
    "\n",
    "時々、検索を実行するだけではなく、特定の結果の良さを知るために関連性スコアを得たいと思うことがあります。\n",
    "\n",
    "> Sometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8804a21d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:51:25.631585Z",
     "start_time": "2023-04-04T10:51:25.227384Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "found_docs = vectara.similarity_search_with_score(\n",
    "    query,\n",
    "    filter=\"doc.speech = 'state-of-the-union'\",\n",
    "    score_threshold=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "756a6887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:51:25.642282Z",
     "start_time": "2023-04-04T10:51:25.635947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Justice Breyer, thank you for your service. One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. A former top litigator in private practice.\n",
      "\n",
      "Score: 0.74179757\n"
     ]
    }
   ],
   "source": [
    "document, score = found_docs[0]\n",
    "print(document.page_content)\n",
    "print(f\"\\nScore: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9876a8",
   "metadata": {},
   "source": [
    "それでは、アップロードしたファイル内のコンテンツに対して同様の検索を行いましょう\n",
    "\n",
    "> Now let's do similar search for content in the files we uploaded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47784de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With this threshold of 1.2 we have 0 documents\n"
     ]
    }
   ],
   "source": [
    "query = \"We must forever conduct our struggle\"\n",
    "min_score = 1.2\n",
    "found_docs = vectara.similarity_search_with_score(\n",
    "    query,\n",
    "    filter=\"doc.speech = 'I-have-a-dream'\",\n",
    "    score_threshold=min_score,\n",
    ")\n",
    "print(f\"With this threshold of {min_score} we have {len(found_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f465e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With this threshold of 0.2 we have 10 documents\n"
     ]
    }
   ],
   "source": [
    "query = \"We must forever conduct our struggle\"\n",
    "min_score = 0.2\n",
    "found_docs = vectara.similarity_search_with_score(\n",
    "    query,\n",
    "    filter=\"doc.speech = 'I-have-a-dream'\",\n",
    "    score_threshold=min_score,\n",
    ")\n",
    "print(f\"With this threshold of {min_score} we have {len(found_docs)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471112c0",
   "metadata": {},
   "source": [
    "MMRは、GenAIアプリケーションにフィードされる検索結果を再ランク付けし、結果の多様性を向上させることによって、多くのアプリケーションにとって重要な検索能力です。\n",
    "\n",
    "> MMR is an important retrieval capability for many applications, whereby search results feeding your GenAI application are reranked to improve diversity of results.\n",
    "\n",
    "Vectaraを使って、それがどのように動作するか見てみましょう：\n",
    "\n",
    "> Let's see how that works with Vectara:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d597e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic assistance.\n",
      "\n",
      "Grow the workforce. Build the economy from the bottom up  \n",
      "and the middle out, not from the top down.\n",
      "\n",
      "When we invest in our workers, when we build the economy from the bottom up and the middle out together, we can do something we haven’t done in a long time: build a better America.\n",
      "\n",
      "Our economy grew at a rate of 5.7% last year, the strongest growth in nearly 40 years, the first step in bringing fundamental change to an economy that hasn’t worked for the working people of this nation for too long.\n",
      "\n",
      "Economists call it “increasing the productive capacity of our economy.”\n"
     ]
    }
   ],
   "source": [
    "query = \"state of the economy\"\n",
    "found_docs = vectara.similarity_search(\n",
    "    query,\n",
    "    n_sentence_context=0,\n",
    "    filter=\"doc.speech = 'state-of-the-union'\",\n",
    "    k=5,\n",
    "    mmr_config={\"is_enabled\": True, \"mmr_k\": 50, \"diversity_bias\": 0.0},\n",
    ")\n",
    "print(\"\\n\\n\".join([x.page_content for x in found_docs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2b2326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic assistance.\n",
      "\n",
      "The Russian stock market has lost 40% of its value and trading remains suspended.\n",
      "\n",
      "But that trickle-down theory led to weaker economic growth, lower wages, bigger deficits, and the widest gap between those at the top and everyone else in nearly a century.\n",
      "\n",
      "In state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections.\n",
      "\n",
      "The federal government spends about $600 Billion a year to keep the country safe and secure.\n"
     ]
    }
   ],
   "source": [
    "query = \"state of the economy\"\n",
    "found_docs = vectara.similarity_search(\n",
    "    query,\n",
    "    n_sentence_context=0,\n",
    "    filter=\"doc.speech = 'state-of-the-union'\",\n",
    "    k=5,\n",
    "    mmr_config={\"is_enabled\": True, \"mmr_k\": 50, \"diversity_bias\": 1.0},\n",
    ")\n",
    "print(\"\\n\\n\".join([x.page_content for x in found_docs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c1427e",
   "metadata": {},
   "source": [
    "ご覧の通り、最初の例ではdiversity\\_biasを0.0に設定しました（これは多様性リランキングを無効にすることと同等です）。その結果、上位5つの最も関連性の高いドキュメントが得られました。diversity\\_biasを1.0に設定すると、多様性が最大化され、結果として得られるトップドキュメントは、その意味内容においてはるかに多様性があります。\n",
    "\n",
    "> As you can see, in the first example diversity\\_bias was set to 0.0 (equivalent to diversity reranking disabled), which resulted in a the top-5 most relevant documents. With diversity\\_bias=1.0 we maximize diversity and as you can see the resulting top documents are much more diverse in their semantic meanings.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a82d6",
   "metadata": {},
   "source": [
    "## Vectara as a Retriever | Vectaraを検索エンジンとして\n",
    "\n",
    "最後に、`as_retriever()` インターフェースを使って Vectara を使用する方法を見てみましょう：\n",
    "\n",
    "> Finally let's see how to use Vectara with the `as_retriever()` interface:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9427195f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:51:26.031451Z",
     "start_time": "2023-04-04T10:51:26.018763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Vectara'], vectorstore=<langchain.vectorstores.vectara.Vectara object at 0x109a3c760>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectara.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3c70c31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:51:26.495652Z",
     "start_time": "2023-04-04T10:51:26.046407Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Justice Breyer, thank you for your service. One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. A former top litigator in private practice.', metadata={'source': 'langchain', 'lang': 'eng', 'offset': '596', 'len': '97', 'speech': 'state-of-the-union'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "retriever.get_relevant_documents(query)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2300e785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}